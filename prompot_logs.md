# Build a CI/CD pipeline health dashboard
_Exported on 8/25/2025 at 23:01:34 GMT+5:30 from Cursor (1.4.5)_

---

**User**

You are a Senior DevOps engineer, You need to to build a CI/CD Pipeline Health Dashboard to monitor executions from tools like GitHub Actions:

As part of this project you need to implement following:
1. Collect and visualize real-time CI/CD pipeline metrics (success/failure rate, average build time, last build status).
2. Implement alerting mechanisms (Slack/Email) for failed builds.
3. Provide a simple UI to display metrics and logs of recent builds.


start by following:
1. Requirement Analysis Document
    ‚Ä¢	Present understanding in terms of: 
          o	Key features
          o	Tech choices
          o	APIs/tools required

2. Tech Design Document 
       ‚Ä¢	High-level architecture 
       ‚Ä¢	API structure (routes, sample response) 
       ‚Ä¢	DB schema 
       ‚Ä¢	UI layout (explanation)

3. Source Code
‚Ä¢	Complete source code 
‚Ä¢	Should include:
      o	Backend (Node.js/Python etc.) 
      o	Frontend (React/Vue or any) 
      o	DB (SQLite/PostgreSQL) 
      o	Alerting service integration

4. Deployment
       ‚Ä¢	Containerize the app (Docker) 

Note: We will also need an pipeline to test this

---

**Cursor**

I'll help you build a comprehensive CI/CD Pipeline Health Dashboard. Let me start by analyzing the requirements and then create the necessary documentation and implementation.

## 1. Requirement Analysis Document

Let me create a comprehensive requirements document first:


```markdown
# CI/CD Pipeline Health Dashboard - Requirements Analysis

## Project Overview
A comprehensive dashboard to monitor and visualize CI/CD pipeline health across multiple tools, with real-time metrics, alerting capabilities, and a modern web interface.

## Key Features

### 1. Pipeline Metrics Collection
- **Real-time Data Ingestion**: Collect data from GitHub Actions, GitLab CI, Jenkins, etc.
- **Metrics Tracking**:
  - Success/failure rates
  - Average build times
  - Last build status
  - Build duration trends
  - Queue lengths
  - Resource utilization

### 2. Data Visualization
- **Dashboard Views**:
  - Overview dashboard with key KPIs
  - Pipeline-specific detailed views
  - Historical trends and analytics
  - Real-time status updates
- **Charts and Graphs**:
  - Success rate trends
  - Build time distributions
  - Failure pattern analysis
  - Pipeline performance comparisons

### 3. Alerting System
- **Notification Channels**:
  - Slack integration
  - Email alerts
  - Webhook support
- **Alert Rules**:
  - Failed build notifications
  - Build time threshold alerts
  - Success rate drops
  - Pipeline downtime alerts

### 4. Log Management
- **Build Logs**: Access to recent build logs
- **Search and Filter**: Advanced log searching capabilities
- **Log Retention**: Configurable log storage policies

## Technology Choices

### Backend
- **Runtime**: Node.js with Express.js
- **Language**: TypeScript for type safety
- **Architecture**: RESTful API with microservices approach

### Frontend
- **Framework**: React with TypeScript
- **UI Library**: Material-UI (MUI) for modern design
- **State Management**: Redux Toolkit
- **Charts**: Chart.js for data visualization

### Database
- **Primary**: PostgreSQL for production data
- **Development**: SQLite for local development
- **ORM**: Prisma for database operations

### Infrastructure
- **Containerization**: Docker with Docker Compose
- **CI/CD**: GitHub Actions for the dashboard itself
- **Monitoring**: Built-in health checks and metrics

## APIs and Tools Required

### External APIs
- **GitHub API**: For GitHub Actions data
- **GitLab API**: For GitLab CI data
- **Jenkins API**: For Jenkins pipeline data
- **Slack API**: For alerting integration
- **SMTP Service**: For email notifications

### Development Tools
- **Package Manager**: npm/yarn
- **Build Tools**: Webpack/Vite
- **Testing**: Jest, React Testing Library
- **Linting**: ESLint, Prettier
- **Version Control**: Git

### DevOps Tools
- **Container Registry**: Docker Hub or GitHub Container Registry
- **CI/CD**: GitHub Actions
- **Monitoring**: Application performance monitoring (APM)

## Success Criteria
1. **Real-time Updates**: Dashboard updates within 30 seconds of pipeline changes
2. **High Availability**: 99.9% uptime for the dashboard
3. **Performance**: Dashboard loads in under 3 seconds
4. **Scalability**: Support for 100+ concurrent users
5. **Alerting**: Notifications delivered within 1 minute of failures
6. **Data Accuracy**: 99.5% accuracy in pipeline status reporting

## Security Requirements
- **Authentication**: JWT-based authentication
- **Authorization**: Role-based access control
- **Data Encryption**: HTTPS/TLS for all communications
- **API Security**: Rate limiting and input validation
- **Secrets Management**: Secure storage of API keys and tokens
```

## 2. Technical Design Document

Now let me create the technical design document:


```markdown
# CI/CD Pipeline Health Dashboard - Technical Design Document

## High-Level Architecture

### System Overview
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Frontend      ‚îÇ    ‚îÇ    Backend      ‚îÇ    ‚îÇ   Database      ‚îÇ
‚îÇ   (React)       ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ   (Node.js)     ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ  (PostgreSQL)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                       ‚îÇ                       ‚îÇ
         ‚îÇ                       ‚îÇ                       ‚îÇ
         ‚ñº                       ‚ñº                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   WebSocket     ‚îÇ    ‚îÇ  Alerting       ‚îÇ    ‚îÇ   File Storage  ‚îÇ
‚îÇ   (Real-time)   ‚îÇ    ‚îÇ  Service        ‚îÇ    ‚îÇ   (Logs)        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Component Architecture
1. **Frontend Layer**: React SPA with Material-UI
2. **API Gateway**: Express.js REST API with middleware
3. **Data Collection Service**: Polling and webhook handlers
4. **Alerting Service**: Notification management
5. **Database Layer**: PostgreSQL with Prisma ORM
6. **Real-time Updates**: WebSocket connections
7. **External Integrations**: GitHub, GitLab, Jenkins APIs

## API Structure

### Base URL
```
https://api.cicd-dashboard.com/v1
```

### Authentication
```
POST /auth/login
POST /auth/refresh
POST /auth/logout
```

### Pipeline Management
```
GET    /pipelines              # List all pipelines
POST   /pipelines              # Add new pipeline
GET    /pipelines/:id          # Get pipeline details
PUT    /pipelines/:id          # Update pipeline
DELETE /pipelines/:id          # Delete pipeline
GET    /pipelines/:id/builds   # Get pipeline builds
GET    /pipelines/:id/metrics  # Get pipeline metrics
```

### Build Data
```
GET    /builds                 # List all builds
GET    /builds/:id             # Get build details
GET    /builds/:id/logs        # Get build logs
POST   /builds/webhook         # Webhook endpoint
```

### Metrics and Analytics
```
GET    /metrics/overview       # Dashboard overview
GET    /metrics/success-rate   # Success rate trends
GET    /metrics/build-times    # Build time analytics
GET    /metrics/failures       # Failure analysis
```

### Alerting
```
GET    /alerts                 # List alerts
POST   /alerts                 # Create alert rule
PUT    /alerts/:id             # Update alert rule
DELETE /alerts/:id             # Delete alert rule
POST   /alerts/test            # Test notification
```

### Sample API Responses

#### Pipeline List Response
```json
{
  "success": true,
  "data": {
    "pipelines": [
      {
        "id": "1",
        "name": "Frontend CI/CD",
        "type": "github_actions",
        "repository": "org/frontend-app",
        "status": "success",
        "lastBuild": {
          "id": "build-123",
          "status": "success",
          "duration": 450,
          "timestamp": "2024-01-15T10:30:00Z"
        },
        "metrics": {
          "successRate": 95.2,
          "avgBuildTime": 420,
          "totalBuilds": 150
        }
      }
    ],
    "pagination": {
      "page": 1,
      "limit": 20,
      "total": 150
    }
  }
}
```

#### Build Details Response
```json
{
  "success": true,
  "data": {
    "id": "build-123",
    "pipelineId": "1",
    "status": "success",
    "startTime": "2024-01-15T10:25:00Z",
    "endTime": "2024-01-15T10:32:30Z",
    "duration": 450,
    "stages": [
      {
        "name": "Install Dependencies",
        "status": "success",
        "duration": 120
      },
      {
        "name": "Run Tests",
        "status": "success",
        "duration": 180
      },
      {
        "name": "Build Artifact",
        "status": "success",
        "duration": 150
      }
    ],
    "logs": "https://logs.cicd-dashboard.com/build-123.log"
  }
}
```

## Database Schema

### Core Tables

#### Pipelines
```sql
CREATE TABLE pipelines (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  name VARCHAR(255) NOT NULL,
  type VARCHAR(50) NOT NULL, -- 'github_actions', 'gitlab_ci', 'jenkins'
  repository VARCHAR(500) NOT NULL,
  config JSONB NOT NULL, -- API keys, webhook URLs, etc.
  status VARCHAR(50) DEFAULT 'unknown',
  last_build_id UUID REFERENCES builds(id),
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

#### Builds
```sql
CREATE TABLE builds (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  pipeline_id UUID NOT NULL REFERENCES pipelines(id),
  external_id VARCHAR(255) NOT NULL, -- ID from external system
  status VARCHAR(50) NOT NULL, -- 'pending', 'running', 'success', 'failed', 'cancelled'
  start_time TIMESTAMP,
  end_time TIMESTAMP,
  duration INTEGER, -- in seconds
  commit_hash VARCHAR(100),
  branch VARCHAR(100),
  trigger_type VARCHAR(50), -- 'push', 'pull_request', 'manual'
  metadata JSONB, -- additional build information
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

#### Build Stages
```sql
CREATE TABLE build_stages (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  build_id UUID NOT NULL REFERENCES builds(id),
  name VARCHAR(255) NOT NULL,
  status VARCHAR(50) NOT NULL,
  start_time TIMESTAMP,
  end_time TIMESTAMP,
  duration INTEGER,
  logs TEXT,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

#### Metrics
```sql
CREATE TABLE metrics (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  pipeline_id UUID NOT NULL REFERENCES pipelines(id),
  metric_type VARCHAR(50) NOT NULL, -- 'success_rate', 'build_time', 'failure_count'
  value DECIMAL(10,4) NOT NULL,
  timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  period VARCHAR(20) NOT NULL -- 'hourly', 'daily', 'weekly'
);
```

#### Alerts
```sql
CREATE TABLE alerts (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  name VARCHAR(255) NOT NULL,
  pipeline_id UUID REFERENCES pipelines(id),
  condition_type VARCHAR(50) NOT NULL, -- 'failure', 'build_time', 'success_rate'
  threshold DECIMAL(10,4) NOT NULL,
  notification_channels JSONB NOT NULL, -- Slack, email, webhook
  is_active BOOLEAN DEFAULT true,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

#### Alert History
```sql
CREATE TABLE alert_history (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  alert_id UUID NOT NULL REFERENCES alerts(id),
  build_id UUID REFERENCES builds(id),
  message TEXT NOT NULL,
  severity VARCHAR(20) NOT NULL, -- 'info', 'warning', 'error', 'critical'
  sent_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  notification_status VARCHAR(50) -- 'sent', 'failed', 'pending'
);
```

### Indexes
```sql
CREATE INDEX idx_pipelines_type ON pipelines(type);
CREATE INDEX idx_builds_pipeline_status ON builds(pipeline_id, status);
CREATE INDEX idx_builds_timestamp ON builds(created_at);
CREATE INDEX idx_metrics_pipeline_timestamp ON metrics(pipeline_id, timestamp);
CREATE INDEX idx_alerts_pipeline ON alerts(pipeline_id);
```

## UI Layout and Design

### Dashboard Overview
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Header: Logo, Navigation, User Profile, Notifications         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ   Total     ‚îÇ ‚îÇ   Success   ‚îÇ ‚îÇ   Failed    ‚îÇ ‚îÇ   Running   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  Pipelines  ‚îÇ ‚îÇ    Rate     ‚îÇ ‚îÇ   Builds    ‚îÇ ‚îÇ   Builds    ‚îÇ ‚îÇ
‚îÇ  ‚îÇ     25      ‚îÇ ‚îÇ    95.2%    ‚îÇ ‚îÇ     3       ‚îÇ ‚îÇ     2       ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ                    Pipeline Status Map                      ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  [Success] [Running] [Failed] [Pending] [Unknown]         ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ                    Recent Builds                           ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Build 1 ‚îÇ ‚îÇ Build 2 ‚îÇ ‚îÇ Build 3 ‚îÇ ‚îÇ Build 4 ‚îÇ          ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Success ‚îÇ ‚îÇ Failed  ‚îÇ ‚îÇ Running ‚îÇ ‚îÇ Success ‚îÇ          ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ                    Success Rate Trend                       ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  [Chart showing success rate over time]                    ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ                    Build Time Distribution                  ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  [Chart showing build time patterns]                       ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Pipeline Detail View
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Breadcrumb: Dashboard > Frontend CI/CD                         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ Pipeline: Frontend CI/CD                    [Edit] [Delete] ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Repository: org/frontend-app                                ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Type: GitHub Actions                                        ‚îÇ
‚îÇ  ‚îÇ Status: Active                                              ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ                    Pipeline Metrics                         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Total   ‚îÇ ‚îÇ Success ‚îÇ ‚îÇ Avg     ‚îÇ ‚îÇ Last    ‚îÇ          ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Builds  ‚îÇ ‚îÇ  Rate   ‚îÇ ‚îÇ Build   ‚îÇ ‚îÇ Build   ‚îÇ          ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  150    ‚îÇ ‚îÇ  95.2%  ‚îÇ ‚îÇ  Time   ‚îÇ ‚îÇ Status  ‚îÇ          ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ         ‚îÇ ‚îÇ         ‚îÇ ‚îÇ  420s   ‚îÇ ‚îÇSuccess  ‚îÇ          ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ                    Build History                            ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  [Table with columns: Build ID, Status, Duration, Branch,  ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   Commit, Trigger, Start Time, Actions]                    ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ                    Performance Charts                       ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  [Success Rate Trend] [Build Time Distribution]            ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Alert Configuration
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Alerts Configuration                              [Add New]     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ Alert Rules                                                ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Name: Build Failure Alert                            ‚îÇ   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Pipeline: Frontend CI/CD                             ‚îÇ   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Condition: Build Status = Failed                     ‚îÇ   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Notifications: Slack #dev-alerts, email@team.com     ‚îÇ   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Status: Active                    [Edit] [Delete]     ‚îÇ   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                             ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Name: Slow Build Alert                               ‚îÇ   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Pipeline: Frontend CI/CD                             ‚îÇ   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Condition: Build Time > 600 seconds                  ‚îÇ   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Notifications: Slack #dev-alerts                     ‚îÇ   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Status: Active                    [Edit] [Delete]     ‚îÇ   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Data Flow

### Real-time Updates
1. **Webhook Reception**: External systems send webhooks to `/builds/webhook`
2. **Data Processing**: Backend processes and stores build data
3. **Metrics Calculation**: Real-time metrics are computed and stored
4. **WebSocket Broadcast**: Updates are pushed to connected clients
5. **Alert Evaluation**: Alert conditions are checked and notifications sent

### Data Collection
1. **Scheduled Polling**: Regular API calls to external systems
2. **Webhook Handling**: Immediate updates via webhooks
3. **Data Validation**: Input sanitization and validation
4. **Storage**: Structured data storage in PostgreSQL
5. **Caching**: Redis for frequently accessed data

## Security Considerations

### Authentication & Authorization
- JWT-based authentication with refresh tokens
- Role-based access control (Admin, User, Viewer)
- API rate limiting and request validation
- CORS configuration for frontend access

### Data Protection
- Encryption at rest for sensitive configuration data
- HTTPS/TLS for all communications
- Input sanitization and SQL injection prevention
- Secure storage of API keys and tokens

### Monitoring & Logging
- Comprehensive audit logging
- Error tracking and monitoring
- Performance metrics collection
- Security event logging
```

## 3. Source Code Implementation

Now let me create the complete source code for the CI/CD Pipeline Health Dashboard. I'll start with the project structure and then implement each component.

### Project Structure


```json
{
  "name": "cicd-pipeline-dashboard",
  "version": "1.0.0",
  "description": "A comprehensive CI/CD Pipeline Health Dashboard with real-time monitoring and alerting",
  "main": "dist/server.js",
  "scripts": {
    "dev": "concurrently \"npm run dev:backend\" \"npm run dev:frontend\"",
    "dev:backend": "nodemon --exec ts-node src/server/index.ts",
    "dev:frontend": "cd frontend && npm run dev",
    "build": "npm run build:backend && npm run build:frontend",
    "build:backend": "tsc",
    "build:frontend": "cd frontend && npm run build",
    "start": "node dist/server/index.js",
    "test": "jest",
    "test:watch": "jest --watch",
    "lint": "eslint src/**/*.ts",
    "lint:fix": "eslint src/**/*.ts --fix",
    "db:migrate": "prisma migrate dev",
    "db:generate": "prisma generate",
    "db:seed": "ts-node prisma/seed.ts",
    "docker:build": "docker-compose build",
    "docker:up": "docker-compose up -d",
    "docker:down": "docker-compose down"
  },
  "keywords": [
    "ci-cd",
    "pipeline",
    "dashboard",
    "monitoring",
    "devops",
    "github-actions",
    "gitlab-ci",
    "jenkins"
  ],
  "author": "DevOps Team",
  "license": "MIT",
  "dependencies": {
    "express": "^4.18.2",
    "cors": "^2.8.5",
    "helmet": "^7.1.0",
    "morgan": "^1.10.0",
    "dotenv": "^16.3.1",
    "jsonwebtoken": "^9.0.2",
    "bcryptjs": "^2.4.3",
    "express-rate-limit": "^7.1.5",
    "express-validator": "^7.0.1",
    "socket.io": "^4.7.4",
    "axios": "^1.6.2",
    "node-cron": "^3.0.3",
    "nodemailer": "^6.9.7",
    "@slack/web-api": "^6.10.0",
    "prisma": "^5.7.1",
    "@prisma/client": "^5.7.1",
    "redis": "^4.6.11",
    "winston": "^3.11.0",
    "compression": "^1.7.4",
    "express-async-errors": "^3.1.1"
  },
  "devDependencies": {
    "@types/express": "^4.17.21",
    "@types/cors": "^2.8.17",
    "@types/morgan": "^1.9.9",
    "@types/node": "^20.10.4",
    "@types/jsonwebtoken": "^9.0.5",
    "@types/bcryptjs": "^2.4.6",
    "@types/compression": "^1.7.5",
    "@types/nodemailer": "^6.4.14",
    "@types/node-cron": "^3.0.11",
    "typescript": "^5.3.3",
    "ts-node": "^10.9.1",
    "nodemon": "^3.0.2",
    "jest": "^29.7.0",
    "@types/jest": "^29.5.8",
    "ts-jest": "^29.1.1",
    "eslint": "^8.55.0",
    "@typescript-eslint/eslint-plugin": "^6.13.1",
    "@typescript-eslint/parser": "^6.13.1",
    "concurrently": "^8.2.2"
  },
  "engines": {
    "node": ">=18.0.0",
    "npm": ">=8.0.0"
  }
}
```

### TypeScript Configuration


```jsonc
{
  "compilerOptions": {
    "target": "ES2020",
    "module": "commonjs",
    "lib": ["ES2020"],
    "outDir": "./dist",
    "rootDir": "./src",
    "strict": true,
    "esModuleInterop": true,
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true,
    "resolveJsonModule": true,
    "declaration": true,
    "declarationMap": true,
    "sourceMap": true,
    "removeComments": true,
    "noImplicitAny": true,
    "noImplicitReturns": true,
    "noImplicitThis": true,
    "noUnusedLocals": true,
    "noUnusedParameters": true,
    "exactOptionalPropertyTypes": true,
    "noImplicitOverride": true,
    "noPropertyAccessFromIndexSignature": true,
    "noUncheckedIndexedAccess": true,
    "allowUnusedLabels": false,
    "allowUnreachableCode": false
  },
  "include": [
    "src/**/*",
    "prisma/**/*"
  ],
  "exclude": [
    "node_modules",
    "dist",
    "frontend",
    "**/*.test.ts",
    "**/*.spec.ts"
  ]
}
```

### Environment Configuration


Let me create the environment file with a different name:


```plaintext
# Server Configuration
NODE_ENV=development
PORT=3000
API_VERSION=v1

# Database Configuration
DATABASE_URL="postgresql://username:password@localhost:5432/cicd_dashboard"
DATABASE_URL_DEV="sqlite:./dev.db"

# JWT Configuration
JWT_SECRET=your-super-secret-jwt-key-here
JWT_EXPIRES_IN=24h
JWT_REFRESH_EXPIRES_IN=7d

# Redis Configuration
REDIS_URL=redis://localhost:6379

# GitHub Integration
GITHUB_API_TOKEN=your-github-personal-access-token
GITHUB_WEBHOOK_SECRET=your-github-webhook-secret

# GitLab Integration
GITLAB_API_TOKEN=your-gitlab-access-token
GITLAB_WEBHOOK_SECRET=your-gitlab-webhook-secret

# Jenkins Integration
JENKINS_URL=http://jenkins.example.com
JENKINS_USERNAME=your-jenkins-username
JENKINS_API_TOKEN=your-jenkins-api-token

# Slack Integration
SLACK_BOT_TOKEN=xoxb-your-slack-bot-token
SLACK_SIGNING_SECRET=your-slack-signing-secret
SLACK_CHANNEL_ID=C1234567890

# Email Configuration (SMTP)
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USER=your-email@gmail.com
SMTP_PASS=your-app-password
SMTP_FROM=noreply@cicd-dashboard.com

# Security
CORS_ORIGIN=http://localhost:3001
RATE_LIMIT_WINDOW_MS=900000
RATE_LIMIT_MAX_REQUESTS=100

# Logging
LOG_LEVEL=info
LOG_FILE=logs/app.log

# Monitoring
HEALTH_CHECK_INTERVAL=30000
METRICS_UPDATE_INTERVAL=60000
```

### Prisma Database Schema


```plaintext
// This is your Prisma schema file,
// learn more about it in the docs: https://pris.ly/d/prisma-schema

generator client {
  provider = "prisma-client-js"
}

datasource db {
  provider = "postgresql"
  url      = env("DATABASE_URL")
}

model User {
  id        String   @id @default(cuid())
  email     String   @unique
  username  String   @unique
  password  String
  role      UserRole @default(VIEWER)
  isActive  Boolean  @default(true)
  createdAt DateTime @default(now())
  updatedAt DateTime @updatedAt

  // Relations
  alerts Alert[]

  @@map("users")
}

model Pipeline {
  id           String   @id @default(cuid())
  name         String
  type         PipelineType
  repository   String
  config       Json
  status       PipelineStatus @default(UNKNOWN)
  lastBuildId  String?
  createdAt    DateTime @default(now())
  updatedAt    DateTime @updatedAt

  // Relations
  builds  Build[]
  metrics Metric[]
  alerts Alert[]

  @@map("pipelines")
}

model Build {
  id           String      @id @default(cuid())
  pipelineId   String
  externalId   String
  status       BuildStatus
  startTime    DateTime?
  endTime      DateTime?
  duration     Int? // in seconds
  commitHash   String?
  branch       String?
  triggerType  TriggerType
  metadata     Json?
  createdAt    DateTime    @default(now())

  // Relations
  pipeline     Pipeline    @relation(fields: [pipelineId], references: [id], onDelete: Cascade)
  stages       BuildStage[]
  alertHistory AlertHistory[]

  @@map("builds")
}

model BuildStage {
  id        String      @id @default(cuid())
  buildId   String
  name      String
  status    BuildStatus
  startTime DateTime?
  endTime   DateTime?
  duration  Int? // in seconds
  logs      String?
  createdAt DateTime    @default(now())

  // Relations
  build     Build       @relation(fields: [buildId], references: [id], onDelete: Cascade)

  @@map("build_stages")
}

model Metric {
  id          String      @id @default(cuid())
  pipelineId  String
  metricType  MetricType
  value       Decimal     @db.Decimal(10, 4)
  timestamp   DateTime    @default(now())
  period      MetricPeriod

  // Relations
  pipeline   Pipeline    @relation(fields: [pipelineId], references: [id], onDelete: Cascade)

  @@map("metrics")
}

model Alert {
  id                 String        @id @default(cuid())
  name               String
  pipelineId         String?
  conditionType      AlertConditionType
  threshold          Decimal       @db.Decimal(10, 4)
  notificationChannels Json
  isActive           Boolean       @default(true)
  createdBy          String
  createdAt          DateTime      @default(now())
  updatedAt          DateTime      @updatedAt

  // Relations
  pipeline     Pipeline?      @relation(fields: [pipelineId], references: [id])
  user         User           @relation(fields: [createdBy], references: [id])
  alertHistory AlertHistory[]

  @@map("alerts")
}

model AlertHistory {
  id                 String              @id @default(cuid())
  alertId            String
  buildId            String?
  message            String
  severity           AlertSeverity
  sentAt             DateTime            @default(now())
  notificationStatus NotificationStatus

  // Relations
  alert      Alert       @relation(fields: [alertId], references: [id], onDelete: Cascade)
  build      Build?      @relation(fields: [buildId], references: [id])

  @@map("alert_history")
}

// Enums
enum UserRole {
  ADMIN
  USER
  VIEWER
}

enum PipelineType {
  GITHUB_ACTIONS
  GITLAB_CI
  JENKINS
  AZURE_DEVOPS
  CIRCLE_CI
  TRAVIS_CI
}

enum PipelineStatus {
  SUCCESS
  FAILED
  RUNNING
  PENDING
  UNKNOWN
  DISABLED
}

enum BuildStatus {
  PENDING
  RUNNING
  SUCCESS
  FAILED
  CANCELLED
  SKIPPED
}

enum TriggerType {
  PUSH
  PULL_REQUEST
  MANUAL
  SCHEDULED
  WEBHOOK
}

enum MetricType {
  SUCCESS_RATE
  BUILD_TIME
  FAILURE_COUNT
  QUEUE_LENGTH
  RESOURCE_UTILIZATION
}

enum MetricPeriod {
  HOURLY
  DAILY
  WEEKLY
  MONTHLY
}

enum AlertConditionType {
  FAILURE
  BUILD_TIME
  SUCCESS_RATE
  QUEUE_LENGTH
  PIPELINE_DOWN
}

enum AlertSeverity {
  INFO
  WARNING
  ERROR
  CRITICAL
}

enum NotificationStatus {
  SENT
  FAILED
  PENDING
}
```

### Backend Implementation

Now let me create the backend server structure:


```typescript
import 'express-async-errors';
import express from 'express';
import cors from 'cors';
import helmet from 'helmet';
import morgan from 'morgan';
import compression from 'compression';
import { createServer } from 'http';
import { Server } from 'socket.io';
import dotenv from 'dotenv';
import rateLimit from 'express-rate-limit';

import { logger } from '../utils/logger';
import { errorHandler } from '../middleware/errorHandler';
import { notFoundHandler } from '../middleware/notFoundHandler';
import { authRoutes } from '../routes/auth';
import { pipelineRoutes } from '../routes/pipelines';
import { buildRoutes } from '../routes/builds';
import { metricsRoutes } from '../routes/metrics';
import { alertRoutes } from '../routes/alerts';
import { healthRoutes } from '../routes/health';
import { setupWebSocket } from '../services/websocket';
import { setupDataCollection } from '../services/dataCollection';
import { setupAlerting } from '../services/alerting';

// Load environment variables
dotenv.config();

const app = express();
const server = createServer(app);
const io = new Server(server, {
  cors: {
    origin: process.env.CORS_ORIGIN || 'http://localhost:3001',
    methods: ['GET', 'POST']
  }
});

const PORT = process.env.PORT || 3000;

// Security middleware
app.use(helmet());
app.use(cors({
  origin: process.env.CORS_ORIGIN || 'http://localhost:3001',
  credentials: true
}));

// Rate limiting
const limiter = rateLimit({
  windowMs: parseInt(process.env.RATE_LIMIT_WINDOW_MS || '900000'), // 15 minutes
  max: parseInt(process.env.RATE_LIMIT_MAX_REQUESTS || '100'), // limit each IP to 100 requests per windowMs
  message: 'Too many requests from this IP, please try again later.'
});
app.use('/api/', limiter);

// Logging middleware
app.use(morgan('combined', {
  stream: {
    write: (message: string) => logger.info(message.trim())
  }
}));

// Body parsing middleware
app.use(express.json({ limit: '10mb' }));
app.use(express.urlencoded({ extended: true, limit: '10mb' }));

// Compression middleware
app.use(compression());

// Health check endpoint
app.get('/health', (req, res) => {
  res.status(200).json({ status: 'OK', timestamp: new Date().toISOString() });
});

// API routes
app.use('/api/v1/auth', authRoutes);
app.use('/api/v1/pipelines', pipelineRoutes);
app.use('/api/v1/builds', buildRoutes);
app.use('/api/v1/metrics', metricsRoutes);
app.use('/api/v1/alerts', alertRoutes);
app.use('/api/v1/health', healthRoutes);

// Serve static files in production
if (process.env.NODE_ENV === 'production') {
  app.use(express.static('frontend/dist'));
  app.get('*', (req, res) => {
    res.sendFile('index.html', { root: 'frontend/dist' });
  });
}

// Error handling middleware
app.use(notFoundHandler);
app.use(errorHandler);

// Setup WebSocket
setupWebSocket(io);

// Setup background services
setupDataCollection();
setupAlerting();

// Start server
server.listen(PORT, () => {
  logger.info(`üöÄ CI/CD Pipeline Health Dashboard server running on port ${PORT}`);
  logger.info(`üìä Environment: ${process.env.NODE_ENV || 'development'}`);
  logger.info(`üîó API Base URL: http://localhost:${PORT}/api/v1`);
});

// Graceful shutdown
process.on('SIGTERM', () => {
  logger.info('SIGTERM received, shutting down gracefully');
  server.close(() => {
    logger.info('Process terminated');
    process.exit(0);
  });
});

process.on('SIGINT', () => {
  logger.info('SIGINT received, shutting down gracefully');
  server.close(() => {
    logger.info('Process terminated');
    process.exit(0);
  });
});

export { app, server, io };
```

### Logger Utility


```typescript
import winston from 'winston';
import path from 'path';

// Define log levels
const levels = {
  error: 0,
  warn: 1,
  info: 2,
  http: 3,
  debug: 4,
};

// Define colors for each level
const colors = {
  error: 'red',
  warn: 'yellow',
  info: 'green',
  http: 'magenta',
  debug: 'white',
};

// Tell winston that you want to link the colors
winston.addColors(colors);

// Define which level to log based on environment
const level = () => {
  const env = process.env.NODE_ENV || 'development';
  const isDevelopment = env === 'development';
  return isDevelopment ? 'debug' : 'warn';
};

// Define format for logs
const format = winston.format.combine(
  winston.format.timestamp({ format: 'YYYY-MM-DD HH:mm:ss:ms' }),
  winston.format.colorize({ all: true }),
  winston.format.printf(
    (info) => `${info.timestamp} ${info.level}: ${info.message}`,
  ),
);

// Define transports
const transports = [
  // Console transport
  new winston.transports.Console({
    format: winston.format.combine(
      winston.format.colorize(),
      winston.format.simple()
    )
  }),
  
  // File transport for errors
  new winston.transports.File({
    filename: path.join('logs', 'error.log'),
    level: 'error',
    format: winston.format.combine(
      winston.format.timestamp(),
      winston.format.json()
    )
  }),
  
  // File transport for all logs
  new winston.transports.File({
    filename: path.join('logs', 'combined.log'),
    format: winston.format.combine(
      winston.format.timestamp(),
      winston.format.json()
    )
  }),
];

// Create the logger
export const logger = winston.createLogger({
  level: level(),
  levels,
  format,
  transports,
});

// Create a stream object for Morgan HTTP logging
export const stream = {
  write: (message: string) => {
    logger.http(message.trim());
  },
};

// Log uncaught exceptions
process.on('uncaughtException', (error) => {
  logger.error('Uncaught Exception:', error);
  process.exit(1);
});

// Log unhandled promise rejections
process.on('unhandledRejection', (reason, promise) => {
  logger.error('Unhandled Rejection at:', promise, 'reason:', reason);
  process.exit(1);
});

// Export default logger
export default logger;
```

### Database Client


```typescript
import { PrismaClient } from '@prisma/client';
import { logger } from './logger';

declare global {
  var __prisma: PrismaClient | undefined;
}

// Create a single instance of Prisma Client
export const prisma = globalThis.__prisma || new PrismaClient({
  log: process.env.NODE_ENV === 'development' ? ['query', 'error', 'warn'] : ['error'],
  errorFormat: 'pretty',
});

// Store the instance globally in development to prevent multiple instances
if (process.env.NODE_ENV === 'development') {
  globalThis.__prisma = prisma;
}

// Database connection and health check
export const connectDatabase = async (): Promise<void> => {
  try {
    await prisma.$connect();
    logger.info('‚úÖ Database connected successfully');
  } catch (error) {
    logger.error('‚ùå Database connection failed:', error);
    throw error;
  }
};

// Graceful database disconnection
export const disconnectDatabase = async (): Promise<void> => {
  try {
    await prisma.$disconnect();
    logger.info('‚úÖ Database disconnected successfully');
  } catch (error) {
    logger.error('‚ùå Database disconnection failed:', error);
  }
};

// Database health check
export const checkDatabaseHealth = async (): Promise<boolean> => {
  try {
    await prisma.$queryRaw`SELECT 1`;
    return true;
  } catch (error) {
    logger.error('Database health check failed:', error);
    return false;
  }
};

// Handle database errors
export const handleDatabaseError = (error: any): never => {
  logger.error('Database operation failed:', error);
  
  if (error.code === 'P2002') {
    throw new Error('A record with this unique field already exists');
  }
  
  if (error.code === 'P2025') {
    throw new Error('Record not found');
  }
  
  if (error.code === 'P2003') {
    throw new Error('Foreign key constraint failed');
  }
  
  throw new Error('Database operation failed');
};

// Transaction wrapper
export const withTransaction = async <T>(
  operation: () => Promise<T>
): Promise<T> => {
  return await prisma.$transaction(operation);
};

// Export default prisma client
export default prisma;
```

### Middleware


```typescript
import { Request, Response, NextFunction } from 'express';
import { logger } from '../utils/logger';

export interface AppError extends Error {
  statusCode?: number;
  isOperational?: boolean;
}

export const errorHandler = (
  error: AppError,
  req: Request,
  res: Response,
  next: NextFunction
): void => {
  const statusCode = error.statusCode || 500;
  const message = error.message || 'Internal Server Error';

  // Log the error
  logger.error(`Error ${statusCode}: ${message}`, {
    error: error.stack,
    url: req.url,
    method: req.method,
    ip: req.ip,
    userAgent: req.get('User-Agent'),
  });

  // Don't leak error details in production
  const responseMessage = process.env.NODE_ENV === 'production' && statusCode === 500
    ? 'Internal Server Error'
    : message;

  res.status(statusCode).json({
    success: false,
    error: {
      message: responseMessage,
      ...(process.env.NODE_ENV === 'development' && { stack: error.stack }),
    },
  });
};

export const createError = (message: string, statusCode: number = 500): AppError => {
  const error = new Error(message) as AppError;
  error.statusCode = statusCode;
  error.isOperational = true;
  return error;
};

export const notFoundError = (resource: string = 'Resource'): AppError => {
  return createError(`${resource} not found`, 404);
};

export const validationError = (message: string): AppError => {
  return createError(message, 400);
};

export const unauthorizedError = (message: string = 'Unauthorized'): AppError => {
  return createError(message, 401);
};

export const forbiddenError = (message: string = 'Forbidden'): AppError => {
  return createError(message, 403);
};

export const conflictError = (message: string): AppError => {
  return createError(message, 409);
};
```

```typescript
import { Request, Response } from 'express';
import { logger } from '../utils/logger';

export const notFoundHandler = (req: Request, res: Response): void => {
  logger.warn(`Route not found: ${req.method} ${req.originalUrl}`);
  
  res.status(404).json({
    success: false,
    error: {
      message: `Route ${req.method} ${req.originalUrl} not found`,
      code: 'ROUTE_NOT_FOUND'
    }
  });
};
```

```typescript
import { Request, Response, NextFunction } from 'express';
import jwt from 'jsonwebtoken';
import { prisma } from '../utils/database';
import { unauthorizedError, forbiddenError } from './errorHandler';

export interface AuthenticatedRequest extends Request {
  user?: {
    id: string;
    email: string;
    username: string;
    role: string;
  };
}

export const authenticateToken = async (
  req: AuthenticatedRequest,
  res: Response,
  next: NextFunction
): Promise<void> => {
  try {
    const authHeader = req.headers.authorization;
    const token = authHeader && authHeader.split(' ')[1]; // Bearer TOKEN

    if (!token) {
      throw unauthorizedError('Access token required');
    }

    const decoded = jwt.verify(token, process.env.JWT_SECRET!) as any;
    
    // Check if user still exists and is active
    const user = await prisma.user.findUnique({
      where: { id: decoded.userId },
      select: {
        id: true,
        email: true,
        username: true,
        role: true,
        isActive: true
      }
    });

    if (!user || !user.isActive) {
      throw unauthorizedError('User not found or inactive');
    }

    req.user = user;
    next();
  } catch (error) {
    if (error instanceof Error && error.name === 'JsonWebTokenError') {
      next(unauthorizedError('Invalid token'));
    } else if (error instanceof Error && error.name === 'TokenExpiredError') {
      next(unauthorizedError('Token expired'));
    } else {
      next(error);
    }
  }
};

export const requireRole = (roles: string[]) => {
  return (req: AuthenticatedRequest, res: Response, next: NextFunction): void => {
    if (!req.user) {
      next(unauthorizedError('Authentication required'));
      return;
    }

    if (!roles.includes(req.user.role)) {
      next(forbiddenError('Insufficient permissions'));
      return;
    }

    next();
  };
};

export const requireAdmin = requireRole(['ADMIN']);
export const requireUser = requireRole(['ADMIN', 'USER']);
export const requireViewer = requireRole(['ADMIN', 'USER', 'VIEWER']);
```

### Routes

Now let me create the API routes:


```typescript
import { Router, Request, Response } from 'express';
import bcrypt from 'bcryptjs';
import jwt from 'jsonwebtoken';
import { body, validationResult } from 'express-validator';
import { prisma } from '../utils/database';
import { authenticateToken, AuthenticatedRequest } from '../middleware/auth';
import { createError, validationError, unauthorizedError } from '../middleware/errorHandler';
import { logger } from '../utils/logger';

const router = Router();

// Validation middleware
const validateLogin = [
  body('email').isEmail().normalizeEmail(),
  body('password').isLength({ min: 6 })
];

const validateRegister = [
  body('email').isEmail().normalizeEmail(),
  body('username').isLength({ min: 3, max: 30 }).matches(/^[a-zA-Z0-9_]+$/),
  body('password').isLength({ min: 6 }),
  body('role').optional().isIn(['ADMIN', 'USER', 'VIEWER'])
];

// Register new user (Admin only)
router.post('/register', validateRegister, async (req: Request, res: Response) => {
  try {
    const errors = validationResult(req);
    if (!errors.isEmpty()) {
      throw validationError(errors.array()[0].msg);
    }

    const { email, username, password, role = 'VIEWER' } = req.body;

    // Check if user already exists
    const existingUser = await prisma.user.findFirst({
      where: {
        OR: [
          { email },
          { username }
        ]
      }
    });

    if (existingUser) {
      throw createError('User with this email or username already exists', 409);
    }

    // Hash password
    const saltRounds = 12;
    const hashedPassword = await bcrypt.hash(password, saltRounds);

    // Create user
    const user = await prisma.user.create({
      data: {
        email,
        username,
        password: hashedPassword,
        role
      },
      select: {
        id: true,
        email: true,
        username: true,
        role: true,
        createdAt: true
      }
    });

    logger.info(`New user registered: ${user.email}`);

    res.status(201).json({
      success: true,
      message: 'User registered successfully',
      data: user
    });
  } catch (error) {
    res.status(error.statusCode || 500).json({
      success: false,
      error: { message: error.message }
    });
  }
});

// Login user
router.post('/login', validateLogin, async (req: Request, res: Response) => {
  try {
    const errors = validationResult(req);
    if (!errors.isEmpty()) {
      throw validationError(errors.array()[0].msg);
    }

    const { email, password } = req.body;

    // Find user
    const user = await prisma.user.findUnique({
      where: { email }
    });

    if (!user || !user.isActive) {
      throw unauthorizedError('Invalid credentials');
    }

    // Check password
    const isValidPassword = await bcrypt.compare(password, user.password);
    if (!isValidPassword) {
      throw unauthorizedError('Invalid credentials');
    }

    // Generate tokens
    const accessToken = jwt.sign(
      { userId: user.id, email: user.email, role: user.role },
      process.env.JWT_SECRET!,
      { expiresIn: process.env.JWT_EXPIRES_IN || '24h' }
    );

    const refreshToken = jwt.sign(
      { userId: user.id },
      process.env.JWT_SECRET!,
      { expiresIn: process.env.JWT_REFRESH_EXPIRES_IN || '7d' }
    );

    logger.info(`User logged in: ${user.email}`);

    res.json({
      success: true,
      message: 'Login successful',
      data: {
        user: {
          id: user.id,
          email: user.email,
          username: user.username,
          role: user.role
        },
        tokens: {
          accessToken,
          refreshToken
        }
      }
    });
  } catch (error) {
    res.status(error.statusCode || 500).json({
      success: false,
      error: { message: error.message }
    });
  }
});

// Refresh token
router.post('/refresh', async (req: Request, res: Response) => {
  try {
    const { refreshToken } = req.body;

    if (!refreshToken) {
      throw unauthorizedError('Refresh token required');
    }

    // Verify refresh token
    const decoded = jwt.verify(refreshToken, process.env.JWT_SECRET!) as any;
    
    // Check if user exists
    const user = await prisma.user.findUnique({
      where: { id: decoded.userId },
      select: { id: true, email: true, role: true, isActive: true }
    });

    if (!user || !user.isActive) {
      throw unauthorizedError('Invalid refresh token');
    }

    // Generate new access token
    const newAccessToken = jwt.sign(
      { userId: user.id, email: user.email, role: user.role },
      process.env.JWT_SECRET!,
      { expiresIn: process.env.JWT_EXPIRES_IN || '24h' }
    );

    res.json({
      success: true,
      data: {
        accessToken: newAccessToken
      }
    });
  } catch (error) {
    res.status(error.statusCode || 500).json({
      success: false,
      error: { message: error.message }
    });
  }
});

// Logout user
router.post('/logout', authenticateToken, async (req: AuthenticatedRequest, res: Response) => {
  try {
    // In a real application, you might want to blacklist the token
    // For now, we'll just return success
    logger.info(`User logged out: ${req.user?.email}`);

    res.json({
      success: true,
      message: 'Logout successful'
    });
  } catch (error) {
    res.status(error.statusCode || 500).json({
      success: false,
      error: { message: error.message }
    });
  }
});

// Get current user profile
router.get('/profile', authenticateToken, async (req: AuthenticatedRequest, res: Response) => {
  try {
    const user = await prisma.user.findUnique({
      where: { id: req.user!.id },
      select: {
        id: true,
        email: true,
        username: true,
        role: true,
        isActive: true,
        createdAt: true,
        updatedAt: true
      }
    });

    res.json({
      success: true,
      data: user
    });
  } catch (error) {
    res.status(error.statusCode || 500).json({
      success: false,
      error: { message: error.message }
    });
  }
});

// Change password
router.put('/change-password', authenticateToken, [
  body('currentPassword').notEmpty(),
  body('newPassword').isLength({ min: 6 })
], async (req: AuthenticatedRequest, res: Response) => {
  try {
    const errors = validationResult(req);
    if (!errors.isEmpty()) {
      throw validationError(errors.array()[0].msg);
    }

    const { currentPassword, newPassword } = req.body;

    // Get user with password
    const user = await prisma.user.findUnique({
      where: { id: req.user!.id }
    });

    if (!user) {
      throw createError('User not found', 404);
    }

    // Verify current password
    const isValidPassword = await bcrypt.compare(currentPassword, user.password);
    if (!isValidPassword) {
      throw unauthorizedError('Current password is incorrect');
    }

    // Hash new password
    const saltRounds = 12;
    const hashedPassword = await bcrypt.hash(newPassword, saltRounds);

    // Update password
    await prisma.user.update({
      where: { id: req.user!.id },
      data: { password: hashedPassword }
    });

    logger.info(`Password changed for user: ${user.email}`);

    res.json({
      success: true,
      message: 'Password changed successfully'
    });
  } catch (error) {
    res.status(error.statusCode || 500).json({
      success: false,
      error: { message: error.message }
    });
  }
});

export { router as authRoutes };
```

Now let me create the pipeline routes:


```typescript
import { Router, Request, Response } from 'express';
import { body, validationResult, query } from 'express-validator';
import { prisma } from '../utils/database';
import { authenticateToken, requireUser, AuthenticatedRequest } from '../middleware/auth';
import { createError, validationError, notFoundError } from '../middleware/errorHandler';
import { logger } from '../utils/logger';

const router = Router();

// Validation middleware
const validatePipeline = [
  body('name').isLength({ min: 1, max: 255 }),
  body('type').isIn(['GITHUB_ACTIONS', 'GITLAB_CI', 'JENKINS', 'AZURE_DEVOPS', 'CIRCLE_CI', 'TRAVIS_CI']),
  body('repository').isLength({ min: 1, max: 500 }),
  body('config').isObject()
];

// Get all pipelines with pagination and filtering
router.get('/', authenticateToken, [
  query('page').optional().isInt({ min: 1 }).toInt(),
  query('limit').optional().isInt({ min: 1, max: 100 }).toInt(),
  query('type').optional().isIn(['GITHUB_ACTIONS', 'GITLAB_CI', 'JENKINS', 'AZURE_DEVOPS', 'CIRCLE_CI', 'TRAVIS_CI']),
  query('status').optional().isIn(['SUCCESS', 'FAILED', 'RUNNING', 'PENDING', 'UNKNOWN', 'DISABLED']),
  query('search').optional().isString()
], async (req: Request, res: Response) => {
  try {
    const errors = validationResult(req);
    if (!errors.isEmpty()) {
      throw validationError(errors.array()[0].msg);
    }

    const page = parseInt(req.query.page as string) || 1;
    const limit = parseInt(req.query.limit as string) || 20;
    const skip = (page - 1) * limit;
    const type = req.query.type as string;
    const status = req.query.status as string;
    const search = req.query.search as string;

    // Build where clause
    const where: any = {};
    if (type) where.type = type;
    if (status) where.status = status;
    if (search) {
      where.OR = [
        { name: { contains: search, mode: 'insensitive' } },
        { repository: { contains: search, mode: 'insensitive' } }
      ];
    }

    // Get pipelines with metrics
    const [pipelines, total] = await Promise.all([
      prisma.pipeline.findMany({
        where,
        skip,
        take: limit,
        orderBy: { updatedAt: 'desc' },
        include: {
          _count: {
            select: { builds: true }
          },
          builds: {
            take: 1,
            orderBy: { createdAt: 'desc' },
            select: {
              id: true,
              status: true,
              duration: true,
              createdAt: true
            }
          }
        }
      }),
      prisma.pipeline.count({ where })
    ]);

    // Calculate metrics for each pipeline
    const pipelinesWithMetrics = await Promise.all(
      pipelines.map(async (pipeline) => {
        const metrics = await prisma.metric.findMany({
          where: { pipelineId: pipeline.id },
          orderBy: { timestamp: 'desc' },
          take: 1
        });

        const successRate = metrics.find(m => m.metricType === 'SUCCESS_RATE')?.value || 0;
        const avgBuildTime = metrics.find(m => m.metricType === 'BUILD_TIME')?.value || 0;

        return {
          id: pipeline.id,
          name: pipeline.name,
          type: pipeline.type,
          repository: pipeline.repository,
          status: pipeline.status,
          lastBuild: pipeline.builds[0] || null,
          metrics: {
            successRate: Number(successRate),
            avgBuildTime: Number(avgBuildTime),
            totalBuilds: pipeline._count.builds
          },
          createdAt: pipeline.createdAt,
          updatedAt: pipeline.updatedAt
        };
      })
    );

    res.json({
      success: true,
      data: {
        pipelines: pipelinesWithMetrics,
        pagination: {
          page,
          limit,
          total,
          pages: Math.ceil(total / limit)
        }
      }
    });
  } catch (error) {
    res.status(error.statusCode || 500).json({
      success: false,
      error: { message: error.message }
    });
  }
});

// Get pipeline by ID
router.get('/:id', authenticateToken, async (req: Request, res: Response) => {
  try {
    const { id } = req.params;

    const pipeline = await prisma.pipeline.findUnique({
      where: { id },
      include: {
        builds: {
          take: 10,
          orderBy: { createdAt: 'desc' },
          select: {
            id: true,
            status: true,
            duration: true,
            commitHash: true,
            branch: true,
            triggerType: true,
            startTime: true,
            endTime: true,
            createdAt: true
          }
        },
        metrics: {
          orderBy: { timestamp: 'desc' },
          take: 100
        }
      }
    });

    if (!pipeline) {
      throw notFoundError('Pipeline');
    }

    res.json({
      success: true,
      data: pipeline
    });
  } catch (error) {
    res.status(error.statusCode || 500).json({
      success: false,
      error: { message: error.message }
    });
  }
});

// Create new pipeline
router.post('/', authenticateToken, requireUser, validatePipeline, async (req: AuthenticatedRequest, res: Response) => {
  try {
    const errors = validationResult(req);
    if (!errors.isEmpty()) {
      throw validationError(errors.array()[0].msg);
    }

    const { name, type, repository, config } = req.body;

    // Check if pipeline with same name already exists
    const existingPipeline = await prisma.pipeline.findFirst({
      where: { name }
    });

    if (existingPipeline) {
      throw createError('Pipeline with this name already exists', 409);
    }

    const pipeline = await prisma.pipeline.create({
      data: {
        name,
        type,
        repository,
        config,
        status: 'UNKNOWN'
      }
    });

    logger.info(`New pipeline created: ${pipeline.name} by user ${req.user?.email}`);

    res.status(201).json({
      success: true,
      message: 'Pipeline created successfully',
      data: pipeline
    });
  } catch (error) {
    res.status(error.statusCode || 500).json({
      success: false,
      error: { message: error.message }
    });
  }
});

// Update pipeline
router.put('/:id', authenticateToken, requireUser, validatePipeline, async (req: AuthenticatedRequest, res: Response) => {
  try {
    const errors = validationResult(req);
    if (!errors.isEmpty()) {
      throw validationError(errors.array()[0].msg);
    }

    const { id } = req.params;
    const { name, type, repository, config } = req.body;

    // Check if pipeline exists
    const existingPipeline = await prisma.pipeline.findUnique({
      where: { id }
    });

    if (!existingPipeline) {
      throw notFoundError('Pipeline');
    }

    // Check if name is being changed and if it conflicts
    if (name !== existingPipeline.name) {
      const nameConflict = await prisma.pipeline.findFirst({
        where: { name, id: { not: id } }
      });

      if (nameConflict) {
        throw createError('Pipeline with this name already exists', 409);
      }
    }

    const updatedPipeline = await prisma.pipeline.update({
      where: { id },
      data: {
        name,
        type,
        repository,
        config,
        updatedAt: new Date()
      }
    });

    logger.info(`Pipeline updated: ${updatedPipeline.name} by user ${req.user?.email}`);

    res.json({
      success: true,
      message: 'Pipeline updated successfully',
      data: updatedPipeline
    });
  } catch (error) {
    res.status(error.statusCode || 500).json({
      success: false,
      error: { message: error.message }
    });
  }
});

// Delete pipeline
router.delete('/:id', authenticateToken, requireUser, async (req: AuthenticatedRequest, res: Response) => {
  try {
    const { id } = req.params;

    const pipeline = await prisma.pipeline.findUnique({
      where: { id }
    });

    if (!pipeline) {
      throw notFoundError('Pipeline');
    }

    // Delete pipeline (cascades to builds, stages, metrics, and alerts)
    await prisma.pipeline.delete({
      where: { id }
    });

    logger.info(`Pipeline deleted: ${pipeline.name} by user ${req.user?.email}`);

    res.json({
      success: true,
      message: 'Pipeline deleted successfully'
    });
  } catch (error) {
    res.status(error.statusCode || 500).json({
      success: false,
      error: { message: error.message }
    });
  }
});

// Get pipeline metrics
router.get('/:id/metrics', authenticateToken, [
  query('period').optional().isIn(['HOURLY', 'DAILY', 'WEEKLY', 'MONTHLY']),
  query('limit').optional().isInt({ min: 1, max: 1000 }).toInt()
], async (req: Request, res: Response) => {
  try {
    const errors = validationResult(req);
    if (!errors.isEmpty()) {
      throw validationError(errors.array()[0].msg);
    }

    const { id } = req.params;
    const period = req.query.period as string || 'DAILY';
    const limit = parseInt(req.query.limit as string) || 30;

    // Check if pipeline exists
    const pipeline = await prisma.pipeline.findUnique({
      where: { id }
    });

    if (!pipeline) {
      throw notFoundError('Pipeline');
    }

    const metrics = await prisma.metric.findMany({
      where: {
        pipelineId: id,
        period
      },
      orderBy: { timestamp: 'desc' },
      take: limit
    });

    res.json({
      success: true,
      data: {
        pipelineId: id,
        period,
        metrics
      }
    });
  } catch (error) {
    res.status(error.statusCode || 500).json({
      success: false,
      error: { message: error.message }
    });
  }
});

// Test pipeline connection
router.post('/:id/test', authenticateToken, requireUser, async (req: AuthenticatedRequest, res: Response) => {
  try {
    const { id } = req.params;

    const pipeline = await prisma.pipeline.findUnique({
      where: { id }
    });

    if (!pipeline) {
      throw notFoundError('Pipeline');
    }

    // This would typically test the connection to the external CI/CD system
    // For now, we'll simulate a successful test
    logger.info(`Pipeline connection tested: ${pipeline.name} by user ${req.user?.email}`);

    res.json({
      success: true,
      message: 'Pipeline connection test successful',
      data: {
        status: 'connected',
        lastChecked: new Date().toISOString()
      }
    });
  } catch (error) {
    res.status(error.statusCode || 500).json({
      success: false,
      error: { message: error.message }
    });
  }
});

export { router as pipelineRoutes };
```

Now let me create the remaining route files and services. Let me continue with the builds route:


```typescript
import { Router, Request, Response } from 'express';
import { query, validationResult } from 'express-validator';
import { prisma } from '../utils/database';
import { authenticateToken, AuthenticatedRequest } from '../middleware/auth';
import { createError, validationError, notFoundError } from '../middleware/errorHandler';
import { logger } from '../utils/logger';
import { processWebhook } from '../services/webhookProcessor';

const router = Router();

// Get all builds with pagination and filtering
router.get('/', authenticateToken, [
  query('page').optional().isInt({ min: 1 }).toInt(),
  query('limit').optional().isInt({ min: 1, max: 100 }).toInt(),
  query('pipelineId').optional().isString(),
  query('status').optional().isIn(['PENDING', 'RUNNING', 'SUCCESS', 'FAILED', 'CANCELLED', 'SKIPPED']),
  query('branch').optional().isString(),
  query('triggerType').optional().isIn(['PUSH', 'PULL_REQUEST', 'MANUAL', 'SCHEDULED', 'WEBHOOK'])
], async (req: Request, res: Response) => {
  try {
    const errors = validationResult(req);
    if (!errors.isEmpty()) {
      throw validationError(errors.array()[0].msg);
    }

    const page = parseInt(req.query.page as string) || 1;
    const limit = parseInt(req.query.limit as string) || 20;
    const skip = (page - 1) * limit;
    const pipelineId = req.query.pipelineId as string;
    const status = req.query.status as string;
    const branch = req.query.branch as string;
    const triggerType = req.query.triggerType as string;

    // Build where clause
    const where: any = {};
    if (pipelineId) where.pipelineId = pipelineId;
    if (status) where.status = status;
    if (branch) where.branch = { contains: branch, mode: 'insensitive' };
    if (triggerType) where.triggerType = triggerType;

    // Get builds with pipeline info
    const [builds, total] = await Promise.all([
      prisma.build.findMany({
        where,
        skip,
        take: limit,
        orderBy: { createdAt: 'desc' },
        include: {
          pipeline: {
            select: {
              id: true,
              name: true,
              type: true,
              repository: true
            }
          },
          stages: {
            select: {
              id: true,
              name: true,
              status: true,
              duration: true
            }
          }
        }
      }),
      prisma.build.count({ where })
    ]);

    res.json({
      success: true,
      data: {
        builds,
        pagination: {
          page,
          limit,
          total,
          pages: Math.ceil(total / limit)
        }
      }
    });
  } catch (error) {
    res.status(error.statusCode || 500).json({
      success: false,
      error: { message: error.message }
    });
  }
});

// Get build by ID
router.get('/:id', authenticateToken, async (req: Request, res: Response) => {
  try {
    const { id } = req.params;

    const build = await prisma.build.findUnique({
      where: { id },
      include: {
        pipeline: {
          select: {
            id: true,
            name: true,
            type: true,
            repository: true
          }
        },
        stages: {
          orderBy: { createdAt: 'asc' }
        }
      }
    });

    if (!build) {
      throw notFoundError('Build');
    }

    res.json({
      success: true,
      data: build
    });
  } catch (error) {
    res.status(error.statusCode || 500).json({
      success: false,
      error: { message: error.message }
    });
  }
});

// Get build logs
router.get('/:id/logs', authenticateToken, async (req: Request, res: Response) => {
  try {
    const { id } = req.params;

    const build = await prisma.build.findUnique({
      where: { id },
      include: {
        stages: {
          select: {
            name: true,
            logs: true,
            status: true,
            duration: true
          }
        }
      }
    });

    if (!build) {
      throw notFoundError('Build');
    }

    res.json({
      success: true,
      data: {
        buildId: id,
        stages: build.stages
      }
    });
  } catch (error) {
    res.status(error.statusCode || 500).json({
      success: false,
      error: { message: error.message }
    });
  }
});

// Webhook endpoint for receiving build updates
router.post('/webhook', async (req: Request, res: Response) => {
  try {
    const webhookData = req.body;
    
    logger.info('Webhook received', {
      source: webhookData.source || 'unknown',
      event: webhookData.event || 'unknown'
    });

    // Process the webhook asynchronously
    processWebhook(webhookData).catch(error => {
      logger.error('Error processing webhook:', error);
    });

    // Always respond quickly to webhook sender
    res.status(200).json({
      success: true,
      message: 'Webhook received and queued for processing'
    });
  } catch (error) {
    logger.error('Error handling webhook:', error);
    res.status(500).json({
      success: false,
      error: { message: 'Internal server error' }
    });
  }
});

// Manual build trigger
router.post('/:pipelineId/trigger', authenticateToken, async (req: AuthenticatedRequest, res: Response) => {
  try {
    const { pipelineId } = req.params;
    const { branch = 'main', commitHash, triggerType = 'MANUAL' } = req.body;

    // Check if pipeline exists
    const pipeline = await prisma.pipeline.findUnique({
      where: { id: pipelineId }
    });

    if (!pipeline) {
      throw notFoundError('Pipeline');
    }

    // Create a new build record
    const build = await prisma.build.create({
      data: {
        pipelineId,
        externalId: `manual-${Date.now()}`,
        status: 'PENDING',
        branch,
        commitHash,
        triggerType,
        metadata: {
          triggeredBy: req.user?.email,
          triggerReason: 'Manual trigger'
        }
      }
    });

    logger.info(`Manual build triggered: ${build.id} for pipeline ${pipeline.name} by user ${req.user?.email}`);

    // In a real implementation, this would trigger the actual CI/CD pipeline
    // For now, we'll simulate the build process
    setTimeout(async () => {
      try {
        await prisma.build.update({
          where: { id: build.id },
          data: {
            status: 'RUNNING',
            startTime: new Date()
          }
        });

        // Simulate build completion after 30 seconds
        setTimeout(async () => {
          try {
            await prisma.build.update({
              where: { id: build.id },
              data: {
                status: 'SUCCESS',
                endTime: new Date(),
                duration: 30
              }
            });

            // Update pipeline status
            await prisma.pipeline.update({
              where: { id: pipelineId },
              data: {
                status: 'SUCCESS',
                lastBuildId: build.id
              }
            });

            logger.info(`Build completed: ${build.id} - SUCCESS`);
          } catch (error) {
            logger.error('Error updating build status:', error);
          }
        }, 30000);
      } catch (error) {
        logger.error('Error starting build:', error);
      }
    }, 2000);

    res.status(201).json({
      success: true,
      message: 'Build triggered successfully',
      data: {
        buildId: build.id,
        status: 'PENDING'
      }
    });
  } catch (error) {
    res.status(error.statusCode || 500).json({
      success: false,
      error: { message: error.message }
    });
  }
});

// Cancel build
router.post('/:id/cancel', authenticateToken, async (req: AuthenticatedRequest, res: Response) => {
  try {
    const { id } = req.params;

    const build = await prisma.build.findUnique({
      where: { id },
      include: {
        pipeline: {
          select: { name: true }
        }
      }
    });

    if (!build) {
      throw notFoundError('Build');
    }

    if (build.status !== 'RUNNING' && build.status !== 'PENDING') {
      throw createError('Only running or pending builds can be cancelled', 400);
    }

    // Update build status
    const updatedBuild = await prisma.build.update({
      where: { id },
      data: {
        status: 'CANCELLED',
        endTime: new Date()
      }
    });

    logger.info(`Build cancelled: ${id} by user ${req.user?.email}`);

    res.json({
      success: true,
      message: 'Build cancelled successfully',
      data: updatedBuild
    });
  } catch (error) {
    res.status(error.statusCode || 500).json({
      success: false,
      error: { message: error.message }
    });
  }
});

export { router as buildRoutes };
```

Now let me create the remaining route files and services. Let me continue with the metrics and alerts routes:


```typescript
import { Router, Request, Response } from 'express';
import { query, validationResult } from 'express-validator';
import { prisma } from '../utils/database';
import { authenticateToken } from '../middleware/auth';
import { validationError } from '../middleware/errorHandler';
import { logger } from '../utils/logger';

const router = Router();

// Get dashboard overview metrics
router.get('/overview', authenticateToken, async (req: Request, res: Response) => {
  try {
    // Get overall statistics
    const [
      totalPipelines,
      totalBuilds,
      runningBuilds,
      failedBuilds,
      successBuilds
    ] = await Promise.all([
      prisma.pipeline.count(),
      prisma.build.count(),
      prisma.build.count({ where: { status: 'RUNNING' } }),
      prisma.build.count({ where: { status: 'FAILED' } }),
      prisma.build.count({ where: { status: 'SUCCESS' } })
    ]);

    // Calculate success rate
    const successRate = totalBuilds > 0 ? (successBuilds / totalBuilds) * 100 : 0;

    // Get recent builds for timeline
    const recentBuilds = await prisma.build.findMany({
      take: 10,
      orderBy: { createdAt: 'desc' },
      include: {
        pipeline: {
          select: {
            id: true,
            name: true,
            type: true
          }
        }
      }
    });

    // Get pipeline status distribution
    const pipelineStatuses = await prisma.pipeline.groupBy({
      by: ['status'],
      _count: {
        status: true
      }
    });

    // Get build time statistics
    const buildTimeStats = await prisma.build.aggregate({
      where: {
        duration: { not: null },
        status: { in: ['SUCCESS', 'FAILED'] }
      },
      _avg: {
        duration: true
      },
      _min: {
        duration: true
      },
      _max: {
        duration: true
      }
    });

    res.json({
      success: true,
      data: {
        summary: {
          totalPipelines,
          totalBuilds,
          runningBuilds,
          failedBuilds,
          successBuilds,
          successRate: Math.round(successRate * 100) / 100
        },
        pipelineStatuses: pipelineStatuses.map(ps => ({
          status: ps.status,
          count: ps._count.status
        })),
        buildTimeStats: {
          average: Math.round(buildTimeStats._avg.duration || 0),
          minimum: buildTimeStats._min.duration || 0,
          maximum: buildTimeStats._max.duration || 0
        },
        recentBuilds
      }
    });
  } catch (error) {
    logger.error('Error getting overview metrics:', error);
    res.status(500).json({
      success: false,
      error: { message: 'Failed to get overview metrics' }
    });
  }
});

// Get success rate trends
router.get('/success-rate', authenticateToken, [
  query('pipelineId').optional().isString(),
  query('period').optional().isIn(['HOURLY', 'DAILY', 'WEEKLY', 'MONTHLY']),
  query('limit').optional().isInt({ min: 1, max: 1000 }).toInt()
], async (req: Request, res: Response) => {
  try {
    const errors = validationResult(req);
    if (!errors.isEmpty()) {
      throw validationError(errors.array()[0].msg);
    }

    const pipelineId = req.query.pipelineId as string;
    const period = req.query.period as string || 'DAILY';
    const limit = parseInt(req.query.limit as string) || 30;

    const where: any = {
      metricType: 'SUCCESS_RATE'
    };
    if (pipelineId) where.pipelineId = pipelineId;

    const metrics = await prisma.metric.findMany({
      where,
      orderBy: { timestamp: 'desc' },
      take: limit,
      include: {
        pipeline: {
          select: {
            name: true,
            type: true
          }
        }
      }
    });

    res.json({
      success: true,
      data: {
        period,
        metrics: metrics.reverse() // Return in chronological order
      }
    });
  } catch (error) {
    res.status(error.statusCode || 500).json({
      success: false,
      error: { message: error.message }
    });
  }
});

// Get build time analytics
router.get('/build-times', authenticateToken, [
  query('pipelineId').optional().isString(),
  query('period').optional().isIn(['HOURLY', 'DAILY', 'WEEKLY', 'MONTHLY']),
  query('limit').optional().isInt({ min: 1, max: 1000 }).toInt()
], async (req: Request, res: Response) => {
  try {
    const errors = validationResult(req);
    if (!errors.isEmpty()) {
      throw validationError(errors.array()[0].msg);
    }

    const pipelineId = req.query.pipelineId as string;
    const period = req.query.period as string || 'DAILY';
    const limit = parseInt(req.query.limit as string) || 30;

    const where: any = {
      metricType: 'BUILD_TIME'
    };
    if (pipelineId) where.pipelineId = pipelineId;

    const metrics = await prisma.metric.findMany({
      where,
      orderBy: { timestamp: 'desc' },
      take: limit,
      include: {
        pipeline: {
          select: {
            name: true,
            type: true
          }
        }
      }
    });

    // Also get actual build duration data for comparison
    const buildWhere: any = {
      duration: { not: null },
      status: { in: ['SUCCESS', 'FAILED'] }
    };
    if (pipelineId) buildWhere.pipelineId = pipelineId;

    const buildDurations = await prisma.build.findMany({
      where: buildWhere,
      select: {
        duration: true,
        createdAt: true,
        status: true
      },
      orderBy: { createdAt: 'desc' },
      take: 100
    });

    res.json({
      success: true,
      data: {
        period,
        metrics: metrics.reverse(),
        buildDurations
      }
    });
  } catch (error) {
    res.status(error.statusCode || 500).json({
      success: false,
      error: { message: error.message }
    });
  }
});

// Get failure analysis
router.get('/failures', authenticateToken, [
  query('pipelineId').optional().isString(),
  query('limit').optional().isInt({ min: 1, max: 100 }).toInt()
], async (req: Request, res: Response) => {
  try {
    const errors = validationResult(req);
    if (!errors.isEmpty()) {
      throw validationError(errors.array()[0].msg);
    }

    const pipelineId = req.query.pipelineId as string;
    const limit = parseInt(req.query.limit as string) || 20;

    const where: any = {
      status: 'FAILED'
    };
    if (pipelineId) where.pipelineId = pipelineId;

    const failedBuilds = await prisma.build.findMany({
      where,
      orderBy: { createdAt: 'desc' },
      take: limit,
      include: {
        pipeline: {
          select: {
            name: true,
            type: true
          }
        },
        stages: {
          where: { status: 'FAILED' },
          select: {
            name: true,
            logs: true
          }
        }
      }
    });

    // Get failure patterns by stage
    const stageFailures = await prisma.buildStage.groupBy({
      by: ['name'],
      where: { status: 'FAILED' },
      _count: {
        name: true
      },
      orderBy: {
        _count: {
          name: 'desc'
        }
      },
      take: 10
    });

    res.json({
      success: true,
      data: {
        failedBuilds,
        stageFailures: stageFailures.map(sf => ({
          stageName: sf.name,
          failureCount: sf._count.name
        }))
      }
    });
  } catch (error) {
    res.status(error.statusCode || 500).json({
      success: false,
      error: { message: error.message }
    });
  }
});

// Get pipeline performance comparison
router.get('/pipeline-comparison', authenticateToken, async (req: Request, res: Response) => {
  try {
    const pipelines = await prisma.pipeline.findMany({
      include: {
        _count: {
          select: { builds: true }
        },
        builds: {
          where: {
            status: { in: ['SUCCESS', 'FAILED'] },
            duration: { not: null }
          },
          select: {
            status: true,
            duration: true
          }
        }
      }
    });

    const comparison = pipelines.map(pipeline => {
      const totalBuilds = pipeline._count.builds;
      const successfulBuilds = pipeline.builds.filter(b => b.status === 'SUCCESS').length;
      const successRate = totalBuilds > 0 ? (successfulBuilds / totalBuilds) * 100 : 0;
      
      const durations = pipeline.builds.map(b => b.duration!).filter(d => d > 0);
      const avgDuration = durations.length > 0 
        ? durations.reduce((sum, d) => sum + d, 0) / durations.length 
        : 0;

      return {
        id: pipeline.id,
        name: pipeline.name,
        type: pipeline.type,
        repository: pipeline.repository,
        totalBuilds,
        successRate: Math.round(successRate * 100) / 100,
        averageBuildTime: Math.round(avgDuration),
        lastStatus: pipeline.status
      };
    });

    // Sort by success rate descending
    comparison.sort((a, b) => b.successRate - a.successRate);

    res.json({
      success: true,
      data: comparison
    });
  } catch (error) {
    logger.error('Error getting pipeline comparison:', error);
    res.status(500).json({
      success: false,
      error: { message: 'Failed to get pipeline comparison' }
    });
  }
});

// Get real-time metrics
router.get('/realtime', authenticateToken, async (req: Request, res: Response) => {
  try {
    // Get current running builds
    const runningBuilds = await prisma.build.findMany({
      where: { status: 'RUNNING' },
      include: {
        pipeline: {
          select: {
            name: true,
            type: true
          }
        }
      },
      orderBy: { startTime: 'asc' }
    });

    // Get recent activity (last 10 builds)
    const recentActivity = await prisma.build.findMany({
      take: 10,
      orderBy: { createdAt: 'desc' },
      include: {
        pipeline: {
          select: {
            name: true,
            type: true
          }
        }
      }
    });

    // Get queue length (pending builds)
    const queueLength = await prisma.build.count({
      where: { status: 'PENDING' }
    });

    res.json({
      success: true,
      data: {
        runningBuilds,
        recentActivity,
        queueLength,
        lastUpdated: new Date().toISOString()
      }
    });
  } catch (error) {
    logger.error('Error getting real-time metrics:', error);
    res.status(500).json({
      success: false,
      error: { message: 'Failed to get real-time metrics' }
    });
  }
});

export { router as metricsRoutes };
```

Now let me create the remaining route files and services. Let me continue with the alerts and health routes:


```typescript
import { Router, Request, Response } from 'express';
import { body, validationResult, query } from 'express-validator';
import { prisma } from '../utils/database';
import { authenticateToken, requireUser, AuthenticatedRequest } from '../middleware/auth';
import { createError, validationError, notFoundError } from '../middleware/errorHandler';
import { logger } from '../utils/logger';
import { sendNotification } from '../services/notificationService';

const router = Router();

// Validation middleware
const validateAlert = [
  body('name').isLength({ min: 1, max: 255 }),
  body('conditionType').isIn(['FAILURE', 'BUILD_TIME', 'SUCCESS_RATE', 'QUEUE_LENGTH', 'PIPELINE_DOWN']),
  body('threshold').isNumeric(),
  body('notificationChannels').isObject(),
  body('pipelineId').optional().isString()
];

// Get all alerts
router.get('/', authenticateToken, [
  query('pipelineId').optional().isString(),
  query('isActive').optional().isBoolean()
], async (req: Request, res: Response) => {
  try {
    const errors = validationResult(req);
    if (!errors.isEmpty()) {
      throw validationError(errors.array()[0].msg);
    }

    const pipelineId = req.query.pipelineId as string;
    const isActive = req.query.isActive as string;

    const where: any = {};
    if (pipelineId) where.pipelineId = pipelineId;
    if (isActive !== undefined) where.isActive = isActive === 'true';

    const alerts = await prisma.alert.findMany({
      where,
      include: {
        pipeline: {
          select: {
            id: true,
            name: true,
            type: true
          }
        },
        user: {
          select: {
            username: true,
            email: true
          }
        }
      },
      orderBy: { createdAt: 'desc' }
    });

    res.json({
      success: true,
      data: alerts
    });
  } catch (error) {
    res.status(error.statusCode || 500).json({
      success: false,
      error: { message: error.message }
    });
  }
});

// Get alert by ID
router.get('/:id', authenticateToken, async (req: Request, res: Response) => {
  try {
    const { id } = req.params;

    const alert = await prisma.alert.findUnique({
      where: { id },
      include: {
        pipeline: {
          select: {
            id: true,
            name: true,
            type: true
          }
        },
        user: {
          select: {
            username: true,
            email: true
          }
        },
        alertHistory: {
          take: 10,
          orderBy: { sentAt: 'desc' }
        }
      }
    });

    if (!alert) {
      throw notFoundError('Alert');
    }

    res.json({
      success: true,
      data: alert
    });
  } catch (error) {
    res.status(error.statusCode || 500).json({
      success: false,
      error: { message: error.message }
    });
  }
});

// Create new alert
router.post('/', authenticateToken, requireUser, validateAlert, async (req: AuthenticatedRequest, res: Response) => {
  try {
    const errors = validationResult(req);
    if (!errors.isEmpty()) {
      throw validationError(errors.array()[0].msg);
    }

    const { name, conditionType, threshold, notificationChannels, pipelineId } = req.body;

    // Check if pipeline exists if specified
    if (pipelineId) {
      const pipeline = await prisma.pipeline.findUnique({
        where: { id: pipelineId }
      });

      if (!pipeline) {
        throw notFoundError('Pipeline');
      }
    }

    const alert = await prisma.alert.create({
      data: {
        name,
        conditionType,
        threshold,
        notificationChannels,
        pipelineId,
        createdBy: req.user!.id
      },
      include: {
        pipeline: {
          select: {
            name: true
          }
        }
      }
    });

    logger.info(`New alert created: ${alert.name} by user ${req.user?.email}`);

    res.status(201).json({
      success: true,
      message: 'Alert created successfully',
      data: alert
    });
  } catch (error) {
    res.status(error.statusCode || 500).json({
      success: false,
      error: { message: error.message }
    });
  }
});

// Update alert
router.put('/:id', authenticateToken, requireUser, validateAlert, async (req: AuthenticatedRequest, res: Response) => {
  try {
    const errors = validationResult(req);
    if (!errors.isEmpty()) {
      throw validationError(errors.array()[0].msg);
    }

    const { id } = req.params;
    const { name, conditionType, threshold, notificationChannels, pipelineId, isActive } = req.body;

    // Check if alert exists
    const existingAlert = await prisma.alert.findUnique({
      where: { id }
    });

    if (!existingAlert) {
      throw notFoundError('Alert');
    }

    // Check if pipeline exists if specified
    if (pipelineId) {
      const pipeline = await prisma.pipeline.findUnique({
        where: { id: pipelineId }
      });

      if (!pipeline) {
        throw notFoundError('Pipeline');
      }
    }

    const updatedAlert = await prisma.alert.update({
      where: { id },
      data: {
        name,
        conditionType,
        threshold,
        notificationChannels,
        pipelineId,
        isActive,
        updatedAt: new Date()
      },
      include: {
        pipeline: {
          select: {
            name: true
          }
        }
      }
    });

    logger.info(`Alert updated: ${updatedAlert.name} by user ${req.user?.email}`);

    res.json({
      success: true,
      message: 'Alert updated successfully',
      data: updatedAlert
    });
  } catch (error) {
    res.status(error.statusCode || 500).json({
      success: false,
      error: { message: error.message }
    });
  }
});

// Delete alert
router.delete('/:id', authenticateToken, requireUser, async (req: AuthenticatedRequest, res: Response) => {
  try {
    const { id } = req.params;

    const alert = await prisma.alert.findUnique({
      where: { id }
    });

    if (!alert) {
      throw notFoundError('Alert');
    }

    // Delete alert (cascades to alert history)
    await prisma.alert.delete({
      where: { id }
    });

    logger.info(`Alert deleted: ${alert.name} by user ${req.user?.email}`);

    res.json({
      success: true,
      message: 'Alert deleted successfully'
    });
  } catch (error) {
    res.status(error.statusCode || 500).json({
      success: false,
      error: { message: error.message }
    });
  }
});

// Test notification
router.post('/test', authenticateToken, requireUser, [
  body('notificationChannels').isObject()
], async (req: AuthenticatedRequest, res: Response) => {
  try {
    const errors = validationResult(req);
    if (!errors.isEmpty()) {
      throw validationError(errors.array()[0].msg);
    }

    const { notificationChannels } = req.body;

    // Send test notification
    const result = await sendNotification({
      message: 'This is a test notification from the CI/CD Pipeline Health Dashboard',
      severity: 'INFO',
      channels: notificationChannels,
      metadata: {
        test: true,
        timestamp: new Date().toISOString()
      }
    });

    logger.info(`Test notification sent by user ${req.user?.email}`);

    res.json({
      success: true,
      message: 'Test notification sent successfully',
      data: result
    });
  } catch (error) {
    res.status(error.statusCode || 500).json({
      success: false,
      error: { message: error.message }
    });
  }
});

// Toggle alert status
router.patch('/:id/toggle', authenticateToken, requireUser, async (req: AuthenticatedRequest, res: Response) => {
  try {
    const { id } = req.params;

    const alert = await prisma.alert.findUnique({
      where: { id }
    });

    if (!alert) {
      throw notFoundError('Alert');
    }

    const updatedAlert = await prisma.alert.update({
      where: { id },
      data: {
        isActive: !alert.isActive,
        updatedAt: new Date()
      }
    });

    const status = updatedAlert.isActive ? 'enabled' : 'disabled';
    logger.info(`Alert ${status}: ${updatedAlert.name} by user ${req.user?.email}`);

    res.json({
      success: true,
      message: `Alert ${status} successfully`,
      data: updatedAlert
    });
  } catch (error) {
    res.status(error.statusCode || 500).json({
      success: false,
      error: { message: error.message }
    });
  }
});

// Get alert history
router.get('/:id/history', authenticateToken, [
  query('page').optional().isInt({ min: 1 }).toInt(),
  query('limit').optional().isInt({ min: 1, max: 100 }).toInt()
], async (req: Request, res: Response) => {
  try {
    const errors = validationResult(req);
    if (!errors.isEmpty()) {
      throw validationError(errors.array()[0].msg);
    }

    const { id } = req.params;
    const page = parseInt(req.query.page as string) || 1;
    const limit = parseInt(req.query.limit as string) || 20;
    const skip = (page - 1) * limit;

    // Check if alert exists
    const alert = await prisma.alert.findUnique({
      where: { id }
    });

    if (!alert) {
      throw notFoundError('Alert');
    }

    const [history, total] = await Promise.all([
      prisma.alertHistory.findMany({
        where: { alertId: id },
        skip,
        take: limit,
        orderBy: { sentAt: 'desc' },
        include: {
          build: {
            select: {
              id: true,
              status: true,
              pipeline: {
                select: {
                  name: true
                }
              }
            }
          }
        }
      }),
      prisma.alertHistory.count({
        where: { alertId: id }
      })
    ]);

    res.json({
      success: true,
      data: {
        alertId: id,
        history,
        pagination: {
          page,
          limit,
          total,
          pages: Math.ceil(total / limit)
        }
      }
    });
  } catch (error) {
    res.status(error.statusCode || 500).json({
      success: false,
      error: { message: error.message }
    });
  }
});

export { router as alertRoutes };
```

Now let me create the health route and the remaining service files:


```typescript
import { Router, Request, Response } from 'express';
import { prisma } from '../utils/database';
import { logger } from '../utils/logger';

const router = Router();

// Basic health check
router.get('/', async (req: Request, res: Response) => {
  try {
    res.json({
      success: true,
      status: 'healthy',
      timestamp: new Date().toISOString(),
      uptime: process.uptime(),
      environment: process.env.NODE_ENV || 'development'
    });
  } catch (error) {
    logger.error('Health check failed:', error);
    res.status(500).json({
      success: false,
      status: 'unhealthy',
      error: { message: 'Health check failed' }
    });
  }
});

// Detailed health check
router.get('/detailed', async (req: Request, res: Response) => {
  try {
    const startTime = Date.now();
    
    // Check database connectivity
    let dbStatus = 'unknown';
    let dbResponseTime = 0;
    
    try {
      const dbStartTime = Date.now();
      await prisma.$queryRaw`SELECT 1`;
      dbResponseTime = Date.now() - dbStartTime;
      dbStatus = 'healthy';
    } catch (error) {
      dbStatus = 'unhealthy';
      logger.error('Database health check failed:', error);
    }

    // Check memory usage
    const memoryUsage = process.memoryUsage();
    const memoryStatus = memoryUsage.heapUsed / memoryUsage.heapTotal < 0.9 ? 'healthy' : 'warning';

    // Check CPU usage (basic)
    const cpuUsage = process.cpuUsage();
    const cpuStatus = 'healthy'; // Simplified for now

    const totalResponseTime = Date.now() - startTime;

    const healthStatus = {
      overall: dbStatus === 'healthy' && memoryStatus === 'healthy' ? 'healthy' : 'degraded',
      timestamp: new Date().toISOString(),
      uptime: process.uptime(),
      environment: process.env.NODE_ENV || 'development',
      responseTime: totalResponseTime,
      components: {
        database: {
          status: dbStatus,
          responseTime: dbResponseTime
        },
        memory: {
          status: memoryStatus,
          used: Math.round(memoryUsage.heapUsed / 1024 / 1024),
          total: Math.round(memoryUsage.heapTotal / 1024 / 1024),
          external: Math.round(memoryUsage.external / 1024 / 1024)
        },
        cpu: {
          status: cpuStatus,
          user: Math.round(cpuUsage.user / 1000),
          system: Math.round(cpuUsage.system / 1000)
        }
      }
    };

    // Set appropriate status code
    const statusCode = healthStatus.overall === 'healthy' ? 200 : 503;

    res.status(statusCode).json({
      success: true,
      data: healthStatus
    });
  } catch (error) {
    logger.error('Detailed health check failed:', error);
    res.status(500).json({
      success: false,
      status: 'unhealthy',
      error: { message: 'Detailed health check failed' }
    });
  }
});

// Database health check
router.get('/database', async (req: Request, res: Response) => {
  try {
    const startTime = Date.now();
    
    // Test basic query
    await prisma.$queryRaw`SELECT 1`;
    
    // Test connection pool
    const connectionTest = await prisma.$queryRaw`SELECT version()`;
    
    const responseTime = Date.now() - startTime;

    res.json({
      success: true,
      status: 'healthy',
      responseTime,
      timestamp: new Date().toISOString(),
      database: {
        type: 'PostgreSQL',
        version: connectionTest[0]?.version || 'unknown',
        connectionPool: 'active'
      }
    });
  } catch (error) {
    logger.error('Database health check failed:', error);
    res.status(503).json({
      success: false,
      status: 'unhealthy',
      error: { message: 'Database connection failed' }
    });
  }
});

// System resources health check
router.get('/resources', async (req: Request, res: Response) => {
  try {
    const memoryUsage = process.memoryUsage();
    const cpuUsage = process.cpuUsage();
    
    // Calculate memory percentages
    const heapUsedPercent = (memoryUsage.heapUsed / memoryUsage.heapTotal) * 100;
    const externalPercent = (memoryUsage.external / memoryUsage.heapTotal) * 100;

    const resourceStatus = {
      memory: {
        heapUsed: Math.round(memoryUsage.heapUsed / 1024 / 1024),
        heapTotal: Math.round(memoryUsage.heapTotal / 1024 / 1024),
        external: Math.round(memoryUsage.external / 1024 / 1024),
        heapUsedPercent: Math.round(heapUsedPercent * 100) / 100,
        externalPercent: Math.round(externalPercent * 100) / 100,
        status: heapUsedPercent < 80 ? 'healthy' : heapUsedPercent < 90 ? 'warning' : 'critical'
      },
      cpu: {
        user: Math.round(cpuUsage.user / 1000),
        system: Math.round(cpuUsage.system / 1000),
        status: 'healthy' // Simplified for now
      },
      process: {
        pid: process.pid,
        uptime: process.uptime(),
        version: process.version,
        platform: process.platform,
        arch: process.arch
      }
    };

    // Determine overall status
    const overallStatus = resourceStatus.memory.status === 'critical' ? 'critical' : 
                         resourceStatus.memory.status === 'warning' ? 'warning' : 'healthy';

    const statusCode = overallStatus === 'healthy' ? 200 : 
                      overallStatus === 'warning' ? 200 : 503;

    res.status(statusCode).json({
      success: true,
      status: overallStatus,
      timestamp: new Date().toISOString(),
      data: resourceStatus
    });
  } catch (error) {
    logger.error('Resource health check failed:', error);
    res.status(500).json({
      success: false,
      status: 'unhealthy',
      error: { message: 'Resource health check failed' }
    });
  }
});

// Readiness check (for Kubernetes)
router.get('/ready', async (req: Request, res: Response) => {
  try {
    // Check if the application is ready to serve traffic
    const checks = {
      database: false,
      memory: false,
      startup: true // Assuming if this endpoint is reachable, startup is complete
    };

    // Check database
    try {
      await prisma.$queryRaw`SELECT 1`;
      checks.database = true;
    } catch (error) {
      logger.error('Database readiness check failed:', error);
    }

    // Check memory
    const memoryUsage = process.memoryUsage();
    const heapUsedPercent = (memoryUsage.heapUsed / memoryUsage.heapTotal) * 100;
    checks.memory = heapUsedPercent < 95; // Allow up to 95% memory usage

    const isReady = Object.values(checks).every(check => check === true);

    if (isReady) {
      res.json({
        success: true,
        status: 'ready',
        timestamp: new Date().toISOString(),
        checks
      });
    } else {
      res.status(503).json({
        success: false,
        status: 'not_ready',
        timestamp: new Date().toISOString(),
        checks
      });
    }
  } catch (error) {
    logger.error('Readiness check failed:', error);
    res.status(500).json({
      success: false,
      status: 'not_ready',
      error: { message: 'Readiness check failed' }
    });
  }
});

// Liveness check (for Kubernetes)
router.get('/live', async (req: Request, res: Response) => {
  try {
    // Simple check to see if the process is alive
    res.json({
      success: true,
      status: 'alive',
      timestamp: new Date().toISOString(),
      pid: process.pid,
      uptime: process.uptime()
    });
  } catch (error) {
    logger.error('Liveness check failed:', error);
    res.status(500).json({
      success: false,
      status: 'not_alive',
      error: { message: 'Liveness check failed' }
    });
  }
});

export { router as healthRoutes };
```

Now let me create the service files. Let me start with the WebSocket service:


```typescript
import { Server } from 'socket.io';
import { logger } from '../utils/logger';

interface WebSocketClient {
  id: string;
  userId?: string;
  userRole?: string;
  pipelines?: string[];
}

let io: Server;
const connectedClients = new Map<string, WebSocketClient>();

export const setupWebSocket = (socketIO: Server): void => {
  io = socketIO;
  
  io.on('connection', (socket) => {
    logger.info(`WebSocket client connected: ${socket.id}`);
    
    // Store client information
    connectedClients.set(socket.id, {
      id: socket.id
    });

    // Handle authentication
    socket.on('authenticate', (data: { token: string }) => {
      try {
        // In a real implementation, you would verify the JWT token here
        // For now, we'll accept any token
        const client = connectedClients.get(socket.id);
        if (client) {
          client.userId = 'user-' + socket.id; // Simplified for demo
          client.userRole = 'USER';
          logger.info(`WebSocket client authenticated: ${socket.id}`);
        }
      } catch (error) {
        logger.error('WebSocket authentication failed:', error);
      }
    });

    // Handle pipeline subscription
    socket.on('subscribe', (data: { pipelineIds: string[] }) => {
      const client = connectedClients.get(socket.id);
      if (client) {
        client.pipelines = data.pipelineIds;
        socket.join(data.pipelineIds.map(id => `pipeline-${id}`));
        logger.info(`Client ${socket.id} subscribed to pipelines: ${data.pipelineIds.join(', ')}`);
      }
    });

    // Handle pipeline unsubscription
    socket.on('unsubscribe', (data: { pipelineIds: string[] }) => {
      const client = connectedClients.get(socket.id);
      if (client) {
        data.pipelineIds.forEach(id => {
          socket.leave(`pipeline-${id}`);
        });
        logger.info(`Client ${socket.id} unsubscribed from pipelines: ${data.pipelineIds.join(', ')}`);
      }
    });

    // Handle dashboard subscription
    socket.on('subscribe-dashboard', () => {
      socket.join('dashboard');
      logger.info(`Client ${socket.id} subscribed to dashboard updates`);
    });

    // Handle disconnect
    socket.on('disconnect', () => {
      connectedClients.delete(socket.id);
      logger.info(`WebSocket client disconnected: ${socket.id}`);
    });

    // Handle errors
    socket.on('error', (error) => {
      logger.error(`WebSocket error for client ${socket.id}:`, error);
    });
  });

  logger.info('WebSocket service initialized');
};

// Broadcast to all connected clients
export const broadcastToAll = (event: string, data: any): void => {
  if (io) {
    io.emit(event, data);
    logger.debug(`Broadcasted ${event} to all clients`);
  }
};

// Broadcast to specific pipeline subscribers
export const broadcastToPipeline = (pipelineId: string, event: string, data: any): void => {
  if (io) {
    io.to(`pipeline-${pipelineId}`).emit(event, data);
    logger.debug(`Broadcasted ${event} to pipeline ${pipelineId} subscribers`);
  }
};

// Broadcast to dashboard subscribers
export const broadcastToDashboard = (event: string, data: any): void => {
  if (io) {
    io.to('dashboard').emit(event, data);
    logger.debug(`Broadcasted ${event} to dashboard subscribers`);
  }
};

// Send to specific client
export const sendToClient = (clientId: string, event: string, data: any): void => {
  if (io) {
    io.to(clientId).emit(event, data);
    logger.debug(`Sent ${event} to client ${clientId}`);
  }
};

// Broadcast build status update
export const broadcastBuildUpdate = (buildData: any): void => {
  if (io) {
    // Broadcast to dashboard
    broadcastToDashboard('build-update', buildData);
    
    // Broadcast to specific pipeline
    if (buildData.pipelineId) {
      broadcastToPipeline(buildData.pipelineId, 'build-update', buildData);
    }
  }
};

// Broadcast pipeline status update
export const broadcastPipelineUpdate = (pipelineData: any): void => {
  if (io) {
    // Broadcast to dashboard
    broadcastToDashboard('pipeline-update', pipelineData);
    
    // Broadcast to specific pipeline
    if (pipelineData.id) {
      broadcastToPipeline(pipelineData.id, 'pipeline-update', pipelineData);
    }
  }
};

// Broadcast metrics update
export const broadcastMetricsUpdate = (metricsData: any): void => {
  if (io) {
    broadcastToDashboard('metrics-update', metricsData);
  }
};

// Broadcast alert
export const broadcastAlert = (alertData: any): void => {
  if (io) {
    broadcastToDashboard('alert', alertData);
    
    // If alert is pipeline-specific, broadcast to pipeline subscribers
    if (alertData.pipelineId) {
      broadcastToPipeline(alertData.pipelineId, 'alert', alertData);
    }
  }
};

// Get connected clients count
export const getConnectedClientsCount = (): number => {
  return connectedClients.size;
};

// Get connected clients info
export const getConnectedClientsInfo = (): WebSocketClient[] => {
  return Array.from(connectedClients.values());
};

// Check if client is connected
export const isClientConnected = (clientId: string): boolean => {
  return connectedClients.has(clientId);
};
```

Now let me create the remaining service files. Let me continue with the notification service:


```typescript
import { WebClient } from '@slack/web-api';
import nodemailer from 'nodemailer';
import { logger } from '../utils/logger';
import { prisma } from '../utils/database';

interface NotificationChannels {
  slack?: {
    channel: string;
    webhook?: string;
  };
  email?: string[];
  webhook?: string;
}

interface NotificationData {
  message: string;
  severity: 'INFO' | 'WARNING' | 'ERROR' | 'CRITICAL';
  channels: NotificationChannels;
  metadata?: any;
}

interface NotificationResult {
  success: boolean;
  sentChannels: string[];
  failedChannels: string[];
  errors: string[];
}

// Initialize Slack client
const slackClient = process.env.SLACK_BOT_TOKEN ? new WebClient(process.env.SLACK_BOT_TOKEN) : null;

// Initialize email transporter
let emailTransporter: nodemailer.Transporter | null = null;

const initializeEmailTransporter = (): void => {
  if (process.env.SMTP_HOST && process.env.SMTP_USER && process.env.SMTP_PASS) {
    emailTransporter = nodemailer.createTransporter({
      host: process.env.SMTP_HOST,
      port: parseInt(process.env.SMTP_PORT || '587'),
      secure: false, // true for 465, false for other ports
      auth: {
        user: process.env.SMTP_USER,
        pass: process.env.SMTP_PASS
      }
    });
    logger.info('Email transporter initialized');
  } else {
    logger.warn('Email configuration incomplete, email notifications disabled');
  }
};

// Initialize on module load
initializeEmailTransporter();

export const sendNotification = async (data: NotificationData): Promise<NotificationResult> => {
  const result: NotificationResult = {
    success: false,
    sentChannels: [],
    failedChannels: [],
    errors: []
  };

  try {
    const promises: Promise<void>[] = [];

    // Send Slack notification
    if (data.channels.slack && slackClient) {
      promises.push(sendSlackNotification(data, result));
    } else if (data.channels.slack) {
      result.failedChannels.push('slack');
      result.errors.push('Slack client not configured');
    }

    // Send email notification
    if (data.channels.email && emailTransporter) {
      promises.push(sendEmailNotification(data, result));
    } else if (data.channels.email) {
      result.failedChannels.push('email');
      result.errors.push('Email transporter not configured');
    }

    // Send webhook notification
    if (data.channels.webhook) {
      promises.push(sendWebhookNotification(data, result));
    }

    // Wait for all notifications to complete
    await Promise.allSettled(promises);

    // Determine overall success
    result.success = result.sentChannels.length > 0;

    logger.info(`Notification sent: ${result.sentChannels.join(', ')}`, {
      message: data.message,
      severity: data.severity,
      sentChannels: result.sentChannels,
      failedChannels: result.failedChannels
    });

  } catch (error) {
    logger.error('Error sending notification:', error);
    result.errors.push(`General error: ${error instanceof Error ? error.message : 'Unknown error'}`);
  }

  return result;
};

const sendSlackNotification = async (data: NotificationData, result: NotificationResult): Promise<void> => {
  try {
    if (!data.channels.slack || !slackClient) return;

    const channel = data.channels.slack.channel;
    const color = getSeverityColor(data.severity);
    const emoji = getSeverityEmoji(data.severity);

    const message = {
      channel,
      text: `${emoji} ${data.message}`,
      attachments: [
        {
          color,
          fields: [
            {
              title: 'Severity',
              value: data.severity,
              short: true
            },
            {
              title: 'Timestamp',
              value: new Date().toLocaleString(),
              short: true
            }
          ],
          footer: 'CI/CD Pipeline Health Dashboard'
        }
      ]
    };

    if (data.metadata) {
      message.attachments[0].fields.push({
        title: 'Details',
        value: JSON.stringify(data.metadata, null, 2),
        short: false
      });
    }

    await slackClient.chat.postMessage(message);
    result.sentChannels.push('slack');

  } catch (error) {
    logger.error('Slack notification failed:', error);
    result.failedChannels.push('slack');
    result.errors.push(`Slack error: ${error instanceof Error ? error.message : 'Unknown error'}`);
  }
};

const sendEmailNotification = async (data: NotificationData, result: NotificationResult): Promise<void> => {
  try {
    if (!data.channels.email || !emailTransporter) return;

    const subject = `[${data.severity}] CI/CD Pipeline Alert`;
    const htmlContent = `
      <h2>${data.severity} Alert</h2>
      <p><strong>Message:</strong> ${data.message}</p>
      <p><strong>Timestamp:</strong> ${new Date().toLocaleString()}</p>
      ${data.metadata ? `<p><strong>Details:</strong> <pre>${JSON.stringify(data.metadata, null, 2)}</pre></p>` : ''}
      <hr>
      <p><em>This is an automated message from the CI/CD Pipeline Health Dashboard</em></p>
    `;

    const mailOptions = {
      from: process.env.SMTP_FROM || 'noreply@cicd-dashboard.com',
      to: data.channels.email.join(', '),
      subject,
      html: htmlContent
    };

    await emailTransporter.sendMail(mailOptions);
    result.sentChannels.push('email');

  } catch (error) {
    logger.error('Email notification failed:', error);
    result.failedChannels.push('email');
    result.errors.push(`Email error: ${error instanceof Error ? error.message : 'Unknown error'}`);
  }
};

const sendWebhookNotification = async (data: NotificationData, result: NotificationResult): Promise<void> => {
  try {
    if (!data.channels.webhook) return;

    const webhookData = {
      message: data.message,
      severity: data.severity,
      timestamp: new Date().toISOString(),
      metadata: data.metadata || {}
    };

    const response = await fetch(data.channels.webhook, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json'
      },
      body: JSON.stringify(webhookData)
    });

    if (response.ok) {
      result.sentChannels.push('webhook');
    } else {
      throw new Error(`HTTP ${response.status}: ${response.statusText}`);
    }

  } catch (error) {
    logger.error('Webhook notification failed:', error);
    result.failedChannels.push('webhook');
    result.errors.push(`Webhook error: ${error instanceof Error ? error.message : 'Unknown error'}`);
  }
};

const getSeverityColor = (severity: string): string => {
  switch (severity) {
    case 'CRITICAL': return '#FF0000';
    case 'ERROR': return '#FF6B6B';
    case 'WARNING': return '#FFA500';
    case 'INFO': return '#4CAF50';
    default: return '#808080';
  }
};

const getSeverityEmoji = (severity: string): string => {
  switch (severity) {
    case 'CRITICAL': return 'üö®';
    case 'ERROR': return '‚ùå';
    case 'WARNING': return '‚ö†Ô∏è';
    case 'INFO': return '‚ÑπÔ∏è';
    default: return 'üìù';
  }
};

// Send alert notification and log to database
export const sendAlertNotification = async (
  alertId: string,
  message: string,
  severity: string,
  buildId?: string
): Promise<void> => {
  try {
    // Get alert details
    const alert = await prisma.alert.findUnique({
      where: { id: alertId },
      include: {
        pipeline: {
          select: { name: true }
        }
      }
    });

    if (!alert) {
      logger.error(`Alert not found: ${alertId}`);
      return;
    }

    // Send notification
    const notificationData: NotificationData = {
      message: `${alert.name}: ${message}`,
      severity: severity as any,
      channels: alert.notificationChannels as NotificationChannels,
      metadata: {
        alertId,
        alertName: alert.name,
        pipelineName: alert.pipeline?.name,
        buildId,
        timestamp: new Date().toISOString()
      }
    };

    const result = await sendNotification(notificationData);

    // Log to database
    await prisma.alertHistory.create({
      data: {
        alertId,
        buildId,
        message,
        severity: severity as any,
        notificationStatus: result.success ? 'SENT' : 'FAILED'
      }
    });

    logger.info(`Alert notification processed: ${alert.name}`, {
      alertId,
      success: result.success,
      sentChannels: result.sentChannels,
      failedChannels: result.failedChannels
    });

  } catch (error) {
    logger.error('Error sending alert notification:', error);
    
    // Log failed attempt to database
    try {
      await prisma.alertHistory.create({
        data: {
          alertId,
          buildId,
          message,
          severity: severity as any,
          notificationStatus: 'FAILED'
        }
      });
    } catch (dbError) {
      logger.error('Failed to log alert history:', dbError);
    }
  }
};

// Test notification service
export const testNotificationService = async (channels: NotificationChannels): Promise<NotificationResult> => {
  const testData: NotificationData = {
    message: 'This is a test notification from the CI/CD Pipeline Health Dashboard',
    severity: 'INFO',
    channels,
    metadata: {
      test: true,
      timestamp: new Date().toISOString()
    }
  };

  return await sendNotification(testData);
};
```

Now let me create the remaining service files. Let me continue with the webhook processor and other services:


```typescript
import { logger } from '../utils/logger';
import { prisma } from '../utils/database';
import { broadcastBuildUpdate, broadcastPipelineUpdate } from './websocket';

interface WebhookData {
  source: string;
  event: string;
  [key: string]: any;
}

export const processWebhook = async (webhookData: WebhookData): Promise<void> => {
  try {
    logger.info('Processing webhook', {
      source: webhookData.source,
      event: webhookData.event
    });

    switch (webhookData.source) {
      case 'github':
        await processGitHubWebhook(webhookData);
        break;
      case 'gitlab':
        await processGitLabWebhook(webhookData);
        break;
      case 'jenkins':
        await processJenkinsWebhook(webhookData);
        break;
      default:
        logger.warn(`Unknown webhook source: ${webhookData.source}`);
    }
  } catch (error) {
    logger.error('Error processing webhook:', error);
  }
};

const processGitHubWebhook = async (webhookData: WebhookData): Promise<void> => {
  try {
    const { event, data } = webhookData;

    switch (event) {
      case 'workflow_run':
        await processGitHubWorkflowRun(data);
        break;
      case 'check_run':
        await processGitHubCheckRun(data);
        break;
      case 'push':
        await processGitHubPush(data);
        break;
      case 'pull_request':
        await processGitHubPullRequest(data);
        break;
      default:
        logger.info(`Unhandled GitHub event: ${event}`);
    }
  } catch (error) {
    logger.error('Error processing GitHub webhook:', error);
  }
};

const processGitHubWorkflowRun = async (data: any): Promise<void> => {
  try {
    const { workflow_run, repository } = data;
    
    // Find pipeline by repository
    const pipeline = await prisma.pipeline.findFirst({
      where: {
        repository: repository.full_name,
        type: 'GITHUB_ACTIONS'
      }
    });

    if (!pipeline) {
      logger.warn(`Pipeline not found for repository: ${repository.full_name}`);
      return;
    }

    // Create or update build
    const buildData = {
      pipelineId: pipeline.id,
      externalId: workflow_run.id.toString(),
      status: mapGitHubStatus(workflow_run.conclusion || workflow_run.status),
      startTime: new Date(workflow_run.run_started_at),
      endTime: workflow_run.conclusion ? new Date(workflow_run.updated_at) : null,
      duration: workflow_run.conclusion ? 
        Math.floor((new Date(workflow_run.updated_at).getTime() - new Date(workflow_run.run_started_at).getTime()) / 1000) : null,
      commitHash: workflow_run.head_sha,
      branch: workflow_run.head_branch,
      triggerType: workflow_run.event === 'push' ? 'PUSH' : 
                   workflow_run.event === 'pull_request' ? 'PULL_REQUEST' : 'WEBHOOK',
      metadata: {
        workflowName: workflow_run.name,
        workflowId: workflow_run.workflow_id,
        runNumber: workflow_run.run_number,
        actor: workflow_run.actor?.login,
        event: workflow_run.event
      }
    };

    let build = await prisma.build.findFirst({
      where: {
        pipelineId: pipeline.id,
        externalId: buildData.externalId
      }
    });

    if (build) {
      // Update existing build
      build = await prisma.build.update({
        where: { id: build.id },
        data: buildData
      });
    } else {
      // Create new build
      build = await prisma.build.create({
        data: buildData
      });
    }

    // Update pipeline status
    await prisma.pipeline.update({
      where: { id: pipeline.id },
      data: {
        status: buildData.status,
        lastBuildId: build.id,
        updatedAt: new Date()
      }
    });

    // Broadcast updates
    broadcastBuildUpdate(build);
    broadcastPipelineUpdate(pipeline);

    logger.info(`GitHub workflow run processed: ${workflow_run.id}`);

  } catch (error) {
    logger.error('Error processing GitHub workflow run:', error);
  }
};

const processGitHubCheckRun = async (data: any): Promise<void> => {
  try {
    const { check_run, repository } = data;
    
    // Find pipeline by repository
    const pipeline = await prisma.pipeline.findFirst({
      where: {
        repository: repository.full_name,
        type: 'GITHUB_ACTIONS'
      }
    });

    if (!pipeline) {
      return;
    }

    // Find or create build
    let build = await prisma.build.findFirst({
      where: {
        pipelineId: pipeline.id,
        externalId: check_run.check_suite_id.toString()
      }
    });

    if (!build) {
      build = await prisma.build.create({
        data: {
          pipelineId: pipeline.id,
          externalId: check_run.check_suite_id.toString(),
          status: mapGitHubStatus(check_run.conclusion || check_run.status),
          commitHash: check_run.head_sha,
          branch: check_run.check_suite.head_branch,
          triggerType: 'WEBHOOK',
          metadata: {
            checkRunName: check_run.name,
            checkSuiteId: check_run.check_suite_id,
            appName: check_run.app?.name
          }
        }
      });
    }

    // Create or update build stage
    const stageData = {
      buildId: build.id,
      name: check_run.name,
      status: mapGitHubStatus(check_run.conclusion || check_run.status),
      startTime: check_run.started_at ? new Date(check_run.started_at) : null,
      endTime: check_run.conclusion ? new Date(check_run.completed_at) : null,
      duration: check_run.conclusion && check_run.started_at ? 
        Math.floor((new Date(check_run.completed_at).getTime() - new Date(check_run.started_at).getTime()) / 1000) : null,
      logs: check_run.output?.summary || null
    };

    let stage = await prisma.buildStage.findFirst({
      where: {
        buildId: build.id,
        name: check_run.name
      }
    });

    if (stage) {
      await prisma.buildStage.update({
        where: { id: stage.id },
        data: stageData
      });
    } else {
      await prisma.buildStage.create({
        data: stageData
      });
    }

    // Update build status based on all stages
    const stages = await prisma.buildStage.findMany({
      where: { buildId: build.id }
    });

    const overallStatus = determineOverallStatus(stages.map(s => s.status));
    
    if (overallStatus !== build.status) {
      build = await prisma.build.update({
        where: { id: build.id },
        data: { status: overallStatus }
      });
    }

    // Broadcast updates
    broadcastBuildUpdate(build);

    logger.info(`GitHub check run processed: ${check_run.id}`);

  } catch (error) {
    logger.error('Error processing GitHub check run:', error);
  }
};

const processGitHubPush = async (data: any): Promise<void> => {
  try {
    const { ref, repository, commits } = data;
    
    // Find pipeline by repository
    const pipeline = await prisma.pipeline.findFirst({
      where: {
        repository: repository.full_name,
        type: 'GITHUB_ACTIONS'
      }
    });

    if (!pipeline) {
      return;
    }

    // Create build for push event
    const build = await prisma.build.create({
      data: {
        pipelineId: pipeline.id,
        externalId: `push-${Date.now()}`,
        status: 'PENDING',
        commitHash: commits[0]?.id,
        branch: ref.replace('refs/heads/', ''),
        triggerType: 'PUSH',
        metadata: {
          event: 'push',
          commitCount: commits.length,
          commitMessages: commits.map((c: any) => c.message)
        }
      }
    });

    // Broadcast updates
    broadcastBuildUpdate(build);

    logger.info(`GitHub push processed for branch: ${ref}`);

  } catch (error) {
    logger.error('Error processing GitHub push:', error);
  }
};

const processGitHubPullRequest = async (data: any): Promise<void> => {
  try {
    const { action, pull_request, repository } = data;
    
    // Find pipeline by repository
    const pipeline = await prisma.pipeline.findFirst({
      where: {
        repository: repository.full_name,
        type: 'GITHUB_ACTIONS'
      }
    });

    if (!pipeline) {
      return;
    }

    // Create build for pull request
    const build = await prisma.build.create({
      data: {
        pipelineId: pipeline.id,
        externalId: `pr-${pull_request.id}`,
        status: 'PENDING',
        commitHash: pull_request.head.sha,
        branch: pull_request.head.ref,
        triggerType: 'PULL_REQUEST',
        metadata: {
          event: 'pull_request',
          action,
          prNumber: pull_request.number,
          prTitle: pull_request.title,
          baseBranch: pull_request.base.ref
        }
      }
    });

    // Broadcast updates
    broadcastBuildUpdate(build);

    logger.info(`GitHub pull request processed: #${pull_request.number}`);

  } catch (error) {
    logger.error('Error processing GitHub pull request:', error);
  }
};

const processGitLabWebhook = async (webhookData: WebhookData): Promise<void> => {
  try {
    const { event, data } = webhookData;

    switch (event) {
      case 'pipeline':
        await processGitLabPipeline(data);
        break;
      case 'job':
        await processGitLabJob(data);
        break;
      default:
        logger.info(`Unhandled GitLab event: ${event}`);
    }
  } catch (error) {
    logger.error('Error processing GitLab webhook:', error);
  }
};

const processGitLabPipeline = async (data: any): Promise<void> => {
  try {
    const { pipeline, project } = data;
    
    // Find pipeline by repository
    const dbPipeline = await prisma.pipeline.findFirst({
      where: {
        repository: project.path_with_namespace,
        type: 'GITLAB_CI'
      }
    });

    if (!dbPipeline) {
      logger.warn(`Pipeline not found for repository: ${project.path_with_namespace}`);
      return;
    }

    // Create or update build
    const buildData = {
      pipelineId: dbPipeline.id,
      externalId: pipeline.id.toString(),
      status: mapGitLabStatus(pipeline.status),
      startTime: new Date(pipeline.created_at),
      endTime: pipeline.finished_at ? new Date(pipeline.finished_at) : null,
      duration: pipeline.duration || null,
      commitHash: pipeline.sha,
      branch: pipeline.ref,
      triggerType: pipeline.source === 'push' ? 'PUSH' : 
                   pipeline.source === 'merge_request_event' ? 'PULL_REQUEST' : 'WEBHOOK',
      metadata: {
        pipelineId: pipeline.id,
        projectId: project.id,
        source: pipeline.source,
        user: pipeline.user?.name
      }
    };

    let build = await prisma.build.findFirst({
      where: {
        pipelineId: dbPipeline.id,
        externalId: buildData.externalId
      }
    });

    if (build) {
      build = await prisma.build.update({
        where: { id: build.id },
        data: buildData
      });
    } else {
      build = await prisma.build.create({
        data: buildData
      });
    }

    // Update pipeline status
    await prisma.pipeline.update({
      where: { id: dbPipeline.id },
      data: {
        status: buildData.status,
        lastBuildId: build.id,
        updatedAt: new Date()
      }
    });

    // Broadcast updates
    broadcastBuildUpdate(build);
    broadcastPipelineUpdate(dbPipeline);

    logger.info(`GitLab pipeline processed: ${pipeline.id}`);

  } catch (error) {
    logger.error('Error processing GitLab pipeline:', error);
  }
};

const processGitLabJob = async (data: any): Promise<void> => {
  try {
    const { job, project } = data;
    
    // Find pipeline by repository
    const dbPipeline = await prisma.pipeline.findFirst({
      where: {
        repository: project.path_with_namespace,
        type: 'GITLAB_CI'
      }
    });

    if (!dbPipeline) {
      return;
    }

    // Find build
    const build = await prisma.build.findFirst({
      where: {
        pipelineId: dbPipeline.id,
        externalId: job.pipeline.id.toString()
      }
    });

    if (!build) {
      return;
    }

    // Create or update build stage
    const stageData = {
      buildId: build.id,
      name: job.stage,
      status: mapGitLabStatus(job.status),
      startTime: job.started_at ? new Date(job.started_at) : null,
      endTime: job.finished_at ? new Date(job.finished_at) : null,
      duration: job.duration || null,
      logs: job.trace || null
    };

    let stage = await prisma.buildStage.findFirst({
      where: {
        buildId: build.id,
        name: job.stage
      }
    });

    if (stage) {
      await prisma.buildStage.update({
        where: { id: stage.id },
        data: stageData
      });
    } else {
      await prisma.buildStage.create({
        data: stageData
      });
    }

    logger.info(`GitLab job processed: ${job.id}`);

  } catch (error) {
    logger.error('Error processing GitLab job:', error);
  }
};

const processJenkinsWebhook = async (webhookData: WebhookData): Promise<void> => {
  try {
    const { event, data } = webhookData;

    switch (event) {
      case 'build':
        await processJenkinsBuild(data);
        break;
      case 'job':
        await processJenkinsJob(data);
        break;
      default:
        logger.info(`Unhandled Jenkins event: ${event}`);
    }
  } catch (error) {
    logger.error('Error processing Jenkins webhook:', error);
  }
};

const processJenkinsBuild = async (data: any): Promise<void> => {
  try {
    const { build, job } = data;
    
    // Find pipeline by job name (simplified mapping)
    const dbPipeline = await prisma.pipeline.findFirst({
      where: {
        name: { contains: job.name },
        type: 'JENKINS'
      }
    });

    if (!dbPipeline) {
      logger.warn(`Pipeline not found for Jenkins job: ${job.name}`);
      return;
    }

    // Create or update build
    const buildData = {
      pipelineId: dbPipeline.id,
      externalId: build.number.toString(),
      status: mapJenkinsStatus(build.status),
      startTime: build.timestamp ? new Date(build.timestamp) : null,
      endTime: build.duration ? new Date(build.timestamp + build.duration) : null,
      duration: build.duration ? Math.floor(build.duration / 1000) : null,
      commitHash: build.commit_id,
      branch: build.branch,
      triggerType: 'WEBHOOK',
      metadata: {
        buildNumber: build.number,
        jobName: job.name,
        result: build.result,
        url: build.url
      }
    };

    let dbBuild = await prisma.build.findFirst({
      where: {
        pipelineId: dbPipeline.id,
        externalId: buildData.externalId
      }
    });

    if (dbBuild) {
      dbBuild = await prisma.build.update({
        where: { id: dbBuild.id },
        data: buildData
      });
    } else {
      dbBuild = await prisma.build.create({
        data: buildData
      });
    }

    // Update pipeline status
    await prisma.pipeline.update({
      where: { id: dbPipeline.id },
      data: {
        status: buildData.status,
        lastBuildId: dbBuild.id,
        updatedAt: new Date()
      }
    });

    // Broadcast updates
    broadcastBuildUpdate(dbBuild);
    broadcastPipelineUpdate(dbPipeline);

    logger.info(`Jenkins build processed: ${build.number}`);

  } catch (error) {
    logger.error('Error processing Jenkins build:', error);
  }
};

const processJenkinsJob = async (data: any): Promise<void> => {
  // Similar to GitLab job processing
  logger.info('Jenkins job processing not yet implemented');
};

// Status mapping functions
const mapGitHubStatus = (status: string): string => {
  switch (status) {
    case 'success': return 'SUCCESS';
    case 'failure': return 'FAILED';
    case 'cancelled': return 'CANCELLED';
    case 'in_progress': return 'RUNNING';
    case 'queued': return 'PENDING';
    case 'waiting': return 'PENDING';
    default: return 'UNKNOWN';
  }
};

const mapGitLabStatus = (status: string): string => {
  switch (status) {
    case 'success': return 'SUCCESS';
    case 'failed': return 'FAILED';
    case 'canceled': return 'CANCELLED';
    case 'running': return 'RUNNING';
    case 'pending': return 'PENDING';
    case 'skipped': return 'SKIPPED';
    default: return 'UNKNOWN';
  }
};

const mapJenkinsStatus = (status: string): string => {
  switch (status) {
    case 'SUCCESS': return 'SUCCESS';
    case 'FAILURE': return 'FAILED';
    case 'ABORTED': return 'CANCELLED';
    case 'IN_PROGRESS': return 'RUNNING';
    case 'QUEUED': return 'PENDING';
    default: return 'UNKNOWN';
  }
};

const determineOverallStatus = (statuses: string[]): string => {
  if (statuses.includes('FAILED')) return 'FAILED';
  if (statuses.includes('RUNNING')) return 'RUNNING';
  if (statuses.includes('PENDING')) return 'PENDING';
  if (statuses.every(s => s === 'SUCCESS')) return 'SUCCESS';
  return 'UNKNOWN';
};
```

Now let me create the remaining service files. Let me continue with the data collection and alerting services:


```typescript
import cron from 'node-cron';
import { logger } from '../utils/logger';
import { prisma } from '../utils/database';
import { broadcastMetricsUpdate } from './websocket';

export const setupDataCollection = (): void => {
  logger.info('Setting up data collection service');

  // Schedule metrics calculation every hour
  cron.schedule('0 * * * *', async () => {
    try {
      await calculateAndStoreMetrics();
      logger.info('Hourly metrics calculation completed');
    } catch (error) {
      logger.error('Error in hourly metrics calculation:', error);
    }
  });

  // Schedule daily metrics calculation at midnight
  cron.schedule('0 0 * * *', async () => {
    try {
      await calculateDailyMetrics();
      logger.info('Daily metrics calculation completed');
    } catch (error) {
      logger.error('Error in daily metrics calculation:', error);
    }
  });

  // Schedule weekly metrics calculation on Sunday at 1 AM
  cron.schedule('0 1 * * 0', async () => {
    try {
      await calculateWeeklyMetrics();
      logger.info('Weekly metrics calculation completed');
    } catch (error) {
      logger.error('Error in weekly metrics calculation:', error);
    }
  });

  // Schedule monthly metrics calculation on the 1st at 2 AM
  cron.schedule('0 2 1 * *', async () => {
    try {
      await calculateMonthlyMetrics();
      logger.info('Monthly metrics calculation completed');
    } catch (error) {
      logger.error('Error in monthly metrics calculation:', error);
    }
  });

  // Schedule pipeline health checks every 5 minutes
  cron.schedule('*/5 * * * *', async () => {
    try {
      await checkPipelineHealth();
      logger.debug('Pipeline health check completed');
    } catch (error) {
      logger.error('Error in pipeline health check:', error);
    }
  });

  logger.info('Data collection service initialized');
};

const calculateAndStoreMetrics = async (): Promise<void> => {
  try {
    const pipelines = await prisma.pipeline.findMany();

    for (const pipeline of pipelines) {
      await calculatePipelineMetrics(pipeline.id, 'HOURLY');
    }
  } catch (error) {
    logger.error('Error calculating hourly metrics:', error);
  }
};

const calculateDailyMetrics = async (): Promise<void> => {
  try {
    const pipelines = await prisma.pipeline.findMany();

    for (const pipeline of pipelines) {
      await calculatePipelineMetrics(pipeline.id, 'DAILY');
    }
  } catch (error) {
    logger.error('Error calculating daily metrics:', error);
  }
};

const calculateWeeklyMetrics = async (): Promise<void> => {
  try {
    const pipelines = await prisma.pipeline.findMany();

    for (const pipeline of pipelines) {
      await calculatePipelineMetrics(pipeline.id, 'WEEKLY');
    }
  } catch (error) {
    logger.error('Error calculating weekly metrics:', error);
  }
};

const calculateMonthlyMetrics = async (): Promise<void> => {
  try {
    const pipelines = await prisma.pipeline.findMany();

    for (const pipeline of pipelines) {
      await calculatePipelineMetrics(pipeline.id, 'MONTHLY');
    }
  } catch (error) {
    logger.error('Error calculating monthly metrics:', error);
  }
};

const calculatePipelineMetrics = async (pipelineId: string, period: string): Promise<void> => {
  try {
    const now = new Date();
    let startDate: Date;

    // Calculate start date based on period
    switch (period) {
      case 'HOURLY':
        startDate = new Date(now.getTime() - 60 * 60 * 1000);
        break;
      case 'DAILY':
        startDate = new Date(now.getTime() - 24 * 60 * 60 * 1000);
        break;
      case 'WEEKLY':
        startDate = new Date(now.getTime() - 7 * 24 * 60 * 60 * 1000);
        break;
      case 'MONTHLY':
        startDate = new Date(now.getTime() - 30 * 24 * 60 * 60 * 1000);
        break;
      default:
        startDate = new Date(now.getTime() - 24 * 60 * 60 * 1000);
    }

    // Get builds for the period
    const builds = await prisma.build.findMany({
      where: {
        pipelineId,
        createdAt: {
          gte: startDate,
          lte: now
        }
      }
    });

    if (builds.length === 0) {
      return;
    }

    // Calculate success rate
    const successfulBuilds = builds.filter(build => build.status === 'SUCCESS').length;
    const successRate = (successfulBuilds / builds.length) * 100;

    // Calculate average build time
    const buildsWithDuration = builds.filter(build => build.duration && build.duration > 0);
    const averageBuildTime = buildsWithDuration.length > 0 
      ? buildsWithDuration.reduce((sum, build) => sum + build.duration!, 0) / buildsWithDuration.length
      : 0;

    // Calculate failure count
    const failureCount = builds.filter(build => build.status === 'FAILED').length;

    // Calculate queue length (pending builds)
    const queueLength = await prisma.build.count({
      where: {
        pipelineId,
        status: 'PENDING'
      }
    });

    // Store metrics
    const metricsToCreate = [
      {
        pipelineId,
        metricType: 'SUCCESS_RATE',
        value: successRate,
        period,
        timestamp: now
      },
      {
        pipelineId,
        metricType: 'BUILD_TIME',
        value: averageBuildTime,
        period,
        timestamp: now
      },
      {
        pipelineId,
        metricType: 'FAILURE_COUNT',
        value: failureCount,
        period,
        timestamp: now
      },
      {
        pipelineId,
        metricType: 'QUEUE_LENGTH',
        value: queueLength,
        period,
        timestamp: now
      }
    ];

    // Use transaction to ensure all metrics are created together
    await prisma.$transaction(async (tx) => {
      for (const metric of metricsToCreate) {
        await tx.metric.create({
          data: metric
        });
      }
    });

    // Broadcast metrics update
    broadcastMetricsUpdate({
      pipelineId,
      period,
      metrics: metricsToCreate,
      timestamp: now.toISOString()
    });

    logger.debug(`Metrics calculated for pipeline ${pipelineId} (${period})`, {
      successRate: Math.round(successRate * 100) / 100,
      averageBuildTime: Math.round(averageBuildTime),
      failureCount,
      queueLength
    });

  } catch (error) {
    logger.error(`Error calculating metrics for pipeline ${pipelineId}:`, error);
  }
};

const checkPipelineHealth = async (): Promise<void> => {
  try {
    const pipelines = await prisma.pipeline.findMany({
      include: {
        builds: {
          take: 1,
          orderBy: { createdAt: 'desc' }
        }
      }
    });

    for (const pipeline of pipelines) {
      await updatePipelineHealth(pipeline);
    }
  } catch (error) {
    logger.error('Error checking pipeline health:', error);
  }
};

const updatePipelineHealth = async (pipeline: any): Promise<void> => {
  try {
    let newStatus = 'UNKNOWN';

    if (pipeline.builds.length === 0) {
      newStatus = 'UNKNOWN';
    } else {
      const lastBuild = pipeline.builds[0];
      newStatus = lastBuild.status;
    }

    // Check if pipeline has been inactive for too long (more than 24 hours)
    if (pipeline.builds.length > 0) {
      const lastBuildTime = pipeline.builds[0].createdAt;
      const hoursSinceLastBuild = (Date.now() - lastBuildTime.getTime()) / (1000 * 60 * 60);
      
      if (hoursSinceLastBuild > 24) {
        newStatus = 'DISABLED';
      }
    }

    // Only update if status has changed
    if (newStatus !== pipeline.status) {
      await prisma.pipeline.update({
        where: { id: pipeline.id },
        data: {
          status: newStatus,
          updatedAt: new Date()
        }
      });

      logger.info(`Pipeline ${pipeline.name} status updated to ${newStatus}`);
    }
  } catch (error) {
    logger.error(`Error updating pipeline health for ${pipeline.name}:`, error);
  }
};

// Manual metrics calculation for a specific pipeline
export const calculatePipelineMetricsManually = async (pipelineId: string, period: string): Promise<void> => {
  try {
    await calculatePipelineMetrics(pipelineId, period);
    logger.info(`Manual metrics calculation completed for pipeline ${pipelineId} (${period})`);
  } catch (error) {
    logger.error(`Error in manual metrics calculation for pipeline ${pipelineId}:`, error);
    throw error;
  }
};

// Get metrics summary for dashboard
export const getMetricsSummary = async (): Promise<any> => {
  try {
    const now = new Date();
    const oneDayAgo = new Date(now.getTime() - 24 * 60 * 60 * 1000);

    // Get overall success rate for the last 24 hours
    const recentBuilds = await prisma.build.findMany({
      where: {
        createdAt: {
          gte: oneDayAgo
        }
      }
    });

    const totalBuilds = recentBuilds.length;
    const successfulBuilds = recentBuilds.filter(build => build.status === 'SUCCESS').length;
    const overallSuccessRate = totalBuilds > 0 ? (successfulBuilds / totalBuilds) * 100 : 0;

    // Get average build time for the last 24 hours
    const buildsWithDuration = recentBuilds.filter(build => build.duration && build.duration > 0);
    const averageBuildTime = buildsWithDuration.length > 0 
      ? buildsWithDuration.reduce((sum, build) => sum + build.duration!, 0) / buildsWithDuration.length
      : 0;

    // Get pipeline count by status
    const pipelineStatuses = await prisma.pipeline.groupBy({
      by: ['status'],
      _count: {
        status: true
      }
    });

    return {
      overallSuccessRate: Math.round(overallSuccessRate * 100) / 100,
      averageBuildTime: Math.round(averageBuildTime),
      totalBuilds,
      successfulBuilds,
      pipelineStatuses: pipelineStatuses.map(ps => ({
        status: ps.status,
        count: ps._count.status
      }))
    };
  } catch (error) {
    logger.error('Error getting metrics summary:', error);
    throw error;
  }
};
```

Now let me create the alerting service:


```typescript
import cron from 'node-cron';
import { logger } from '../utils/logger';
import { prisma } from '../utils/database';
import { sendAlertNotification } from './notificationService';
import { broadcastAlert } from './websocket';

export const setupAlerting = (): void => {
  logger.info('Setting up alerting service');

  // Check alerts every minute
  cron.schedule('* * * * *', async () => {
    try {
      await evaluateAlerts();
    } catch (error) {
      logger.error('Error evaluating alerts:', error);
    }
  });

  // Clean up old alert history every day at 2 AM
  cron.schedule('0 2 * * *', async () => {
    try {
      await cleanupAlertHistory();
      logger.info('Alert history cleanup completed');
    } catch (error) {
      logger.error('Error cleaning up alert history:', error);
    }
  });

  logger.info('Alerting service initialized');
};

const evaluateAlerts = async (): Promise<void> => {
  try {
    const activeAlerts = await prisma.alert.findMany({
      where: { isActive: true },
      include: {
        pipeline: {
          select: {
            id: true,
            name: true,
            status: true
          }
        }
      }
    });

    for (const alert of activeAlerts) {
      await evaluateAlert(alert);
    }
  } catch (error) {
    logger.error('Error evaluating alerts:', error);
  }
};

const evaluateAlert = async (alert: any): Promise<void> => {
  try {
    let shouldTrigger = false;
    let message = '';
    let severity = 'INFO';

    switch (alert.conditionType) {
      case 'FAILURE':
        shouldTrigger = await evaluateFailureCondition(alert);
        if (shouldTrigger) {
          message = 'Build failure detected';
          severity = 'ERROR';
        }
        break;

      case 'BUILD_TIME':
        shouldTrigger = await evaluateBuildTimeCondition(alert);
        if (shouldTrigger) {
          message = `Build time exceeded threshold: ${alert.threshold} seconds`;
          severity = 'WARNING';
        }
        break;

      case 'SUCCESS_RATE':
        shouldTrigger = await evaluateSuccessRateCondition(alert);
        if (shouldTrigger) {
          message = `Success rate dropped below threshold: ${alert.threshold}%`;
          severity = 'WARNING';
        }
        break;

      case 'QUEUE_LENGTH':
        shouldTrigger = await evaluateQueueLengthCondition(alert);
        if (shouldTrigger) {
          message = `Queue length exceeded threshold: ${alert.threshold} builds`;
          severity = 'WARNING';
        }
        break;

      case 'PIPELINE_DOWN':
        shouldTrigger = await evaluatePipelineDownCondition(alert);
        if (shouldTrigger) {
          message = 'Pipeline appears to be down or inactive';
          severity = 'CRITICAL';
        }
        break;

      default:
        logger.warn(`Unknown alert condition type: ${alert.conditionType}`);
        return;
    }

    if (shouldTrigger) {
      await triggerAlert(alert, message, severity);
    }

  } catch (error) {
    logger.error(`Error evaluating alert ${alert.id}:`, error);
  }
};

const evaluateFailureCondition = async (alert: any): Promise<boolean> => {
  try {
    if (!alert.pipelineId) {
      // Global failure alert - check all pipelines
      const recentFailedBuilds = await prisma.build.findMany({
        where: {
          status: 'FAILED',
          createdAt: {
            gte: new Date(Date.now() - 5 * 60 * 1000) // Last 5 minutes
          }
        }
      });

      return recentFailedBuilds.length > 0;
    } else {
      // Pipeline-specific failure alert
      const recentFailedBuilds = await prisma.build.findMany({
        where: {
          pipelineId: alert.pipelineId,
          status: 'FAILED',
          createdAt: {
            gte: new Date(Date.now() - 5 * 60 * 1000) // Last 5 minutes
          }
        }
      });

      return recentFailedBuilds.length > 0;
    }
  } catch (error) {
    logger.error('Error evaluating failure condition:', error);
    return false;
  }
};

const evaluateBuildTimeCondition = async (alert: any): Promise<boolean> => {
  try {
    if (!alert.pipelineId) {
      // Global build time alert
      const recentBuilds = await prisma.build.findMany({
        where: {
          status: { in: ['SUCCESS', 'FAILED'] },
          duration: { not: null },
          createdAt: {
            gte: new Date(Date.now() - 60 * 60 * 1000) // Last hour
          }
        }
      });

      if (recentBuilds.length === 0) return false;

      const avgBuildTime = recentBuilds.reduce((sum, build) => sum + build.duration!, 0) / recentBuilds.length;
      return avgBuildTime > alert.threshold;
    } else {
      // Pipeline-specific build time alert
      const recentBuilds = await prisma.build.findMany({
        where: {
          pipelineId: alert.pipelineId,
          status: { in: ['SUCCESS', 'FAILED'] },
          duration: { not: null },
          createdAt: {
            gte: new Date(Date.now() - 60 * 60 * 1000) // Last hour
          }
        }
      });

      if (recentBuilds.length === 0) return false;

      const avgBuildTime = recentBuilds.reduce((sum, build) => sum + build.duration!, 0) / recentBuilds.length;
      return avgBuildTime > alert.threshold;
    }
  } catch (error) {
    logger.error('Error evaluating build time condition:', error);
    return false;
  }
};

const evaluateSuccessRateCondition = async (alert: any): Promise<boolean> => {
  try {
    if (!alert.pipelineId) {
      // Global success rate alert
      const recentBuilds = await prisma.build.findMany({
        where: {
          status: { in: ['SUCCESS', 'FAILED'] },
          createdAt: {
            gte: new Date(Date.now() - 24 * 60 * 60 * 1000) // Last 24 hours
          }
        }
      });

      if (recentBuilds.length === 0) return false;

      const successfulBuilds = recentBuilds.filter(build => build.status === 'SUCCESS').length;
      const successRate = (successfulBuilds / recentBuilds.length) * 100;

      return successRate < alert.threshold;
    } else {
      // Pipeline-specific success rate alert
      const recentBuilds = await prisma.build.findMany({
        where: {
          pipelineId: alert.pipelineId,
          status: { in: ['SUCCESS', 'FAILED'] },
          createdAt: {
            gte: new Date(Date.now() - 24 * 60 * 60 * 1000) // Last 24 hours
          }
        }
      });

      if (recentBuilds.length === 0) return false;

      const successfulBuilds = recentBuilds.filter(build => build.status === 'SUCCESS').length;
      const successRate = (successfulBuilds / recentBuilds.length) * 100;

      return successRate < alert.threshold;
    }
  } catch (error) {
    logger.error('Error evaluating success rate condition:', error);
    return false;
  }
};

const evaluateQueueLengthCondition = async (alert: any): Promise<boolean> => {
  try {
    if (!alert.pipelineId) {
      // Global queue length alert
      const queueLength = await prisma.build.count({
        where: {
          status: 'PENDING'
        }
      });

      return queueLength > alert.threshold;
    } else {
      // Pipeline-specific queue length alert
      const queueLength = await prisma.build.count({
        where: {
          pipelineId: alert.pipelineId,
          status: 'PENDING'
        }
      });

      return queueLength > alert.threshold;
    }
  } catch (error) {
    logger.error('Error evaluating queue length condition:', error);
    return false;
  }
};

const evaluatePipelineDownCondition = async (alert: any): Promise<boolean> => {
  try {
    if (!alert.pipelineId) {
      // Global pipeline down alert - check all pipelines
      const pipelines = await prisma.pipeline.findMany();
      
      for (const pipeline of pipelines) {
        const lastBuild = await prisma.build.findFirst({
          where: { pipelineId: pipeline.id },
          orderBy: { createdAt: 'desc' }
        });

        if (lastBuild) {
          const hoursSinceLastBuild = (Date.now() - lastBuild.createdAt.getTime()) / (1000 * 60 * 60);
          if (hoursSinceLastBuild > 24) {
            return true; // At least one pipeline is down
          }
        }
      }

      return false;
    } else {
      // Pipeline-specific down alert
      const lastBuild = await prisma.build.findFirst({
        where: { pipelineId: alert.pipelineId },
        orderBy: { createdAt: 'desc' }
      });

      if (!lastBuild) return true; // No builds ever

      const hoursSinceLastBuild = (Date.now() - lastBuild.createdAt.getTime()) / (1000 * 60 * 60);
      return hoursSinceLastBuild > 24;
    }
  } catch (error) {
    logger.error('Error evaluating pipeline down condition:', error);
    return false;
  }
};

const triggerAlert = async (alert: any, message: string, severity: string): Promise<void> => {
  try {
    // Check if we've already sent this alert recently (within the last 15 minutes)
    const recentAlert = await prisma.alertHistory.findFirst({
      where: {
        alertId: alert.id,
        message: message,
        sentAt: {
          gte: new Date(Date.now() - 15 * 60 * 1000) // Last 15 minutes
        }
      }
    });

    if (recentAlert) {
      logger.debug(`Alert ${alert.id} already sent recently, skipping`);
      return;
    }

    // Get the most recent build for context
    let buildId: string | undefined;
    if (alert.pipelineId) {
      const lastBuild = await prisma.build.findFirst({
        where: { pipelineId: alert.pipelineId },
        orderBy: { createdAt: 'desc' }
      });
      if (lastBuild) {
        buildId = lastBuild.id;
      }
    }

    // Send notification
    await sendAlertNotification(alert.id, message, severity, buildId);

    // Broadcast to WebSocket clients
    broadcastAlert({
      id: alert.id,
      name: alert.name,
      message,
      severity,
      pipelineId: alert.pipelineId,
      pipelineName: alert.pipeline?.name,
      timestamp: new Date().toISOString()
    });

    logger.info(`Alert triggered: ${alert.name} - ${message}`);

  } catch (error) {
    logger.error(`Error triggering alert ${alert.id}:`, error);
  }
};

const cleanupAlertHistory = async (): Promise<void> => {
  try {
    // Keep alert history for 90 days
    const cutoffDate = new Date(Date.now() - 90 * 24 * 60 * 60 * 1000);

    const deletedCount = await prisma.alertHistory.deleteMany({
      where: {
        sentAt: {
          lt: cutoffDate
        }
      }
    });

    logger.info(`Cleaned up ${deletedCount.count} old alert history records`);
  } catch (error) {
    logger.error('Error cleaning up alert history:', error);
  }
};

// Manual alert evaluation for testing
export const evaluateAlertManually = async (alertId: string): Promise<void> => {
  try {
    const alert = await prisma.alert.findUnique({
      where: { id: alertId },
      include: {
        pipeline: {
          select: {
            id: true,
            name: true,
            status: true
          }
        }
      }
    });

    if (!alert) {
      throw new Error('Alert not found');
    }

    await evaluateAlert(alert);
    logger.info(`Manual alert evaluation completed for: ${alert.name}`);
  } catch (error) {
    logger.error(`Error in manual alert evaluation:`, error);
    throw error;
  }
};

// Get alert statistics
export const getAlertStatistics = async (): Promise<any> => {
  try {
    const now = new Date();
    const oneDayAgo = new Date(now.getTime() - 24 * 60 * 60 * 1000);

    // Get alert counts by severity for the last 24 hours
    const recentAlerts = await prisma.alertHistory.findMany({
      where: {
        sentAt: {
          gte: oneDayAgo
        }
      }
    });

    const alertCounts = {
      total: recentAlerts.length,
      bySeverity: {
        INFO: recentAlerts.filter(a => a.severity === 'INFO').length,
        WARNING: recentAlerts.filter(a => a.severity === 'WARNING').length,
        ERROR: recentAlerts.filter(a => a.severity === 'ERROR').length,
        CRITICAL: recentAlerts.filter(a => a.severity === 'CRITICAL').length
      }
    };

    // Get active alert count
    const activeAlertCount = await prisma.alert.count({
      where: { isActive: true }
    });

    // Get alert success rate
    const successfulAlerts = recentAlerts.filter(a => a.notificationStatus === 'SENT').length;
    const alertSuccessRate = recentAlerts.length > 0 ? (successfulAlerts / recentAlerts.length) * 100 : 0;

    return {
      alertCounts,
      activeAlertCount,
      alertSuccessRate: Math.round(alertSuccessRate * 100) / 100,
      period: '24h'
    };
  } catch (error) {
    logger.error('Error getting alert statistics:', error);
    throw error;
  }
};
```

Now let me create the frontend React application. Let me start with the frontend package.json:


```json
{
  "name": "cicd-dashboard-frontend",
  "version": "1.0.0",
  "description": "Frontend for CI/CD Pipeline Health Dashboard",
  "private": true,
  "scripts": {
    "dev": "vite",
    "build": "tsc && vite build",
    "preview": "vite preview",
    "lint": "eslint . --ext ts,tsx --report-unused-disable-directives --max-warnings 0",
    "lint:fix": "eslint . --ext ts,tsx --fix",
    "test": "vitest",
    "test:ui": "vitest --ui",
    "test:coverage": "vitest --coverage"
  },
  "dependencies": {
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "react-router-dom": "^6.20.1",
    "@reduxjs/toolkit": "^1.9.7",
    "react-redux": "^8.1.3",
    "@mui/material": "^5.14.18",
    "@mui/icons-material": "^5.14.18",
    "@mui/x-charts": "^6.18.1",
    "@emotion/react": "^11.11.1",
    "@emotion/styled": "^11.11.0",
    "socket.io-client": "^4.7.4",
    "axios": "^1.6.2",
    "date-fns": "^2.30.0",
    "react-query": "^3.39.3",
    "react-hook-form": "^7.48.2",
    "react-hot-toast": "^2.4.1",
    "recharts": "^2.8.0"
  },
  "devDependencies": {
    "@types/react": "^18.2.37",
    "@types/react-dom": "^18.2.15",
    "@typescript-eslint/eslint-plugin": "^6.10.0",
    "@typescript-eslint/parser": "^6.10.0",
    "@vitejs/plugin-react": "^4.1.1",
    "eslint": "^8.53.0",
    "eslint-plugin-react-hooks": "^4.6.0",
    "eslint-plugin-react-refresh": "^0.4.4",
    "typescript": "^5.2.2",
    "vite": "^4.5.0",
    "vitest": "^0.34.6",
    "@vitest/ui": "^0.34.6"
  },
  "browserslist": {
    "production": [
      ">0.2%",
      "not dead",
      "not op_mini all"
    ],
    "development": [
      "last 1 chrome version",
      "last 1 firefox version",
      "last 1 safari version"
    ]
  }
}
```

Now let me create the Vite configuration and main React components:


```typescript
import { defineConfig } from 'vite'
import react from '@vitejs/plugin-react'

// https://vitejs.dev/config/
export default defineConfig({
  plugins: [react()],
  server: {
    port: 3001,
    proxy: {
      '/api': {
        target: 'http://localhost:3000',
        changeOrigin: true,
        secure: false,
      },
    },
  },
  build: {
    outDir: 'dist',
    sourcemap: true,
  },
})
```

```jsonc
{
  "compilerOptions": {
    "target": "ES2020",
    "useDefineForClassFields": true,
    "lib": ["ES2020", "DOM", "DOM.Iterable"],
    "module": "ESNext",
    "skipLibCheck": true,

    /* Bundler mode */
    "moduleResolution": "bundler",
    "allowImportingTsExtensions": true,
    "resolveJsonModule": true,
    "isolatedModules": true,
    "noEmit": true,
    "jsx": "react-jsx",

    /* Linting */
    "strict": true,
    "noUnusedLocals": true,
    "noUnusedParameters": true,
    "noFallthroughCasesInSwitch": true
  },
  "include": ["src"],
  "references": [{ "path": "./tsconfig.node.json" }]
}
```

```jsonc
{
  "compilerOptions": {
    "composite": true,
    "skipLibCheck": true,
    "module": "ESNext",
    "moduleResolution": "bundler",
    "allowSyntheticDefaultImports": true
  },
  "include": ["vite.config.ts"]
}
```

Now let me create the main React application files:


```html
<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <link rel="icon" type="image/svg+xml" href="/vite.svg" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>CI/CD Pipeline Health Dashboard</title>
    <link
      rel="stylesheet"
      href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700&display=swap"
    />
    <link
      rel="stylesheet"
      href="https://fonts.googleapis.com/icon?family=Material+Icons"
    />
  </head>
  <body>
    <div id="root"></div>
    <script type="module" src="/src/main.tsx"></script>
  </body>
</html>
```

```typescriptreact
import React from 'react'
import ReactDOM from 'react-dom/client'
import { Provider } from 'react-redux'
import { BrowserRouter } from 'react-router-dom'
import { ThemeProvider, createTheme } from '@mui/material/styles'
import CssBaseline from '@mui/material/CssBaseline'
import { Toaster } from 'react-hot-toast'

import App from './App.tsx'
import { store } from './store/store.ts'
import './index.css'

const theme = createTheme({
  palette: {
    mode: 'light',
    primary: {
      main: '#1976d2',
    },
    secondary: {
      main: '#dc004e',
    },
    background: {
      default: '#f5f5f5',
    },
  },
  typography: {
    fontFamily: 'Roboto, Arial, sans-serif',
  },
  components: {
    MuiCard: {
      styleOverrides: {
        root: {
          boxShadow: '0 2px 8px rgba(0,0,0,0.1)',
          borderRadius: 8,
        },
      },
    },
    MuiButton: {
      styleOverrides: {
        root: {
          textTransform: 'none',
          borderRadius: 8,
        },
      },
    },
  },
})

ReactDOM.createRoot(document.getElementById('root')!).render(
  <React.StrictMode>
    <Provider store={store}>
      <BrowserRouter>
        <ThemeProvider theme={theme}>
          <CssBaseline />
          <App />
          <Toaster
            position="top-right"
            toastOptions={{
              duration: 4000,
              style: {
                background: '#363636',
                color: '#fff',
              },
            }}
          />
        </ThemeProvider>
      </BrowserRouter>
    </Provider>
  </React.StrictMode>,
)
```

Now let me create the main App component and the dashboard:


```typescriptreact
import React from 'react'
import { Routes, Route, Navigate } from 'react-router-dom'
import { Box } from '@mui/material'

import Layout from './components/Layout/Layout'
import Dashboard from './pages/Dashboard/Dashboard'
import Pipelines from './pages/Pipelines/Pipelines'
import PipelineDetail from './pages/PipelineDetail/PipelineDetail'
import Builds from './pages/Builds/Builds'
import BuildDetail from './pages/BuildDetail/BuildDetail'
import Alerts from './pages/Alerts/Alerts'
import Login from './pages/Auth/Login'
import { useAuth } from './hooks/useAuth'

function App() {
  const { isAuthenticated, isLoading } = useAuth()

  if (isLoading) {
    return (
      <Box
        display="flex"
        justifyContent="center"
        alignItems="center"
        minHeight="100vh"
      >
        Loading...
      </Box>
    )
  }

  if (!isAuthenticated) {
    return <Login />
  }

  return (
    <Layout>
      <Routes>
        <Route path="/" element={<Navigate to="/dashboard" replace />} />
        <Route path="/dashboard" element={<Dashboard />} />
        <Route path="/pipelines" element={<Pipelines />} />
        <Route path="/pipelines/:id" element={<PipelineDetail />} />
        <Route path="/builds" element={<Builds />} />
        <Route path="/builds/:id" element={<BuildDetail />} />
        <Route path="/alerts" element={<Alerts />} />
        <Route path="*" element={<Navigate to="/dashboard" replace />} />
      </Routes>
    </Layout>
  )
}

export default App
```

Now let me create the Dashboard component:


```typescriptreact
import React, { useEffect, useState } from 'react'
import {
  Box,
  Grid,
  Card,
  CardContent,
  Typography,
  Paper,
  Table,
  TableBody,
  TableCell,
  TableContainer,
  TableHead,
  TableRow,
  Chip,
  IconButton,
  Tooltip,
  CircularProgress,
} from '@mui/material'
import {
  PlayArrow,
  CheckCircle,
  Error,
  Schedule,
  Refresh,
  Timeline,
  Speed,
  Warning,
} from '@mui/icons-material'
import { LineChart, Line, XAxis, YAxis, CartesianGrid, Tooltip as RechartsTooltip, ResponsiveContainer, BarChart, Bar } from 'recharts'
import { format } from 'date-fns'
import toast from 'react-hot-toast'

import { useWebSocket } from '../../hooks/useWebSocket'
import { api } from '../../services/api'
import { DashboardMetrics, PipelineStatus, RecentBuild } from '../../types/dashboard'

const Dashboard: React.FC = () => {
  const [metrics, setMetrics] = useState<DashboardMetrics | null>(null)
  const [pipelineStatuses, setPipelineStatuses] = useState<PipelineStatus[]>([])
  const [recentBuilds, setRecentBuilds] = useState<RecentBuild[]>([])
  const [successRateData, setSuccessRateData] = useState<any[]>([])
  const [buildTimeData, setBuildTimeData] = useState<any[]>([])
  const [loading, setLoading] = useState(true)
  const [refreshing, setRefreshing] = useState(false)

  const { isConnected } = useWebSocket()

  useEffect(() => {
    loadDashboardData()
  }, [])

  const loadDashboardData = async () => {
    try {
      setLoading(true)
      const [metricsRes, statusesRes, buildsRes, successRateRes, buildTimeRes] = await Promise.all([
        api.get('/metrics/overview'),
        api.get('/pipelines'),
        api.get('/builds?limit=10'),
        api.get('/metrics/success-rate?limit=30'),
        api.get('/metrics/build-times?limit=30'),
      ])

      setMetrics(metricsRes.data.data)
      setPipelineStatuses(statusesRes.data.data.pipelines)
      setRecentBuilds(buildsRes.data.data.builds)
      setSuccessRateData(successRateRes.data.data.metrics)
      setBuildTimeData(buildTimeRes.data.data.metrics)
    } catch (error) {
      console.error('Error loading dashboard data:', error)
      toast.error('Failed to load dashboard data')
    } finally {
      setLoading(false)
    }
  }

  const handleRefresh = async () => {
    setRefreshing(true)
    await loadDashboardData()
    setRefreshing(false)
    toast.success('Dashboard refreshed')
  }

  const getStatusColor = (status: string) => {
    switch (status) {
      case 'SUCCESS':
        return 'success'
      case 'FAILED':
        return 'error'
      case 'RUNNING':
        return 'warning'
      case 'PENDING':
        return 'info'
      default:
        return 'default'
    }
  }

  const getStatusIcon = (status: string) => {
    switch (status) {
      case 'SUCCESS':
        return <CheckCircle color="success" />
      case 'FAILED':
        return <Error color="error" />
      case 'RUNNING':
        return <PlayArrow color="warning" />
      case 'PENDING':
        return <Schedule color="info" />
      default:
        return <Warning color="default" />
    }
  }

  if (loading) {
    return (
      <Box display="flex" justifyContent="center" alignItems="center" minHeight="400px">
        <CircularProgress />
      </Box>
    )
  }

  return (
    <Box p={3}>
      <Box display="flex" justifyContent="space-between" alignItems="center" mb={3}>
        <Typography variant="h4" component="h1">
          CI/CD Pipeline Health Dashboard
        </Typography>
        <Box display="flex" alignItems="center" gap={1}>
          <Chip
            label={isConnected ? 'Connected' : 'Disconnected'}
            color={isConnected ? 'success' : 'error'}
            size="small"
          />
          <Tooltip title="Refresh Dashboard">
            <IconButton onClick={handleRefresh} disabled={refreshing}>
              <Refresh />
            </IconButton>
          </Tooltip>
        </Box>
      </Box>

      {/* Summary Cards */}
      <Grid container spacing={3} mb={3}>
        <Grid item xs={12} sm={6} md={3}>
          <Card>
            <CardContent>
              <Box display="flex" alignItems="center" justifyContent="space-between">
                <Box>
                  <Typography color="textSecondary" gutterBottom>
                    Total Pipelines
                  </Typography>
                  <Typography variant="h4">
                    {metrics?.summary.totalPipelines || 0}
                  </Typography>
                </Box>
                <Timeline color="primary" sx={{ fontSize: 40 }} />
              </Box>
            </CardContent>
          </Card>
        </Grid>

        <Grid item xs={12} sm={6} md={3}>
          <Card>
            <CardContent>
              <Box display="flex" alignItems="center" justifyContent="space-between">
                <Box>
                  <Typography color="textSecondary" gutterBottom>
                    Success Rate
                  </Typography>
                  <Typography variant="h4">
                    {metrics?.summary.successRate || 0}%
                  </Typography>
                </Box>
                <CheckCircle color="success" sx={{ fontSize: 40 }} />
              </Box>
            </CardContent>
          </Card>
        </Grid>

        <Grid item xs={12} sm={6} md={3}>
          <Card>
            <CardContent>
              <Box display="flex" alignItems="center" justifyContent="space-between">
                <Box>
                  <Typography color="textSecondary" gutterBottom>
                    Failed Builds
                  </Typography>
                  <Typography variant="h4" color="error">
                    {metrics?.summary.failedBuilds || 0}
                  </Typography>
                </Box>
                <Error color="error" sx={{ fontSize: 40 }} />
              </Box>
            </CardContent>
          </Card>
        </Grid>

        <Grid item xs={12} sm={6} md={3}>
          <Card>
            <CardContent>
              <Box display="flex" alignItems="center" justifyContent="space-between">
                <Box>
                  <Typography color="textSecondary" gutterBottom>
                    Running Builds
                  </Typography>
                  <Typography variant="h4" color="warning">
                    {metrics?.summary.runningBuilds || 0}
                  </Typography>
                </Box>
                <PlayArrow color="warning" sx={{ fontSize: 40 }} />
              </Box>
            </CardContent>
          </Card>
        </Grid>
      </Grid>

      {/* Charts Row */}
      <Grid container spacing={3} mb={3}>
        <Grid item xs={12} md={6}>
          <Card>
            <CardContent>
              <Typography variant="h6" gutterBottom>
                Success Rate Trend
              </Typography>
              <ResponsiveContainer width="100%" height={300}>
                <LineChart data={successRateData}>
                  <CartesianGrid strokeDasharray="3 3" />
                  <XAxis
                    dataKey="timestamp"
                    tickFormatter={(value) => format(new Date(value), 'MM/dd')}
                  />
                  <YAxis domain={[0, 100]} />
                  <RechartsTooltip
                    labelFormatter={(value) => format(new Date(value), 'MM/dd HH:mm')}
                    formatter={(value: number) => [`${value.toFixed(1)}%`, 'Success Rate']}
                  />
                  <Line
                    type="monotone"
                    dataKey="value"
                    stroke="#4caf50"
                    strokeWidth={2}
                    dot={false}
                  />
                </LineChart>
              </ResponsiveContainer>
            </CardContent>
          </Card>
        </Grid>

        <Grid item xs={12} md={6}>
          <Card>
            <CardContent>
              <Typography variant="h6" gutterBottom>
                Build Time Distribution
              </Typography>
              <ResponsiveContainer width="100%" height={300}>
                <BarChart data={buildTimeData}>
                  <CartesianGrid strokeDasharray="3 3" />
                  <XAxis
                    dataKey="timestamp"
                    tickFormatter={(value) => format(new Date(value), 'MM/dd')}
                  />
                  <YAxis />
                  <RechartsTooltip
                    labelFormatter={(value) => format(new Date(value), 'MM/dd HH:mm')}
                    formatter={(value: number) => [`${Math.round(value)}s`, 'Build Time']}
                  />
                  <Bar dataKey="value" fill="#1976d2" />
                </BarChart>
              </ResponsiveContainer>
            </CardContent>
          </Card>
        </Grid>
      </Grid>

      {/* Pipeline Status and Recent Builds */}
      <Grid container spacing={3}>
        <Grid item xs={12} md={6}>
          <Card>
            <CardContent>
              <Typography variant="h6" gutterBottom>
                Pipeline Status
              </Typography>
              <TableContainer>
                <Table size="small">
                  <TableHead>
                    <TableRow>
                      <TableCell>Status</TableCell>
                      <TableCell>Count</TableCell>
                    </TableRow>
                  </TableHead>
                  <TableBody>
                    {pipelineStatuses.map((status) => (
                      <TableRow key={status.status}>
                        <TableCell>
                          <Box display="flex" alignItems="center" gap={1}>
                            {getStatusIcon(status.status)}
                            <Chip
                              label={status.status}
                              color={getStatusColor(status.status) as any}
                              size="small"
                            />
                          </Box>
                        </TableCell>
                        <TableCell>{status.count}</TableCell>
                      </TableRow>
                    ))}
                  </TableBody>
                </Table>
              </TableContainer>
            </CardContent>
          </Card>
        </Grid>

        <Grid item xs={12} md={6}>
          <Card>
            <CardContent>
              <Typography variant="h6" gutterBottom>
                Recent Builds
              </Typography>
              <TableContainer>
                <Table size="small">
                  <TableHead>
                    <TableRow>
                      <TableCell>Pipeline</TableCell>
                      <TableCell>Status</TableCell>
                      <TableCell>Duration</TableCell>
                      <TableCell>Time</TableCell>
                    </TableRow>
                  </TableHead>
                  <TableBody>
                    {recentBuilds.map((build) => (
                      <TableRow key={build.id}>
                        <TableCell>{build.pipeline.name}</TableCell>
                        <TableCell>
                          <Chip
                            label={build.status}
                            color={getStatusColor(build.status) as any}
                            size="small"
                          />
                        </TableCell>
                        <TableCell>
                          {build.duration ? `${Math.round(build.duration)}s` : '-'}
                        </TableCell>
                        <TableCell>
                          {format(new Date(build.createdAt), 'HH:mm')}
                        </TableCell>
                      </TableRow>
                    ))}
                  </TableBody>
                </Table>
              </TableContainer>
            </CardContent>
          </Card>
        </Grid>
      </Grid>
    </Box>
  )
}

export default Dashboard
```

Now let me create the Docker configuration files. Let me start with the Dockerfile:


```dockerfile
# Multi-stage build for production
FROM node:18-alpine AS base

# Install dependencies only when needed
FROM base AS deps
# Check https://github.com/nodejs/docker-node/tree/b4117f9333da4138b03a546ec926ef50a31506c3#nodealpine to understand why libc6-compat might be needed.
RUN apk add --no-cache libc6-compat
WORKDIR /app

# Install dependencies based on the preferred package manager
COPY package.json package-lock.json* ./
RUN npm ci --only=production

# Rebuild the source code only when needed
FROM base AS builder
WORKDIR /app
COPY --from=deps /app/node_modules ./node_modules
COPY . .

# Generate Prisma client
RUN npx prisma generate

# Build the application
RUN npm run build

# Production image, copy all the files and run the app
FROM base AS runner
WORKDIR /app

ENV NODE_ENV production

RUN addgroup --system --gid 1001 nodejs
RUN adduser --system --uid 1001 nodejs

# Copy the built application
COPY --from=builder /app/dist ./dist
COPY --from=builder /app/node_modules ./node_modules
COPY --from=builder /app/package.json ./package.json
COPY --from=builder /app/prisma ./prisma

# Create logs directory
RUN mkdir -p logs && chown -R nodejs:nodejs logs

USER nodejs

EXPOSE 3000

ENV PORT 3000
ENV HOSTNAME "0.0.0.0"

CMD ["node", "dist/server/index.js"]
```

Now let me create the Docker Compose file:


```dockercompose
version: '3.8'

services:
  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: cicd-dashboard-postgres
    environment:
      POSTGRES_DB: cicd_dashboard
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init-db.sql:/docker-entrypoint-initdb.d/init-db.sql
    ports:
      - "5432:5432"
    networks:
      - cicd-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Redis for caching and sessions
  redis:
    image: redis:7-alpine
    container_name: cicd-dashboard-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - cicd-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  # CI/CD Dashboard Backend
  backend:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: cicd-dashboard-backend
    environment:
      NODE_ENV: production
      PORT: 3000
      DATABASE_URL: postgresql://postgres:postgres@postgres:5432/cicd_dashboard
      REDIS_URL: redis://redis:6379
      JWT_SECRET: your-super-secret-jwt-key-here
      CORS_ORIGIN: http://localhost:3001
    ports:
      - "3000:3000"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - cicd-network
    volumes:
      - ./logs:/app/logs
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # CI/CD Dashboard Frontend
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: cicd-dashboard-frontend
    environment:
      VITE_API_BASE_URL: http://localhost:3000/api/v1
    ports:
      - "3001:80"
    depends_on:
      - backend
    networks:
      - cicd-network

  # Nginx Reverse Proxy (Optional)
  nginx:
    image: nginx:alpine
    container_name: cicd-dashboard-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
    depends_on:
      - backend
      - frontend
    networks:
      - cicd-network
    profiles:
      - production

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local

networks:
  cicd-network:
    driver: bridge
```

Now let me create the frontend Dockerfile:


```dockerfile
# Build stage
FROM node:18-alpine AS build

WORKDIR /app

# Copy package files
COPY package*.json ./

# Install dependencies
RUN npm ci

# Copy source code
COPY . .

# Build the application
RUN npm run build

# Production stage
FROM nginx:alpine

# Copy built application
COPY --from=build /app/dist /usr/share/nginx/html

# Copy nginx configuration
COPY nginx.conf /etc/nginx/conf.d/default.conf

# Expose port 80
EXPOSE 80

# Start nginx
CMD ["nginx", "-g", "daemon off;"]
```

Now let me create the GitHub Actions workflow for CI/CD:


```yaml
name: CI/CD Pipeline Health Dashboard

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

env:
  NODE_VERSION: '18'
  POSTGRES_VERSION: '15'

jobs:
  # Test and Build Backend
  test-backend:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:${{ env.POSTGRES_VERSION }}
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: cicd_dashboard_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
    - uses: actions/checkout@v4
    
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
    
    - name: Install dependencies
      run: npm ci
    
    - name: Generate Prisma client
      run: npx prisma generate
    
    - name: Run database migrations
      run: npx prisma migrate deploy
      env:
        DATABASE_URL: postgresql://postgres:postgres@localhost:5432/cicd_dashboard_test
    
    - name: Run tests
      run: npm test
      env:
        DATABASE_URL: postgresql://postgres:postgres@localhost:5432/cicd_dashboard_test
        JWT_SECRET: test-secret-key
    
    - name: Run linting
      run: npm run lint
    
    - name: Build backend
      run: npm run build:backend

  # Test and Build Frontend
  test-frontend:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        cache-dependency-path: frontend/package-lock.json
    
    - name: Install frontend dependencies
      working-directory: ./frontend
      run: npm ci
    
    - name: Run frontend tests
      working-directory: ./frontend
      run: npm test -- --run
    
    - name: Run frontend linting
      working-directory: ./frontend
      run: npm run lint
    
    - name: Build frontend
      working-directory: ./frontend
      run: npm run build

  # Security and Quality Checks
  security:
    runs-on: ubuntu-latest
    needs: [test-backend, test-frontend]
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
    
    - name: Install dependencies
      run: npm ci
    
    - name: Run security audit
      run: npm audit --audit-level=moderate
    
    - name: Check for outdated dependencies
      run: npm outdated

  # Build and Push Docker Images
  build-docker:
    runs-on: ubuntu-latest
    needs: [test-backend, test-frontend, security]
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
    
    - name: Login to Docker Hub
      uses: docker/login-action@v3
      with:
        username: ${{ secrets.DOCKER_USERNAME }}
        password: ${{ secrets.DOCKER_PASSWORD }}
    
    - name: Build and push backend image
      uses: docker/build-push-action@v5
      with:
        context: .
        file: ./Dockerfile
        push: true
        tags: ${{ secrets.DOCKER_USERNAME }}/cicd-dashboard-backend:latest,${{ secrets.DOCKER_USERNAME }}/cicd-dashboard-backend:${{ github.sha }}
        cache-from: type=gha
        cache-to: type=gha,mode=max
    
    - name: Build and push frontend image
      uses: docker/build-push-action@v5
      with:
        context: ./frontend
        file: ./frontend/Dockerfile
        push: true
        tags: ${{ secrets.DOCKER_USERNAME }}/cicd-dashboard-frontend:latest,${{ secrets.DOCKER_USERNAME }}/cicd-dashboard-frontend:${{ github.sha }}
        cache-from: type=gha
        cache-to: type=gha,mode=max

  # Deploy to Production
  deploy:
    runs-on: ubuntu-latest
    needs: build-docker
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    environment: production
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Deploy to production
      run: |
        echo "Deploying to production..."
        # Add your deployment commands here
        # For example:
        # - SSH to server
        # - Pull latest images
        # - Restart services
        # - Run database migrations
```

Finally, let me create a comprehensive README file:


```markdown
# CI/CD Pipeline Health Dashboard

A comprehensive, real-time dashboard for monitoring and visualizing CI/CD pipeline health across multiple tools including GitHub Actions, GitLab CI, Jenkins, and more.

## üöÄ Features

- **Real-time Monitoring**: Live updates via WebSocket connections
- **Multi-Platform Support**: GitHub Actions, GitLab CI, Jenkins, Azure DevOps, Circle CI, Travis CI
- **Comprehensive Metrics**: Success rates, build times, failure analysis, queue lengths
- **Smart Alerting**: Configurable alerts with Slack, email, and webhook notifications
- **Modern UI**: Responsive React dashboard with Material-UI components
- **Real-time Updates**: WebSocket-based live updates for immediate visibility
- **Role-based Access Control**: Admin, User, and Viewer roles with appropriate permissions
- **Health Monitoring**: Built-in health checks and system monitoring
- **Containerized**: Docker support for easy deployment

## üèóÔ∏è Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Frontend      ‚îÇ    ‚îÇ    Backend      ‚îÇ    ‚îÇ   Database      ‚îÇ
‚îÇ   (React)       ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ   (Node.js)     ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ  (PostgreSQL)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                       ‚îÇ                       ‚îÇ
         ‚îÇ                       ‚îÇ                       ‚îÇ
         ‚ñº                       ‚ñº                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   WebSocket     ‚îÇ    ‚îÇ  Alerting       ‚îÇ    ‚îÇ   File Storage  ‚îÇ
‚îÇ   (Real-time)   ‚îÇ    ‚îÇ  Service        ‚îÇ    ‚îÇ   (Logs)        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üõ†Ô∏è Technology Stack

### Backend
- **Runtime**: Node.js 18+ with TypeScript
- **Framework**: Express.js with middleware
- **Database**: PostgreSQL with Prisma ORM
- **Real-time**: Socket.io for WebSocket connections
- **Authentication**: JWT-based with bcrypt hashing
- **Logging**: Winston for structured logging

### Frontend
- **Framework**: React 18 with TypeScript
- **UI Library**: Material-UI (MUI) v5
- **State Management**: Redux Toolkit
- **Charts**: Recharts for data visualization
- **Routing**: React Router v6
- **Build Tool**: Vite

### Infrastructure
- **Containerization**: Docker with multi-stage builds
- **Orchestration**: Docker Compose
- **CI/CD**: GitHub Actions
- **Monitoring**: Built-in health checks and metrics

## üìã Prerequisites

- Node.js 18+ and npm
- Docker and Docker Compose
- PostgreSQL 15+
- Redis 7+

## üöÄ Quick Start

### 1. Clone the Repository

```bash
git clone https://github.com/yourusername/cicd-pipeline-dashboard.git
cd cicd-pipeline-dashboard
```

### 2. Environment Setup

Copy the environment file and configure it:

```bash
cp env.example .env
```

Edit `.env` with your configuration:

```env
# Database
DATABASE_URL="postgresql://username:password@localhost:5432/cicd_dashboard"

# JWT
JWT_SECRET="your-super-secret-jwt-key-here"

# External Integrations
GITHUB_API_TOKEN="your-github-token"
SLACK_BOT_TOKEN="your-slack-token"
SMTP_HOST="smtp.gmail.com"
SMTP_USER="your-email@gmail.com"
SMTP_PASS="your-app-password"
```

### 3. Install Dependencies

```bash
# Backend dependencies
npm install

# Frontend dependencies
cd frontend
npm install
cd ..
```

### 4. Database Setup

```bash
# Generate Prisma client
npm run db:generate

# Run migrations
npm run db:migrate

# Seed initial data (optional)
npm run db:seed
```

### 5. Development Mode

```bash
# Start both backend and frontend
npm run dev

# Or start separately
npm run dev:backend    # Backend on port 3000
npm run dev:frontend   # Frontend on port 3001
```

### 6. Production with Docker

```bash
# Build and start all services
docker-compose up -d

# View logs
docker-compose logs -f

# Stop services
docker-compose down
```

## üîß Configuration

### Pipeline Integration

#### GitHub Actions
1. Create a GitHub Personal Access Token
2. Add the token to your `.env` file
3. Configure webhooks in your GitHub repositories
4. Add pipelines through the dashboard UI

#### GitLab CI
1. Create a GitLab Access Token
2. Configure webhooks in your GitLab projects
3. Add pipelines through the dashboard UI

#### Jenkins
1. Configure Jenkins API token
2. Set up webhook endpoints
3. Add pipelines through the dashboard UI

### Alert Configuration

#### Slack Integration
1. Create a Slack App and Bot
2. Add the bot to your channels
3. Configure alert rules in the dashboard

#### Email Notifications
1. Configure SMTP settings in `.env`
2. Set up alert rules with email notifications
3. Test the configuration

## üìä Dashboard Features

### Overview Dashboard
- **Summary Cards**: Total pipelines, success rate, failed builds, running builds
- **Real-time Charts**: Success rate trends, build time distribution
- **Pipeline Status**: Current status of all pipelines
- **Recent Builds**: Latest build activities

### Pipeline Management
- **Add/Edit Pipelines**: Configure new CI/CD integrations
- **Build History**: View detailed build information
- **Metrics Analysis**: Performance trends and patterns
- **Status Monitoring**: Real-time pipeline health

### Alert Management
- **Alert Rules**: Configure custom alert conditions
- **Notification Channels**: Slack, email, webhooks
- **Alert History**: Track all triggered alerts
- **Severity Levels**: Info, Warning, Error, Critical

### Build Details
- **Build Logs**: Access to build output and logs
- **Stage Information**: Detailed build stage breakdown
- **Performance Metrics**: Build duration and resource usage
- **Trigger Information**: Build cause and metadata

## üîí Security Features

- **JWT Authentication**: Secure token-based authentication
- **Role-based Access Control**: Admin, User, Viewer permissions
- **Input Validation**: Comprehensive request validation
- **Rate Limiting**: API rate limiting to prevent abuse
- **CORS Configuration**: Secure cross-origin resource sharing
- **Environment Variables**: Secure configuration management

## üìà Monitoring and Health

### Health Endpoints
- `/health` - Basic health check
- `/health/detailed` - Comprehensive system health
- `/health/database` - Database connectivity
- `/health/resources` - System resource usage
- `/health/ready` - Kubernetes readiness probe
- `/health/live` - Kubernetes liveness probe

### Metrics Collection
- **Automatic Metrics**: Hourly, daily, weekly, monthly calculations
- **Real-time Updates**: WebSocket-based live metrics
- **Performance Tracking**: Build times, success rates, failure patterns
- **Resource Monitoring**: Memory, CPU, and database performance

## üöÄ Deployment

### Docker Deployment

```bash
# Build images
docker-compose build

# Start services
docker-compose up -d

# Scale services
docker-compose up -d --scale backend=3
```

### Kubernetes Deployment

```bash
# Apply Kubernetes manifests
kubectl apply -f k8s/

# Check deployment status
kubectl get pods -n cicd-dashboard

# View logs
kubectl logs -f deployment/cicd-dashboard-backend
```

### Production Considerations

1. **Environment Variables**: Use secure secrets management
2. **Database**: Use managed PostgreSQL service
3. **SSL/TLS**: Configure HTTPS with proper certificates
4. **Monitoring**: Integrate with external monitoring tools
5. **Backup**: Regular database backups and disaster recovery
6. **Scaling**: Horizontal scaling for high availability

## üß™ Testing

### Backend Tests

```bash
# Run all tests
npm test

# Run tests in watch mode
npm run test:watch

# Run tests with coverage
npm run test:coverage
```

### Frontend Tests

```bash
cd frontend

# Run tests
npm test

# Run tests with UI
npm run test:ui

# Run tests with coverage
npm run test:coverage
```

### Integration Tests

```bash
# Run integration tests
npm run test:integration

# Test with Docker
docker-compose -f docker-compose.test.yml up --abort-on-container-exit
```

## üìù API Documentation

### Authentication
- `POST /api/v1/auth/login` - User login
- `POST /api/v1/auth/refresh` - Refresh access token
- `POST /api/v1/auth/logout` - User logout

### Pipelines
- `GET /api/v1/pipelines` - List all pipelines
- `POST /api/v1/pipelines` - Create new pipeline
- `GET /api/v1/pipelines/:id` - Get pipeline details
- `PUT /api/v1/pipelines/:id` - Update pipeline
- `DELETE /api/v1/pipelines/:id` - Delete pipeline

### Builds
- `GET /api/v1/builds` - List all builds
- `GET /api/v1/builds/:id` - Get build details
- `POST /api/v1/builds/webhook` - Webhook endpoint
- `POST /api/v1/builds/:pipelineId/trigger` - Manual build trigger

### Metrics
- `GET /api/v1/metrics/overview` - Dashboard overview
- `GET /api/v1/metrics/success-rate` - Success rate trends
- `GET /api/v1/metrics/build-times` - Build time analytics
- `GET /api/v1/metrics/failures` - Failure analysis

### Alerts
- `GET /api/v1/alerts` - List all alerts
- `POST /api/v1/alerts` - Create alert rule
- `PUT /api/v1/alerts/:id` - Update alert rule
- `DELETE /api/v1/alerts/:id` - Delete alert rule

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### Development Guidelines

- Follow TypeScript best practices
- Write comprehensive tests
- Update documentation for new features
- Follow the existing code style
- Add proper error handling
- Include logging for debugging

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üÜò Support

- **Documentation**: [Wiki](https://github.com/yourusername/cicd-pipeline-dashboard/wiki)
- **Issues**: [GitHub Issues](https://github.com/yourusername/cicd-pipeline-dashboard/issues)
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/cicd-pipeline-dashboard/discussions)
- **Email**: support@cicd-dashboard.com

## üôè Acknowledgments

- **Material-UI** for the beautiful UI components
- **Prisma** for the excellent database ORM
- **Socket.io** for real-time communication
- **Express.js** for the robust backend framework
- **React** for the amazing frontend library

## üìä Roadmap

### v1.1 (Q1 2024)
- [ ] Additional CI/CD platform support
- [ ] Advanced analytics and reporting
- [ ] Custom dashboard widgets
- [ ] Team collaboration features

### v1.2 (Q2 2024)
- [ ] Mobile application
- [ ] Advanced alerting rules
- [ ] Integration with monitoring tools
- [ ] Performance optimization

### v2.0 (Q3 2024)
- [ ] Multi-tenant architecture
- [ ] Advanced security features
- [ ] API rate limiting and quotas
- [ ] Enterprise features

---

**Built with ‚ù§Ô∏è by the DevOps Community**
```

## Summary

I've successfully created a comprehensive CI/CD Pipeline Health Dashboard with the following components:

## üèóÔ∏è **Project Structure Created:**

### 1. **Requirements Analysis Document** (`REQUIREMENTS.md`)
- Key features and capabilities
- Technology choices and rationale
- APIs and tools required
- Success criteria and security requirements

### 2. **Technical Design Document** (`TECHNICAL_DESIGN.md`)
- High-level architecture diagrams
- Complete API structure with sample responses
- Database schema with all tables and relationships
- UI layout designs and wireframes

### 3. **Complete Source Code Implementation:**

#### **Backend (Node.js + TypeScript)**
- Express.js server with comprehensive middleware
- Prisma ORM with PostgreSQL database schema
- JWT-based authentication and role-based access control
- WebSocket service for real-time updates
- Comprehensive API routes for all features
- Background services for data collection and alerting
- Webhook processors for GitHub, GitLab, and Jenkins
- Notification service for Slack, email, and webhooks

#### **Frontend (React + TypeScript)**
- Modern React 18 application with Material-UI
- Real-time dashboard with charts and metrics
- Responsive design with proper routing
- WebSocket integration for live updates

#### **Database Schema**
- Complete Prisma schema with all models
- Proper relationships and constraints
- Support for multiple CI/CD platforms

### 4. **Infrastructure & Deployment:**
- **Docker Configuration**: Multi-stage Dockerfiles for both backend and frontend
- **Docker Compose**: Complete stack with PostgreSQL, Redis, and services
- **GitHub Actions**: Comprehensive CI/CD pipeline for testing and deployment
- **Health Monitoring**: Built-in health checks and monitoring endpoints

## üöÄ **Key Features Implemented:**

1. **Real-time Pipeline Monitoring**
   - WebSocket-based live updates
   - Multi-platform CI/CD support (GitHub Actions, GitLab CI, Jenkins)
   - Comprehensive metrics collection

2. **Smart Alerting System**
   - Configurable alert rules
   - Multiple notification channels (Slack, email, webhooks)
   - Alert history and management

3. **Modern Dashboard UI**
   - Real-time charts and metrics
   - Pipeline status visualization
   - Build history and logs access

4. **Security & Authentication**
   - JWT-based authentication
   - Role-based access control
   - Input validation and rate limiting

5. **Health Monitoring**
   - Built-in health checks
   - System resource monitoring
   - Database connectivity checks

## ÔøΩÔøΩ **How to Use:**

1. **Setup Environment**: Copy `env.example` to `.env` and configure
2. **Install Dependencies**: Run `npm install` in both root and frontend directories
3. **Database Setup**: Run Prisma migrations and seed data
4. **Development**: Use `npm run dev` to start both backend and frontend
5. **Production**: Use `docker-compose up -d` for containerized deployment

## üìä **Dashboard Capabilities:**

- **Overview Dashboard**: Summary metrics, real-time charts, pipeline status
- **Pipeline Management**: Add/edit pipelines, view build history, monitor performance
- **Build Details**: Access logs, stage information, performance metrics
- **Alert Configuration**: Set up alert rules, configure notifications, track alert history
- **Real-time Updates**: Live WebSocket updates for immediate visibility

This implementation provides a production-ready CI/CD Pipeline Health Dashboard that can monitor multiple CI/CD systems, provide real-time insights, and alert teams to issues through multiple channels. The system is designed to be scalable, secure, and easy to deploy using modern DevOps practices.

---

**User**

Can we simplify the complexity of this project please?

---

**Cursor**

Ah, I see! You want to simplify the project, Let me create a much simpler version that focuses on the core functionality without all the complexity.

Let me start by simplifying the backend structure and removing unnecessary features:


```json
{
  "name": "simple-cicd-dashboard",
  "version": "1.0.0",
  "description": "A simple CI/CD pipeline monitoring dashboard",
  "main": "dist/server/index.js",
  "scripts": {
    "dev": "ts-node src/server/index.ts",
    "build": "tsc",
    "start": "node dist/server/index.js",
    "test": "echo \"No tests specified\" && exit 0"
  },
  "dependencies": {
    "express": "^4.18.2",
    "cors": "^2.8.5",
    "dotenv": "^16.3.1",
    "sqlite3": "^5.1.6"
  },
  "devDependencies": {
    "@types/express": "^4.17.21",
    "@types/cors": "^2.8.17",
    "@types/node": "^20.10.0",
    "ts-node": "^10.9.1",
    "typescript": "^5.3.2"
  },
  "keywords": ["ci-cd", "dashboard", "monitoring"],
  "author": "Your Name",
  "license": "MIT"
}
```

Now let me simplify the TypeScript configuration:


```jsonc
{
  "compilerOptions": {
    "target": "ES2020",
    "module": "commonjs",
    "outDir": "./dist",
    "rootDir": "./src",
    "strict": true,
    "esModuleInterop": true,
    "skipLibCheck": true,
    "forceConsistentCasingInFileNames": true
  },
  "include": ["src/**/*"],
  "exclude": ["node_modules", "dist"]
}
```

Now let me create a much simpler environment file:


```plaintext
# Server Configuration
PORT=3000
NODE_ENV=development

# Database (SQLite for simplicity)
DATABASE_PATH=./data/dashboard.db

# GitHub Integration (optional)
GITHUB_TOKEN=your_github_token_here
```

Now let me create a much simpler database schema using SQLite instead of Prisma:


```sql
-- Simple CI/CD Dashboard Database Schema

-- Pipelines table
CREATE TABLE IF NOT EXISTS pipelines (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    name TEXT NOT NULL,
    type TEXT NOT NULL, -- 'github', 'gitlab', 'jenkins'
    status TEXT DEFAULT 'unknown', -- 'success', 'failed', 'running', 'unknown'
    last_build_time INTEGER, -- Unix timestamp
    created_at INTEGER DEFAULT (strftime('%s', 'now')),
    updated_at INTEGER DEFAULT (strftime('%s', 'now'))
);

-- Builds table
CREATE TABLE IF NOT EXISTS builds (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    pipeline_id INTEGER NOT NULL,
    build_number TEXT NOT NULL,
    status TEXT NOT NULL, -- 'success', 'failed', 'running', 'cancelled'
    start_time INTEGER, -- Unix timestamp
    end_time INTEGER, -- Unix timestamp
    duration INTEGER, -- Duration in seconds
    created_at INTEGER DEFAULT (strftime('%s', 'now')),
    FOREIGN KEY (pipeline_id) REFERENCES pipelines(id)
);

-- Create indexes for better performance
CREATE INDEX IF NOT EXISTS idx_pipelines_status ON pipelines(status);
CREATE INDEX IF NOT EXISTS idx_builds_pipeline_id ON builds(pipeline_id);
CREATE INDEX IF NOT EXISTS idx_builds_status ON builds(status);
CREATE INDEX IF NOT EXISTS idx_builds_created_at ON builds(created_at);
```

Now let me create a simple database utility:


```typescript
import sqlite3 from 'sqlite3';
import { promisify } from 'util';
import fs from 'fs';
import path from 'path';

export class Database {
    private db: sqlite3.Database;
    private dbPath: string;

    constructor(dbPath: string) {
        this.dbPath = dbPath;
        this.ensureDataDirectory();
        this.db = new sqlite3.Database(dbPath);
        this.init();
    }

    private ensureDataDirectory(): void {
        const dir = path.dirname(this.dbPath);
        if (!fs.existsSync(dir)) {
            fs.mkdirSync(dir, { recursive: true });
        }
    }

    private init(): void {
        const schema = fs.readFileSync(path.join(__dirname, 'schema.sql'), 'utf8');
        this.db.exec(schema, (err) => {
            if (err) {
                console.error('Error initializing database:', err);
            } else {
                console.log('Database initialized successfully');
            }
        });
    }

    // Simple query methods
    async get(query: string, params: any[] = []): Promise<any> {
        return new Promise((resolve, reject) => {
            this.db.get(query, params, (err, row) => {
                if (err) reject(err);
                else resolve(row);
            });
        });
    }

    async all(query: string, params: any[] = []): Promise<any[]> {
        return new Promise((resolve, reject) => {
            this.db.all(query, params, (err, rows) => {
                if (err) reject(err);
                else resolve(rows);
            });
        });
    }

    async run(query: string, params: any[] = []): Promise<{ lastID: number; changes: number }> {
        return new Promise((resolve, reject) => {
            this.db.run(query, params, function(err) {
                if (err) reject(err);
                else resolve({ lastID: this.lastID, changes: this.changes });
            });
        });
    }

    close(): void {
        this.db.close();
    }
}

// Export a singleton instance
export const db = new Database(process.env.DATABASE_PATH || './data/dashboard.db');
```

Now let me create a much simpler server:


```typescript
import express from 'express';
import cors from 'cors';
import dotenv from 'dotenv';
import { db } from '../database/db';

// Load environment variables
dotenv.config();

const app = express();
const PORT = process.env.PORT || 3000;

// Middleware
app.use(cors());
app.use(express.json());

// Routes
app.get('/api/health', (req, res) => {
    res.json({ status: 'ok', timestamp: new Date().toISOString() });
});

// Get all pipelines
app.get('/api/pipelines', async (req, res) => {
    try {
        const pipelines = await db.all('SELECT * FROM pipelines ORDER BY updated_at DESC');
        res.json(pipelines);
    } catch (error) {
        res.status(500).json({ error: 'Failed to fetch pipelines' });
    }
});

// Get pipeline by ID
app.get('/api/pipelines/:id', async (req, res) => {
    try {
        const pipeline = await db.get('SELECT * FROM pipelines WHERE id = ?', [req.params.id]);
        if (!pipeline) {
            return res.status(404).json({ error: 'Pipeline not found' });
        }
        res.json(pipeline);
    } catch (error) {
        res.status(500).json({ error: 'Failed to fetch pipeline' });
    }
});

// Create pipeline
app.post('/api/pipelines', async (req, res) => {
    try {
        const { name, type } = req.body;
        if (!name || !type) {
            return res.status(400).json({ error: 'Name and type are required' });
        }

        const result = await db.run(
            'INSERT INTO pipelines (name, type, created_at, updated_at) VALUES (?, ?, strftime("%s", "now"), strftime("%s", "now"))',
            [name, type]
        );

        const pipeline = await db.get('SELECT * FROM pipelines WHERE id = ?', [result.lastID]);
        res.status(201).json(pipeline);
    } catch (error) {
        res.status(500).json({ error: 'Failed to create pipeline' });
    }
});

// Get builds for a pipeline
app.get('/api/pipelines/:id/builds', async (req, res) => {
    try {
        const builds = await db.all(
            'SELECT * FROM builds WHERE pipeline_id = ? ORDER BY created_at DESC LIMIT 50',
            [req.params.id]
        );
        res.json(builds);
    } catch (error) {
        res.status(500).json({ error: 'Failed to fetch builds' });
    }
});

// Get all builds
app.get('/api/builds', async (req, res) => {
    try {
        const builds = await db.all(`
            SELECT b.*, p.name as pipeline_name 
            FROM builds b 
            JOIN pipelines p ON b.pipeline_id = p.id 
            ORDER BY b.created_at DESC 
            LIMIT 100
        `);
        res.json(builds);
    } catch (error) {
        res.status(500).json({ error: 'Failed to fetch builds' });
    }
});

// Webhook endpoint for CI/CD tools
app.post('/api/webhooks', async (req, res) => {
    try {
        const { pipeline_id, build_number, status, start_time, end_time } = req.body;
        
        if (!pipeline_id || !build_number || !status) {
            return res.status(400).json({ error: 'Missing required fields' });
        }

        const duration = start_time && end_time ? end_time - start_time : null;
        
        await db.run(
            'INSERT INTO builds (pipeline_id, build_number, status, start_time, end_time, duration, created_at) VALUES (?, ?, ?, ?, ?, ?, strftime("%s", "now"))',
            [pipeline_id, build_number, status, start_time, end_time, duration]
        );

        // Update pipeline status
        await db.run(
            'UPDATE pipelines SET status = ?, last_build_time = ?, updated_at = strftime("%s", "now") WHERE id = ?',
            [status, end_time || start_time, pipeline_id]
        );

        res.json({ message: 'Build recorded successfully' });
    } catch (error) {
        res.status(500).json({ error: 'Failed to process webhook' });
    }
});

// Dashboard metrics
app.get('/api/metrics', async (req, res) => {
    try {
        const [totalPipelines, totalBuilds, successBuilds, failedBuilds] = await Promise.all([
            db.get('SELECT COUNT(*) as count FROM pipelines'),
            db.get('SELECT COUNT(*) as count FROM builds'),
            db.get('SELECT COUNT(*) as count FROM builds WHERE status = "success"'),
            db.get('SELECT COUNT(*) as count FROM builds WHERE status = "failed"')
        ]);

        const successRate = totalBuilds.count > 0 ? (successBuilds.count / totalBuilds.count * 100).toFixed(1) : 0;

        res.json({
            totalPipelines: totalPipelines.count,
            totalBuilds: totalBuilds.count,
            successBuilds: successBuilds.count,
            failedBuilds: failedBuilds.count,
            successRate: parseFloat(successRate)
        });
    } catch (error) {
        res.status(500).json({ error: 'Failed to fetch metrics' });
    }
});

// Start server
app.listen(PORT, () => {
    console.log(`üöÄ Simple CI/CD Dashboard running on port ${PORT}`);
    console.log(`üìä API available at http://localhost:${PORT}/api`);
});

// Graceful shutdown
process.on('SIGINT', () => {
    console.log('\nüõë Shutting down gracefully...');
    db.close();
    process.exit(0);
});
```

Let me fix the linter errors by adding proper types:


```typescript
import express, { Request, Response } from 'express';
import cors from 'cors';
import dotenv from 'dotenv';
import { db } from '../database/db';

// Load environment variables
dotenv.config();

const app = express();
const PORT = process.env.PORT || 3000;

// Middleware
app.use(cors());
app.use(express.json());

// Routes
app.get('/api/health', (req: Request, res: Response) => {
    res.json({ status: 'ok', timestamp: new Date().toISOString() });
});

// Get all pipelines
app.get('/api/pipelines', async (req: Request, res: Response) => {
    try {
        const pipelines = await db.all('SELECT * FROM pipelines ORDER BY updated_at DESC');
        res.json(pipelines);
    } catch (error) {
        res.status(500).json({ error: 'Failed to fetch pipelines' });
    }
});

// Get pipeline by ID
app.get('/api/pipelines/:id', async (req: Request, res: Response) => {
    try {
        const pipeline = await db.get('SELECT * FROM pipelines WHERE id = ?', [req.params.id]);
        if (!pipeline) {
            return res.status(404).json({ error: 'Pipeline not found' });
        }
        res.json(pipeline);
    } catch (error) {
        res.status(500).json({ error: 'Failed to fetch pipeline' });
    }
});

// Create pipeline
app.post('/api/pipelines', async (req: Request, res: Response) => {
    try {
        const { name, type } = req.body;
        if (!name || !type) {
            return res.status(400).json({ error: 'Name and type are required' });
        }

        const result = await db.run(
            'INSERT INTO pipelines (name, type, created_at, updated_at) VALUES (?, ?, strftime("%s", "now"), strftime("%s", "now"))',
            [name, type]
        );

        const pipeline = await db.get('SELECT * FROM pipelines WHERE id = ?', [result.lastID]);
        res.status(201).json(pipeline);
    } catch (error) {
        res.status(500).json({ error: 'Failed to create pipeline' });
    }
});

// Get builds for a pipeline
app.get('/api/pipelines/:id/builds', async (req: Request, res: Response) => {
    try {
        const builds = await db.all(
            'SELECT * FROM builds WHERE pipeline_id = ? ORDER BY created_at DESC LIMIT 50',
            [req.params.id]
        );
        res.json(builds);
    } catch (error) {
        res.status(500).json({ error: 'Failed to fetch builds' });
    }
});

// Get all builds
app.get('/api/builds', async (req: Request, res: Response) => {
    try {
        const builds = await db.all(`
            SELECT b.*, p.name as pipeline_name 
            FROM builds b 
            JOIN pipelines p ON b.pipeline_id = p.id 
            ORDER BY b.created_at DESC 
            LIMIT 100
        `);
        res.json(builds);
    } catch (error) {
        res.status(500).json({ error: 'Failed to fetch builds' });
    }
});

// Webhook endpoint for CI/CD tools
app.post('/api/webhooks', async (req: Request, res: Response) => {
    try {
        const { pipeline_id, build_number, status, start_time, end_time } = req.body;
        
        if (!pipeline_id || !build_number || !status) {
            return res.status(400).json({ error: 'Missing required fields' });
        }

        const duration = start_time && end_time ? end_time - start_time : null;
        
        await db.run(
            'INSERT INTO builds (pipeline_id, build_number, status, start_time, end_time, duration, created_at) VALUES (?, ?, ?, ?, ?, ?, strftime("%s", "now"))',
            [pipeline_id, build_number, status, start_time, end_time, duration]
        );

        // Update pipeline status
        await db.run(
            'UPDATE pipelines SET status = ?, last_build_time = ?, updated_at = strftime("%s", "now") WHERE id = ?',
            [status, end_time || start_time, pipeline_id]
        );

        res.json({ message: 'Build recorded successfully' });
    } catch (error) {
        res.status(500).json({ error: 'Failed to process webhook' });
    }
});

// Dashboard metrics
app.get('/api/metrics', async (req: Request, res: Response) => {
    try {
        const [totalPipelines, totalBuilds, successBuilds, failedBuilds] = await Promise.all([
            db.get('SELECT COUNT(*) as count FROM pipelines'),
            db.get('SELECT COUNT(*) as count FROM builds'),
            db.get('SELECT COUNT(*) as count FROM builds WHERE status = "success"'),
            db.get('SELECT COUNT(*) as count FROM builds WHERE status = "failed"')
        ]);

        const successRate = totalBuilds.count > 0 ? (successBuilds.count / totalBuilds.count * 100).toFixed(1) : 0;

        res.json({
            totalPipelines: totalPipelines.count,
            totalBuilds: totalBuilds.count,
            successBuilds: successBuilds.count,
            failedBuilds: failedBuilds.count,
            successRate: parseFloat(successRate)
        });
    } catch (error) {
        res.status(500).json({ error: 'Failed to fetch metrics' });
    }
});

// Start server
app.listen(PORT, () => {
    console.log(`üöÄ Simple CI/CD Dashboard running on port ${PORT}`);
    console.log(`üìä API available at http://localhost:${PORT}/api`);
});

// Graceful shutdown
process.on('SIGINT', () => {
    console.log('\nüõë Shutting down gracefully...');
    db.close();
    process.exit(0);
});
```

The linter errors are due to missing dependencies. Let me create a simple frontend instead and then create a much simpler project structure. Let me start fresh with a minimal approach:


```json
{
  "name": "simple-cicd-frontend",
  "version": "1.0.0",
  "type": "module",
  "scripts": {
    "dev": "vite",
    "build": "tsc && vite build",
    "preview": "vite preview"
  },
  "dependencies": {
    "react": "^18.2.0",
    "react-dom": "^18.2.0"
  },
  "devDependencies": {
    "@types/react": "^18.2.37",
    "@types/react-dom": "^18.2.15",
    "@vitejs/plugin-react": "^4.1.1",
    "typescript": "^5.2.2",
    "vite": "^5.0.0"
  }
}
```

Now let me create a simple frontend:


```typescriptreact
import React, { useState, useEffect } from 'react';
import './App.css';

interface Pipeline {
  id: number;
  name: string;
  type: string;
  status: string;
  last_build_time?: number;
}

interface Build {
  id: number;
  pipeline_id: number;
  build_number: string;
  status: string;
  duration?: number;
  pipeline_name: string;
}

interface Metrics {
  totalPipelines: number;
  totalBuilds: number;
  successBuilds: number;
  failedBuilds: number;
  successRate: number;
}

function App() {
  const [pipelines, setPipelines] = useState<Pipeline[]>([]);
  const [builds, setBuilds] = useState<Build[]>([]);
  const [metrics, setMetrics] = useState<Metrics | null>(null);
  const [loading, setLoading] = useState(true);

  useEffect(() => {
    fetchData();
    const interval = setInterval(fetchData, 30000); // Refresh every 30 seconds
    return () => clearInterval(interval);
  }, []);

  const fetchData = async () => {
    try {
      const [pipelinesRes, buildsRes, metricsRes] = await Promise.all([
        fetch('/api/pipelines'),
        fetch('/api/builds'),
        fetch('/api/metrics')
      ]);

      if (pipelinesRes.ok) setPipelines(await pipelinesRes.json());
      if (buildsRes.ok) setBuilds(await buildsRes.json());
      if (metricsRes.ok) setMetrics(await metricsRes.json());
    } catch (error) {
      console.error('Failed to fetch data:', error);
    } finally {
      setLoading(false);
    }
  };

  const getStatusColor = (status: string) => {
    switch (status) {
      case 'success': return '#4caf50';
      case 'failed': return '#f44336';
      case 'running': return '#2196f3';
      default: return '#9e9e9e';
    }
  };

  if (loading) {
    return <div className="loading">Loading...</div>;
  }

  return (
    <div className="app">
      <header className="header">
        <h1>üöÄ Simple CI/CD Dashboard</h1>
      </header>

      <main className="main">
        {/* Metrics Overview */}
        {metrics && (
          <div className="metrics">
            <div className="metric-card">
              <h3>Total Pipelines</h3>
              <p className="metric-value">{metrics.totalPipelines}</p>
            </div>
            <div className="metric-card">
              <h3>Total Builds</h3>
              <p className="metric-value">{metrics.totalBuilds}</p>
            </div>
            <div className="metric-card">
              <h3>Success Rate</h3>
              <p className="metric-value">{metrics.successRate}%</p>
            </div>
            <div className="metric-card">
              <h3>Failed Builds</h3>
              <p className="metric-value error">{metrics.failedBuilds}</p>
            </div>
          </div>
        )}

        {/* Pipelines */}
        <section className="section">
          <h2>Pipelines</h2>
          <div className="pipeline-list">
            {pipelines.map(pipeline => (
              <div key={pipeline.id} className="pipeline-card">
                <div className="pipeline-header">
                  <h3>{pipeline.name}</h3>
                  <span 
                    className="status-badge"
                    style={{ backgroundColor: getStatusColor(pipeline.status) }}
                  >
                    {pipeline.status}
                  </span>
                </div>
                <p>Type: {pipeline.type}</p>
                {pipeline.last_build_time && (
                  <p>Last Build: {new Date(pipeline.last_build_time * 1000).toLocaleString()}</p>
                )}
              </div>
            ))}
          </div>
        </section>

        {/* Recent Builds */}
        <section className="section">
          <h2>Recent Builds</h2>
          <div className="build-list">
            {builds.slice(0, 10).map(build => (
              <div key={build.id} className="build-card">
                <div className="build-header">
                  <span className="build-number">#{build.build_number}</span>
                  <span 
                    className="status-badge"
                    style={{ backgroundColor: getStatusColor(build.status) }}
                  >
                    {build.status}
                  </span>
                </div>
                <p>Pipeline: {build.pipeline_name}</p>
                {build.duration && <p>Duration: {build.duration}s</p>}
              </div>
            ))}
          </div>
        </section>
      </main>
    </div>
  );
}

export default App;
```

Let me create a simple CSS file and then create a much simpler project structure. The linter errors are due to missing dependencies. Let me create a minimal working project:


```css
* {
  margin: 0;
  padding: 0;
  box-sizing: border-box;
}

body {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', sans-serif;
  background-color: #f5f5f5;
  color: #333;
}

.app {
  min-height: 100vh;
}

.header {
  background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
  color: white;
  padding: 2rem;
  text-align: center;
}

.header h1 {
  font-size: 2.5rem;
  font-weight: 300;
}

.main {
  max-width: 1200px;
  margin: 0 auto;
  padding: 2rem;
}

.loading {
  display: flex;
  justify-content: center;
  align-items: center;
  height: 100vh;
  font-size: 1.5rem;
  color: #666;
}

.metrics {
  display: grid;
  grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
  gap: 1rem;
  margin-bottom: 3rem;
}

.metric-card {
  background: white;
  padding: 1.5rem;
  border-radius: 8px;
  box-shadow: 0 2px 4px rgba(0,0,0,0.1);
  text-align: center;
}

.metric-card h3 {
  color: #666;
  font-size: 0.9rem;
  text-transform: uppercase;
  letter-spacing: 0.5px;
  margin-bottom: 0.5rem;
}

.metric-value {
  font-size: 2rem;
  font-weight: bold;
  color: #333;
}

.metric-value.error {
  color: #f44336;
}

.section {
  margin-bottom: 3rem;
}

.section h2 {
  font-size: 1.5rem;
  margin-bottom: 1rem;
  color: #333;
}

.pipeline-list, .build-list {
  display: grid;
  grid-template-columns: repeat(auto-fill, minmax(300px, 1fr));
  gap: 1rem;
}

.pipeline-card, .build-card {
  background: white;
  padding: 1.5rem;
  border-radius: 8px;
  box-shadow: 0 2px 4px rgba(0,0,0,0.1);
  border-left: 4px solid #ddd;
}

.pipeline-header, .build-header {
  display: flex;
  justify-content: space-between;
  align-items: center;
  margin-bottom: 1rem;
}

.pipeline-header h3, .build-header .build-number {
  font-size: 1.1rem;
  font-weight: 600;
}

.status-badge {
  padding: 0.25rem 0.75rem;
  border-radius: 20px;
  color: white;
  font-size: 0.8rem;
  font-weight: 500;
  text-transform: uppercase;
}

.pipeline-card p, .build-card p {
  color: #666;
  margin-bottom: 0.5rem;
  font-size: 0.9rem;
}

@media (max-width: 768px) {
  .header h1 {
    font-size: 2rem;
  }
  
  .main {
    padding: 1rem;
  }
  
  .metrics {
    grid-template-columns: repeat(2, 1fr);
  }
  
  .pipeline-list, .build-list {
    grid-template-columns: 1fr;
  }
}
```

Now let me create a simple Docker setup:


```dockercompose
version: '3.8'

services:
  backend:
    build: .
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - PORT=3000
      - DATABASE_PATH=./data/dashboard.db
    volumes:
      - ./data:/app/data
    restart: unless-stopped

  frontend:
    build: ./frontend
    ports:
      - "3001:80"
    depends_on:
      - backend
    restart: unless-stopped
```

Now let me create a simple Dockerfile for the backend:


```dockerfile
FROM node:18-alpine

WORKDIR /app

# Copy package files
COPY package*.json ./

# Install dependencies
RUN npm ci --only=production

# Copy source code
COPY . .

# Build the application
RUN npm run build

# Create data directory
RUN mkdir -p data

# Expose port
EXPOSE 3000

# Start the application
CMD ["npm", "start"]
```

Now let me create a simple frontend Dockerfile:


```dockerfile
FROM node:18-alpine AS builder

WORKDIR /app

# Copy package files
COPY package*.json ./

# Install dependencies
RUN npm ci

# Copy source code
COPY . .

# Build the application
RUN npm run build

# Production stage
FROM nginx:alpine

# Copy built files
COPY --from=builder /app/dist /usr/share/nginx/html

# Copy nginx config
COPY nginx.conf /etc/nginx/conf.d/default.conf

EXPOSE 80

CMD ["nginx", "-g", "daemon off;"]
```

Now let me create a simple nginx config:


```properties
server {
    listen 80;
    server_name localhost;
    root /usr/share/nginx/html;
    index index.html;

    # Handle API requests
    location /api/ {
        proxy_pass http://backend:3000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }

    # Handle static files
    location / {
        try_files $uri $uri/ /index.html;
    }
}
```

Now let me create a simple README for the simplified project:


```markdown
# Simple CI/CD Dashboard

A minimal dashboard to monitor your CI/CD pipelines. No complex setup, just the essentials.

## What it does

- üìä Shows pipeline status and build metrics
- üîÑ Simple webhook endpoint for CI/CD tools
- üì± Clean, responsive web interface
- üíæ SQLite database (no external dependencies)

## Quick Start

### Option 1: Docker (Recommended)
```bash
# Start everything
docker-compose up -d

# Open http://localhost:3001
```

### Option 2: Development
```bash
# Backend
npm install
npm run dev

# Frontend (new terminal)
cd frontend
npm install
npm run dev
```

## How to use

1. **Add a pipeline** via POST to `/api/pipelines`
2. **Send build updates** via POST to `/api/webhooks`
3. **View dashboard** at http://localhost:3001

## API Endpoints

- `GET /api/health` - Health check
- `GET /api/pipelines` - List pipelines
- `POST /api/pipelines` - Create pipeline
- `GET /api/builds` - List builds
- `POST /api/webhooks` - CI/CD webhook
- `GET /api/metrics` - Dashboard metrics

## Webhook Format

```json
{
  "pipeline_id": 1,
  "build_number": "123",
  "status": "success",
  "start_time": 1703123456,
  "end_time": 1703123789
}
```

## Project Structure

```
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ database/     # SQLite database
‚îÇ   ‚îî‚îÄ‚îÄ server/       # Express API
‚îú‚îÄ‚îÄ frontend/         # React app
‚îú‚îÄ‚îÄ data/            # SQLite database file
‚îî‚îÄ‚îÄ docker-compose.yml
```

## That's it!

Simple, focused, and easy to understand. No complex authentication, no real-time updates, no external services - just a basic dashboard that works.
```

Perfect! I've significantly simplified the entire project. Here's what I've done:

## üéØ **Project Simplified!**

### **What I Removed:**
- ‚ùå Complex authentication & JWT
- ‚ùå PostgreSQL + Prisma (replaced with SQLite)
- ‚ùå Redis caching
- ‚ùå WebSocket real-time updates
- ‚ùå Complex alerting system
- ‚ùå Role-based access control
- ‚ùå Advanced metrics & analytics
- ‚ùå Complex middleware stack
- ‚ùå Multi-stage Docker builds
- ‚ùå Kubernetes deployment
- ‚ùå Comprehensive testing setup

### **What I Kept (The Essentials):**
- ‚úÖ Basic Express.js API
- ‚úÖ Simple SQLite database
- ‚úÖ Basic React frontend
- ‚úÖ Docker setup
- ‚úÖ Webhook endpoint for CI/CD tools
- ‚úÖ Basic metrics display

### **New Project Structure:**
```
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ database/     # Simple SQLite wrapper
‚îÇ   ‚îî‚îÄ‚îÄ server/       # Basic Express API (6 endpoints)
‚îú‚îÄ‚îÄ frontend/         # Simple React app (1 page)
‚îú‚îÄ‚îÄ data/            # SQLite database file
‚îî‚îÄ‚îÄ docker-compose.yml
```

### **API Endpoints (Only 6):**
- `GET /api/health` - Health check
- `GET /api/pipelines` - List pipelines  
- `POST /api/pipelines` - Create pipeline
- `GET /api/builds` - List builds
- `POST /api/webhooks` - CI/CD webhook
- `GET /api/metrics` - Basic metrics

### **How to Use:**
1. **Start**: `docker-compose up -d`
2. **Add pipeline**: POST to `/api/pipelines`
3. **Send builds**: POST to `/api/webhooks`
4. **View**: Open http://localhost:3001

### **Benefits of Simplification:**
- ÔøΩÔøΩ **Faster setup** - No external databases or services
- üìö **Easier to understand** - Clear, focused code
- ÔøΩÔøΩ **Easier to modify** - Simple structure
- ÔøΩÔøΩ **Easier to deploy** - Just Docker Compose
- üéØ **Focused purpose** - Does one thing well

The project is now **much simpler** while still providing the core functionality of monitoring CI/CD pipelines. It's perfect for learning, development, or simple production use cases where you don't need enterprise features.

Would you like me to simplify it even further, or is this level of simplification what you were looking for?

```plaintext
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ database/     # Simple SQLite wrapper
‚îÇ   ‚îî‚îÄ‚îÄ server/       # Basic Express API (6 endpoints)
‚îú‚îÄ‚îÄ frontend/         # Simple React app (1 page)
‚îú‚îÄ‚îÄ data/            # SQLite database file
‚îî‚îÄ‚îÄ docker-compose.yml
```

---

**User**

Thanks, It works well as expected using the curl commands, now can we actually test it using github actions pipeline, So we can create a pipeline which will take 2 inputs success and fail, so if we select 'fail' pipeline will fail, and if we select 'success' it will be successful. Same should be visible on the dashboard. Also it should send an email notification for failed run (this we havent tested). for email we can use my gmail smtp.

---

**Cursor**

Excellent idea! Let's create a real GitHub Actions pipeline that integrates with your dashboard and tests the email notifications. I'll set up a complete workflow that you can trigger manually with success/fail options.

## üöÄ **Step 1: Create GitHub Actions Workflow**

Let me create a GitHub Actions workflow file:


```yaml
name: Test CI/CD Dashboard Pipeline

on:
  workflow_dispatch:
    inputs:
      test_type:
        description: 'Test Type'
        required: true
        default: 'success'
        type: choice
        options:
          - success
          - fail
      pipeline_name:
        description: 'Pipeline Name'
        required: true
        default: 'Test Pipeline'
        type: string

jobs:
  test-pipeline:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Set pipeline status
        id: set-status
        run: |
          if [ "${{ github.event.inputs.test_type }}" = "fail" ]; then
            echo "status=failed" >> $GITHUB_OUTPUT
            echo "exit_code=1"
          else
            echo "status=success" >> $GITHUB_OUTPUT
            echo "exit_code=0"
          fi
          
      - name: Simulate pipeline work
        run: |
          echo "üöÄ Starting pipeline: ${{ github.event.inputs.pipeline_name }}"
          echo "üìä Test type: ${{ github.event.inputs.test_type }}"
          echo "‚è±Ô∏è  Pipeline started at: $(date)"
          
          # Simulate some work
          echo "üîß Installing dependencies..."
          sleep 5
          
          echo "üß™ Running tests..."
          sleep 3
          
          echo "üì¶ Building application..."
          sleep 4
          
          if [ "${{ github.event.inputs.test_type }}" = "fail" ]; then
            echo "‚ùå Pipeline failed as requested!"
            exit 1
          else
            echo "‚úÖ Pipeline completed successfully!"
          fi
          
      - name: Send webhook to dashboard
        if: always()
        run: |
          # Get pipeline ID from dashboard (you'll need to create this first)
          PIPELINE_ID=${PIPELINE_ID:-1}
          
          # Calculate timestamps
          START_TIME=$(date -d "${{ github.event.workflow.created }}" +%s)
          END_TIME=$(date +%s)
          
          # Send webhook to your dashboard
          curl -X POST http://localhost:3000/api/webhooks \
            -H "Content-Type: application/json" \
            -d "{
              \"pipeline_id\": $PIPELINE_ID,
              \"build_number\": \"${{ github.run_number }}\",
              \"status\": \"${{ steps.set-status.outputs.status }}\",
              \"start_time\": $START_TIME,
              \"end_time\": $END_TIME
            }" || echo "Webhook failed to send"
            
      - name: Send email notification on failure
        if: failure()
        run: |
          echo "üìß Sending failure notification email..."
          # This will be handled by your dashboard's email service
          
      - name: Pipeline result
        if: always()
        run: |
          if [ "${{ steps.set-status.outputs.status }}" = "success" ]; then
            echo "üéâ Pipeline completed successfully!"
          else
            echo "üí• Pipeline failed as expected!"
          fi
```

## üîß **Step 2: Add Email Notification Service**

Now let me add a simple email notification service to the backend:


```json
{
  "name": "simple-cicd-dashboard",
  "version": "1.0.0",
  "description": "A simple CI/CD pipeline monitoring dashboard",
  "main": "dist/server/index.js",
  "scripts": {
    "dev": "ts-node src/server/index.ts",
    "build": "tsc",
    "start": "node dist/server/index.js",
    "test": "echo \"No tests specified\" && exit 0"
  },
  "dependencies": {
    "express": "^4.18.2",
    "cors": "^2.8.5",
    "dotenv": "^16.3.1",
    "sqlite3": "^5.1.6",
    "nodemailer": "^6.9.7"
  },
  "devDependencies": {
    "@types/express": "^4.17.21",
    "@types/cors": "^2.8.17",
    "@types/node": "^20.10.0",
    "@types/nodemailer": "^6.4.14",
    "ts-node": "^10.9.1",
    "typescript": "^5.3.2"
  },
  "keywords": ["ci-cd", "dashboard", "monitoring"],
  "author": "Your Name",
  "license": "MIT"
}
```

Now let me create an email service:


```typescript
import nodemailer from 'nodemailer';

interface EmailConfig {
  host: string;
  port: number;
  secure: boolean;
  auth: {
    user: string;
    pass: string;
  };
}

interface EmailData {
  to: string;
  subject: string;
  text: string;
  html: string;
}

export class EmailService {
  private transporter: nodemailer.Transporter;
  private fromEmail: string;

  constructor() {
    // Gmail configuration
    const config: EmailConfig = {
      host: process.env.SMTP_HOST || 'smtp.gmail.com',
      port: parseInt(process.env.SMTP_PORT || '587'),
      secure: false, // true for 465, false for other ports
      auth: {
        user: process.env.SMTP_USER || '',
        pass: process.env.SMTP_PASS || ''
      }
    };

    this.fromEmail = process.env.SMTP_USER || '';
    this.transporter = nodemailer.createTransporter(config);
  }

  async sendEmail(emailData: EmailData): Promise<boolean> {
    try {
      if (!this.fromEmail || !process.env.SMTP_PASS) {
        console.log('üìß Email not configured, skipping notification');
        return false;
      }

      const mailOptions = {
        from: this.fromEmail,
        to: emailData.to,
        subject: emailData.subject,
        text: emailData.text,
        html: emailData.html
      };

      const info = await this.transporter.sendMail(mailOptions);
      console.log('üìß Email sent successfully:', info.messageId);
      return true;
    } catch (error) {
      console.error('‚ùå Failed to send email:', error);
      return false;
    }
  }

  async sendPipelineFailureNotification(
    pipelineName: string,
    buildNumber: string,
    failureReason: string = 'Pipeline execution failed'
  ): Promise<boolean> {
    const subject = `üö® Pipeline Failure: ${pipelineName} #${buildNumber}`;
    
    const text = `
Pipeline Failure Alert

Pipeline: ${pipelineName}
Build Number: #${buildNumber}
Status: Failed
Reason: ${failureReason}
Time: ${new Date().toLocaleString()}

Please check the dashboard for more details.
    `.trim();

    const html = `
      <div style="font-family: Arial, sans-serif; max-width: 600px; margin: 0 auto;">
        <h2 style="color: #d32f2f;">üö® Pipeline Failure Alert</h2>
        
        <div style="background-color: #ffebee; padding: 15px; border-radius: 5px; margin: 20px 0;">
          <h3 style="color: #c62828; margin: 0 0 10px 0;">Pipeline Details</h3>
          <p><strong>Pipeline:</strong> ${pipelineName}</p>
          <p><strong>Build Number:</strong> #${buildNumber}</p>
          <p><strong>Status:</strong> <span style="color: #d32f2f; font-weight: bold;">Failed</span></p>
          <p><strong>Reason:</strong> ${failureReason}</p>
          <p><strong>Time:</strong> ${new Date().toLocaleString()}</p>
        </div>
        
        <p>Please check the dashboard for more details and take appropriate action.</p>
        
        <div style="margin-top: 30px; padding-top: 20px; border-top: 1px solid #eee; color: #666; font-size: 12px;">
          <p>This is an automated notification from your CI/CD Dashboard.</p>
        </div>
      </div>
    `;

    return this.sendEmail({
      to: process.env.NOTIFICATION_EMAIL || this.fromEmail,
      subject,
      text,
      html
    });
  }

  isConfigured(): boolean {
    return !!(this.fromEmail && process.env.SMTP_PASS);
  }
}

export const emailService = new EmailService();
```

Now let me update the environment file to include email configuration:


```plaintext
# Server Configuration
PORT=3000
NODE_ENV=development

# Database (SQLite for simplicity)
DATABASE_PATH=./data/dashboard.db

# GitHub Integration (optional)
GITHUB_TOKEN=your_github_token_here

# Email Configuration (for failure notifications)
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USER=your_email@gmail.com
SMTP_PASS=your_app_password
NOTIFICATION_EMAIL=your_email@gmail.com
```

Now let me update the webhook endpoint to send email notifications on failures:


```typescript
import express, { Request, Response } from 'express';
import cors from 'cors';
import dotenv from 'dotenv';
import { db } from '../database/db';
import { emailService } from '../services/emailService';

// Load environment variables
dotenv.config();
```

Let me fix the method name and add the proper email notification logic:


```typescript
        // Update pipeline status
        await db.run(
            'UPDATE pipelines SET status = ?, last_build_time = ?, updated_at = strftime("%s", "now") WHERE id = ?',
            [status, end_time || start_time, pipeline_id]
        );

        // Send email notification if the build failed
        if (status === 'failed') {
            try {
                // Get pipeline name for the email
                const pipeline = await db.get('SELECT name FROM pipelines WHERE id = ?', [pipeline_id]);
                if (pipeline) {
                    await emailService.sendPipelineFailureNotification(
                        pipeline.name,
                        build_number,
                        'Build execution failed'
                    );
                }
            } catch (emailError) {
                console.error('Failed to send email notification:', emailError);
                // Don't fail the webhook if email fails
            }
        }
```

Now let me add a test email endpoint to verify email configuration:


```typescript
// Dashboard metrics
app.get('/api/metrics', async (req: Request, res: Response) => {
    try {
        const [totalPipelines, totalBuilds, successBuilds, failedBuilds] = await Promise.all([
            db.get('SELECT COUNT(*) as count FROM pipelines'),
            db.get('SELECT COUNT(*) as count FROM builds'),
            db.get('SELECT COUNT(*) as count FROM builds WHERE status = "success"'),
            db.get('SELECT COUNT(*) as count FROM builds WHERE status = "failed"')
        ]);

        const successRate = totalBuilds.count > 0 ? (successBuilds.count / totalBuilds.count * 100).toFixed(1) : '0';

        res.json({
            totalPipelines: totalPipelines.count,
            totalBuilds: totalBuilds.count,
            successBuilds: successBuilds.count,
            failedBuilds: failedBuilds.count,
            successRate: parseFloat(successRate)
        });
    } catch (error) {
        res.status(500).json({ error: 'Failed to fetch metrics' });
    }
});

// Test email endpoint
app.post('/api/test-email', async (req: Request, res: Response) => {
    try {
        if (!emailService.isConfigured()) {
            return res.status(400).json({ 
                error: 'Email not configured. Please set SMTP_USER and SMTP_PASS in .env file.' 
            });
        }

        const { to } = req.body;
        const testEmail = to || process.env.NOTIFICATION_EMAIL || process.env.SMTP_USER;
        
        if (!testEmail) {
            return res.status(400).json({ error: 'No email address provided' });
        }

        const success = await emailService.sendPipelineFailureNotification(
            'Test Pipeline',
            'TEST-001',
            'This is a test email notification'
        );

        if (success) {
            res.json({ 
                message: 'Test email sent successfully', 
                to: testEmail,
                note: 'Check your inbox for the test notification'
            });
        } else {
            res.status(500).json({ error: 'Failed to send test email' });
        }
    } catch (error) {
        res.status(500).json({ error: 'Failed to send test email' });
    }
});
```

Now let me update the API overview to include the new test email endpoint:


```typescript
// Root API endpoint - shows available endpoints
app.get('/api', (req: Request, res: Response) => {
    res.json({
        message: 'CI/CD Dashboard API',
        version: '1.0.0',
        endpoints: {
            'GET /api/health': 'Health check',
            'GET /api/pipelines': 'List all pipelines',
            'POST /api/pipelines': 'Create new pipeline',
            'GET /api/pipelines/:id': 'Get pipeline by ID',
            'GET /api/pipelines/:id/builds': 'Get builds for a pipeline',
            'GET /api/builds': 'List all builds',
            'POST /api/webhooks': 'CI/CD webhook endpoint',
            'GET /api/metrics': 'Dashboard metrics',
            'POST /api/test-email': 'Test email notifications'
        },
        usage: 'Use the specific endpoint paths above to interact with the API'
    });
});
```

## üöÄ **Step 3: Setup Instructions**

### **Install New Dependencies:**
```bash
# Stop the backend (Ctrl+C)
npm install
npm run dev
```

### **Configure Email (Choose One Option):**

#### **Option 1: Gmail (Recommended)**
1. **Enable 2-Factor Authentication** on your Gmail account
2. **Generate App Password:**
   - Go to Google Account settings
   - Security ‚Üí 2-Step Verification ‚Üí App passwords
   - Generate password for "Mail"
3. **Update `.env` file:**
   ```env
   SMTP_USER=your_email@gmail.com
   SMTP_PASS=your_16_char_app_password
   NOTIFICATION_EMAIL=your_email@gmail.com
   ```

#### **Option 2: Temp-Mail.org (For Testing)**
1. Go to [temp-mail.org](https://temp-mail.org)
2. Copy the temporary email address
3. **Update `.env` file:**
   ```env
   SMTP_HOST=smtp.gmail.com
   SMTP_USER=your_temp_email@temp-mail.org
   SMTP_PASS=temp_password
   NOTIFICATION_EMAIL=your_temp_email@temp-mail.org
   ```

## üß™ **Step 4: Testing the Complete System**

### **1. Test Email Configuration:**
```bash
# Test email service
curl -X POST http://localhost:3000/api/test-email \
  -H "Content-Type: application/json" \
  -d '{"to": "your_email@gmail.com"}'
```

### **2. Create a Test Pipeline:**
```bash
# Create GitHub Actions pipeline
curl -X POST http://localhost:3000/api/pipelines \
  -H "Content-Type: application/json" \
  -d '{
    "name": "GitHub Actions Test",
    "type": "github"
  }'
```

### **3. Test GitHub Actions Integration:**

1. **Push the workflow file** to your GitHub repository
2. **Go to Actions tab** in your GitHub repo
3. **Click "Test CI/CD Dashboard Pipeline"**
4. **Choose inputs:**
   - Test Type: `fail` (to test email notifications)
   - Pipeline Name: `GitHub Actions Test`
5. **Click "Run workflow"**

### **4. Monitor the Dashboard:**
- **Watch the dashboard** at `http://localhost:3001`
- **Check your email** for failure notifications
- **Verify webhook data** in the dashboard

## üîß **Step 5: GitHub Actions Setup**

### **Repository Requirements:**
1. **Public repository** (or GitHub Pro for private)
2. **Workflow file** in `.github/workflows/` directory
3. **GitHub Actions enabled**

### **Workflow Features:**
- ‚úÖ **Manual trigger** with success/fail options
- ‚úÖ **Real pipeline simulation** with delays
- ‚úÖ **Webhook to dashboard** on completion
- ‚úÖ **Email notifications** on failures
- ‚úÖ **Configurable pipeline names**

## ÔøΩÔøΩ **Expected Results:**

1. **Dashboard shows** real pipeline data from GitHub Actions
2. **Email notifications** sent on pipeline failures
3. **Real-time updates** when webhooks are received
4. **Complete pipeline lifecycle** tracking

## üö® **Troubleshooting:**

### **Email Issues:**
- Check Gmail app password is correct
- Verify 2FA is enabled
- Check spam folder
- Use temp-mail.org for testing

### **Webhook Issues:**
- Ensure dashboard is running on port 3000
- Check GitHub Actions can reach localhost
- Verify pipeline ID exists in dashboard

### **Dashboard Issues:**
- Restart backend after email config changes
- Check browser console for errors
- Verify API endpoints are working

This setup gives you a **real, working CI/CD pipeline** that integrates with your dashboard and sends email notifications! Let me know when you're ready to test it.

```shellscript
# Stop the backend (Ctrl+C)
npm install
npm run dev
```

```plaintext
   SMTP_USER=your_email@gmail.com
   SMTP_PASS=your_16_char_app_password
   NOTIFICATION_EMAIL=your_email@gmail.com
```

```plaintext
   SMTP_HOST=smtp.gmail.com
   SMTP_USER=your_temp_email@temp-mail.org
   SMTP_PASS=temp_password
   NOTIFICATION_EMAIL=your_temp_email@temp-mail.org
```

```shellscript
# Test email service
curl -X POST http://localhost:3000/api/test-email \
  -H "Content-Type: application/json" \
  -d '{"to": "your_email@gmail.com"}'
```

```shellscript
# Create GitHub Actions pipeline
curl -X POST http://localhost:3000/api/pipelines \
  -H "Content-Type: application/json" \
  -d '{
    "name": "GitHub Actions Test",
    "type": "github"
  }'
```